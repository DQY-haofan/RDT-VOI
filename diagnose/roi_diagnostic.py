#!/usr/bin/env python3
"""
ROIè¯Šæ–­è„šæœ¬ - æ·±åº¦åˆ†æç®—æ³•é€‰æ‹©ç­–ç•¥å·®å¼‚

åŠŸèƒ½ï¼š
1. å¯¹æ¯”ä¸åŒç®—æ³•çš„ä¼ æ„Ÿå™¨é€‰æ‹©æ¨¡å¼
2. åˆ†è§£ROIè®¡ç®—çš„å„ä¸ªç»„æˆéƒ¨åˆ†
3. åˆ†ææˆæœ¬-æ”¶ç›Šæƒè¡¡
4. è¯†åˆ«å¯¼è‡´è´ŸROIçš„å…·ä½“åŸå› 
5. ç»™å‡ºé’ˆå¯¹æ€§çš„è°ƒå‚å»ºè®®

ç”¨æ³•ï¼š
    python roi_diagnostic.py --config baseline_config.yaml --budget 5
"""

import numpy as np
import scipy.sparse as sp
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import pandas as pd
from dataclasses import dataclass
from typing import List, Dict, Tuple
import yaml
import argparse

# å‡è®¾é¡¹ç›®æ¨¡å—å¯å¯¼å…¥
try:
    from geometry import build_grid2d_geometry
    from spatial_field import build_prior, sample_field
    from sensors import build_sensor_pool
    from selection import greedy_mi, greedy_aopt, greedy_evi_myopic_fast, maxmin_k_center, SelectionResult
    from decision import compute_expected_loss, compute_bayes_decisions
    from inference import SparseFactor, compute_posterior
    from config import Config
except ImportError:
    print("è­¦å‘Šï¼šæ— æ³•å¯¼å…¥é¡¹ç›®æ¨¡å—ï¼Œè¯·ç¡®ä¿è„šæœ¬åœ¨é¡¹ç›®ç›®å½•è¿è¡Œ")


@dataclass
class AlgorithmDiagnostics:
    """å•ä¸ªç®—æ³•çš„è¯Šæ–­ç»“æœ"""
    method_name: str
    selected_ids: List[int]
    total_cost: float
    sensor_types: List[str]
    sensor_costs: List[float]
    sensor_noises: List[float]

    # ç©ºé—´åˆ†å¸ƒ
    selected_coords: np.ndarray
    spatial_coverage: float  # ç©ºé—´è¦†ç›–ç‡

    # å†³ç­–è´¨é‡
    n_TP: int
    n_FP: int
    n_TN: int
    n_FN: int

    # æˆæœ¬åˆ†è§£
    cost_TP: float
    cost_FP: float
    cost_TN: float
    cost_FN: float
    total_loss: float

    # ROIç»„æˆ
    baseline_loss: float
    savings: float
    roi: float

    # ä¿¡æ¯æŒ‡æ ‡
    posterior_variance_mean: float
    posterior_variance_std: float
    mi_total: float  # æ€»äº’ä¿¡æ¯


class ROIDiagnostic:
    """ROIè¯Šæ–­å·¥å…·"""

    def __init__(self, config_path: str):
        """åˆå§‹åŒ–è¯Šæ–­å·¥å…·"""
        self.config = self._load_config(config_path)
        self.output_dir = Path("diagnostics_output")
        self.output_dir.mkdir(exist_ok=True)

    def _load_config(self, config_path: str):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r') as f:
            cfg_dict = yaml.safe_load(f)
        return Config(cfg_dict)

    def run_diagnostic(self, budget: int, methods: List[str] = None):
        """è¿è¡Œå®Œæ•´è¯Šæ–­"""
        print("=" * 80)
        print(f"ğŸ” ROIè¯Šæ–­ - é¢„ç®— k={budget}")
        print("=" * 80)

        # 1. è®¾ç½®å®éªŒ
        print("\n[1/6] è®¾ç½®å®éªŒç¯å¢ƒ...")
        geom, Q_pr, mu_pr, x_true, sensors = self._setup_experiment()

        # 2. è¿è¡Œæ‰€æœ‰ç®—æ³•
        print("\n[2/6] è¿è¡Œç®—æ³•å¹¶æ”¶é›†é€‰æ‹©...")
        if methods is None:
            methods = ['greedy_mi', 'greedy_aopt', 'greedy_evi', 'maxmin']

        results = {}
        for method in methods:
            print(f"  è¿è¡Œ {method}...")
            try:
                results[method] = self._run_method(
                    method, sensors, budget, Q_pr, mu_pr, x_true, geom
                )
            except Exception as e:
                print(f"    âš ï¸ {method} å¤±è´¥: {e}")

        # 3. åˆ†æé€‰æ‹©æ¨¡å¼
        print("\n[3/6] åˆ†æé€‰æ‹©æ¨¡å¼...")
        diagnostics = {}
        for method, result in results.items():
            diagnostics[method] = self._analyze_selection(
                result, sensors, geom, Q_pr, mu_pr, x_true
            )

        # 4. ç”ŸæˆæŠ¥å‘Š
        print("\n[4/6] ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š...")
        self._print_summary_report(diagnostics, budget)

        # 5. å¯è§†åŒ–
        print("\n[5/6] ç”Ÿæˆå¯è§†åŒ–...")
        self._create_visualizations(diagnostics, geom, x_true, budget)

        # 6. è°ƒå‚å»ºè®®
        print("\n[6/6] ç”Ÿæˆè°ƒå‚å»ºè®®...")
        self._generate_tuning_advice(diagnostics, sensors)

        print(f"\nâœ… è¯Šæ–­å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.output_dir}")

        return diagnostics

    def _setup_experiment(self):
        """è®¾ç½®å•æ¬¡å®éªŒ"""
        # æ„å»ºå‡ ä½•
        geom = build_grid2d_geometry(
            self.config.geometry.nx,
            self.config.geometry.ny,
            self.config.geometry.h
        )

        # æ„å»ºå…ˆéªŒ
        Q_pr, mu_pr = build_prior(geom, self.config.prior)

        # é‡‡æ ·çœŸå®åœº
        rng = self.config.get_rng()
        x_true = sample_field(Q_pr, mu_pr, rng)

        # æ„å»ºä¼ æ„Ÿå™¨æ± 
        sensors = build_sensor_pool(geom, self.config.sensors, rng)

        print(f"  âœ“ ç½‘æ ¼: {geom.n} ç‚¹")
        print(f"  âœ“ ä¼ æ„Ÿå™¨å€™é€‰: {len(sensors)} ä¸ª")
        print(f"  âœ“ ä¼ æ„Ÿå™¨ç±»å‹: {len(set(s.sensor_type for s in sensors))} ç§")

        return geom, Q_pr, mu_pr, x_true, sensors

    def _run_method(self, method_name: str, sensors, k: int,
                    Q_pr, mu_pr, x_true, geom) -> SelectionResult:
        """è¿è¡Œå•ä¸ªç®—æ³•"""
        costs = np.array([s.cost for s in sensors])

        if method_name == 'greedy_mi':
            return greedy_mi(
                sensors=sensors,
                k=k,
                Q_pr=Q_pr,
                costs=costs,
                lazy=True,
                batch_size=64,
                use_cost=True,
                keep_fraction=self.config.selection.greedy_mi.get('keep_fraction', 0.20)
            )

        elif method_name == 'greedy_aopt':
            return greedy_aopt(
                sensors=sensors,
                k=k,
                Q_pr=Q_pr,
                costs=costs,
                n_probes=self.config.selection.greedy_aopt.get('n_probes', 8),
                use_cost=True
            )

        elif method_name == 'greedy_evi':
            test_idx = np.arange(min(300, geom.n))
            return greedy_evi_myopic_fast(
                sensors=sensors,
                k=k,
                Q_pr=Q_pr,
                mu_pr=mu_pr,
                decision_config=self.config.decision,
                test_idx=test_idx,
                costs=costs,
                n_y_samples=self.config.selection.greedy_evi.get('n_y_samples', 16),
                use_cost=True,
                mi_prescreen=True,
                keep_fraction=None,
                rng=self.config.get_rng(),
                verbose=False
            )

        elif method_name == 'maxmin':
            return maxmin_k_center(
                sensors=sensors,
                k=k,
                coords=geom.coords,
                costs=costs,
                use_cost=True
            )

        else:
            raise ValueError(f"Unknown method: {method_name}")

    def _analyze_selection(self, result: SelectionResult, sensors, geom,
                           Q_pr, mu_pr, x_true) -> AlgorithmDiagnostics:
        """æ·±åº¦åˆ†æå•ä¸ªç®—æ³•çš„é€‰æ‹©"""
        selected_ids = result.selected_ids
        selected_sensors = [sensors[i] for i in selected_ids]

        # åŸºæœ¬ä¿¡æ¯
        sensor_types = [s.sensor_type for s in selected_sensors]
        sensor_costs = [s.cost for s in selected_sensors]
        sensor_noises = [s.noise_std for s in selected_sensors]
        total_cost = sum(sensor_costs)

        # ç©ºé—´åˆ†å¸ƒ
        selected_coords = np.array([geom.coords[s.location_idx] for s in selected_sensors])
        spatial_coverage = self._compute_spatial_coverage(selected_coords, geom)

        # æ¨¡æ‹Ÿè§‚æµ‹å¹¶è®¡ç®—åéªŒ
        y_obs, H_obs, R_diag_obs = self._simulate_observations(
            selected_sensors, x_true
        )

        mu_post, factor_post = compute_posterior(
            Q_pr, mu_pr, H_obs, R_diag_obs, y_obs
        )

        # è®¡ç®—åéªŒæ–¹å·®
        var_post = self._compute_posterior_variances(factor_post, geom.n)

        # è®¡ç®—å†³ç­–è´¨é‡
        tau_iri = self._get_tau_iri(x_true)
        decisions_prior = (mu_pr >= tau_iri).astype(int)
        decisions_post = (mu_post >= tau_iri).astype(int)
        truth = (x_true >= tau_iri).astype(int)

        # æ··æ·†çŸ©é˜µ
        n_TP = np.sum((decisions_post == 1) & (truth == 1))
        n_FP = np.sum((decisions_post == 1) & (truth == 0))
        n_TN = np.sum((decisions_post == 0) & (truth == 0))
        n_FN = np.sum((decisions_post == 0) & (truth == 1))

        # æˆæœ¬åˆ†è§£
        L_TP = self.config.decision.L_TP_gbp
        L_FP = self.config.decision.L_FP_gbp
        L_TN = self.config.decision.L_TN_gbp
        L_FN = self.config.decision.L_FN_gbp

        cost_TP = n_TP * L_TP
        cost_FP = n_FP * L_FP
        cost_TN = n_TN * L_TN
        cost_FN = n_FN * L_FN
        total_loss = cost_TP + cost_FP + cost_TN + cost_FN

        # åŸºçº¿æŸå¤±ï¼ˆå…ˆéªŒå†³ç­–ï¼‰
        n_TP_prior = np.sum((decisions_prior == 1) & (truth == 1))
        n_FP_prior = np.sum((decisions_prior == 1) & (truth == 0))
        n_TN_prior = np.sum((decisions_prior == 0) & (truth == 0))
        n_FN_prior = np.sum((decisions_prior == 0) & (truth == 1))
        baseline_loss = (n_TP_prior * L_TP + n_FP_prior * L_FP +
                         n_TN_prior * L_TN + n_FN_prior * L_FN)

        # ROIè®¡ç®—
        savings = baseline_loss - total_loss - total_cost
        roi = savings / total_cost if total_cost > 0 else 0.0

        # äº’ä¿¡æ¯ï¼ˆè¿‘ä¼¼ï¼‰
        mi_total = 0.5 * np.sum(np.log(np.maximum(var_post, 1e-10)))

        return AlgorithmDiagnostics(
            method_name=result.method_name,
            selected_ids=selected_ids,
            total_cost=total_cost,
            sensor_types=sensor_types,
            sensor_costs=sensor_costs,
            sensor_noises=sensor_noises,
            selected_coords=selected_coords,
            spatial_coverage=spatial_coverage,
            n_TP=n_TP, n_FP=n_FP, n_TN=n_TN, n_FN=n_FN,
            cost_TP=cost_TP, cost_FP=cost_FP, cost_TN=cost_TN, cost_FN=cost_FN,
            total_loss=total_loss,
            baseline_loss=baseline_loss,
            savings=savings,
            roi=roi,
            posterior_variance_mean=np.mean(var_post),
            posterior_variance_std=np.std(var_post),
            mi_total=mi_total
        )

    def _get_tau_iri(self, x_true: np.ndarray) -> float:
        """è®¡ç®—å†³ç­–é˜ˆå€¼"""
        tau_quantile = self.config.decision.tau_quantile
        return np.quantile(x_true, tau_quantile)

    def _simulate_observations(self, sensors, x_true):
        """æ¨¡æ‹Ÿä¼ æ„Ÿå™¨è§‚æµ‹"""
        m = len(sensors)
        n = len(x_true)

        y_obs = np.zeros(m)
        R_diag = np.zeros(m)
        rows, cols, data = [], [], []

        for i, sensor in enumerate(sensors):
            # è·å–è§‚æµ‹å€¼
            y_obs[i] = sensor.observe(x_true)
            R_diag[i] = sensor.noise_std ** 2

            # æ„å»ºHçŸ©é˜µ
            for j in sensor.footprint_indices:
                rows.append(i)
                cols.append(j)
                data.append(sensor.footprint_weights[sensor.footprint_indices.index(j)])

        H = sp.csr_matrix((data, (rows, cols)), shape=(m, n))

        return y_obs, H, R_diag

    def _compute_posterior_variances(self, factor: SparseFactor, n: int) -> np.ndarray:
        """è®¡ç®—åéªŒæ–¹å·®ï¼ˆå¯¹è§’å…ƒï¼‰"""
        # å¿«é€Ÿé‡‡æ ·æ–¹æ³•
        sample_size = min(n, 100)
        sample_idx = np.random.choice(n, size=sample_size, replace=False)

        var_sample = np.zeros(sample_size)
        for i, idx in enumerate(sample_idx):
            e_i = np.zeros(n)
            e_i[idx] = 1.0
            z = factor.solve(e_i)
            var_sample[i] = z[idx]

        # æ’å€¼åˆ°å…¨åŸŸ
        var_full = np.full(n, np.mean(var_sample))
        var_full[sample_idx] = var_sample

        return var_full

    def _compute_spatial_coverage(self, coords: np.ndarray, geom) -> float:
        """è®¡ç®—ç©ºé—´è¦†ç›–ç‡"""
        if len(coords) == 0:
            return 0.0

        # ç®€åŒ–ï¼šè®¡ç®—æœ€å°åŒ…å›´åœ†å æ€»é¢ç§¯çš„æ¯”ä¾‹
        center = coords.mean(axis=0)
        max_dist = np.max(np.linalg.norm(coords - center, axis=1))

        total_area = (geom.coords[:, 0].max() - geom.coords[:, 0].min()) * \
                     (geom.coords[:, 1].max() - geom.coords[:, 1].min())
        coverage_area = np.pi * max_dist ** 2

        return min(coverage_area / total_area, 1.0)

    def _print_summary_report(self, diagnostics: Dict[str, AlgorithmDiagnostics], budget: int):
        """æ‰“å°æ‘˜è¦æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print(f"ğŸ“Š è¯Šæ–­æŠ¥å‘Šæ‘˜è¦ (k={budget})")
        print("=" * 80)

        # åˆ›å»ºå¯¹æ¯”è¡¨
        data = []
        for method, diag in diagnostics.items():
            data.append({
                'ç®—æ³•': method,
                'æ€»æˆæœ¬(Â£)': f"{diag.total_cost:.0f}",
                'ROI': f"{diag.roi:.3f}",
                'èŠ‚çœ(Â£)': f"{diag.savings:.0f}",
                'æ€»æŸå¤±(Â£)': f"{diag.total_loss:.0f}",
                'TP': diag.n_TP,
                'FP': diag.n_FP,
                'FN': diag.n_FN,
                'è¦†ç›–ç‡': f"{diag.spatial_coverage:.2f}"
            })

        df = pd.DataFrame(data)
        print("\n" + df.to_string(index=False))

        # è¯¦ç»†åˆ†ææ¯ä¸ªç®—æ³•
        print("\n" + "-" * 80)
        print("ğŸ“‹ è¯¦ç»†åˆ†æ")
        print("-" * 80)

        for method, diag in diagnostics.items():
            print(f"\nã€{method}ã€‘")
            print(f"  ä¼ æ„Ÿå™¨é€‰æ‹©:")
            print(f"    - ç±»å‹åˆ†å¸ƒ: {pd.Series(diag.sensor_types).value_counts().to_dict()}")
            print(f"    - å¹³å‡æˆæœ¬: Â£{np.mean(diag.sensor_costs):.1f}")
            print(f"    - å¹³å‡å™ªå£°: {np.mean(diag.sensor_noises):.3f}")

            print(f"  å†³ç­–è´¨é‡:")
            total_decisions = diag.n_TP + diag.n_FP + diag.n_TN + diag.n_FN
            print(f"    - å‡†ç¡®ç‡: {(diag.n_TP + diag.n_TN) / total_decisions:.3f}")
            print(f"    - ç²¾ç¡®ç‡: {diag.n_TP / max(diag.n_TP + diag.n_FP, 1):.3f}")
            print(f"    - å¬å›ç‡: {diag.n_TP / max(diag.n_TP + diag.n_FN, 1):.3f}")

            print(f"  æˆæœ¬åˆ†è§£:")
            print(f"    - åŸºçº¿æŸå¤±: Â£{diag.baseline_loss:.0f}")
            print(f"    - åéªŒæŸå¤±: Â£{diag.total_loss:.0f}")
            print(f"    - ä¼ æ„Ÿå™¨æˆæœ¬: Â£{diag.total_cost:.0f}")
            print(f"    - å‡€èŠ‚çœ: Â£{diag.savings:.0f}")
            print(f"    - ROI: {diag.roi:.3f}")

            # ğŸ”¥ å…³é”®ï¼šè¯†åˆ«ROIä¸ºè´Ÿçš„åŸå› 
            if diag.roi < 0:
                print(f"  âš ï¸ ROIä¸ºè´Ÿçš„åŸå› :")
                loss_reduction = diag.baseline_loss - diag.total_loss
                if loss_reduction < diag.total_cost:
                    print(f"    - æŸå¤±å‡å°‘(Â£{loss_reduction:.0f}) < ä¼ æ„Ÿå™¨æˆæœ¬(Â£{diag.total_cost:.0f})")
                    print(f"    - å·®é¢: Â£{diag.total_cost - loss_reduction:.0f}")
                if diag.n_FP > 0:
                    print(f"    - è¯¯æŠ¥æˆæœ¬è¿‡é«˜: {diag.n_FP} Ã— Â£{self.config.decision.L_FP_gbp} = Â£{diag.cost_FP:.0f}")
                if diag.n_FN > 0:
                    print(f"    - æ¼æŠ¥æˆæœ¬è¿‡é«˜: {diag.n_FN} Ã— Â£{self.config.decision.L_FN_gbp} = Â£{diag.cost_FN:.0f}")

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.output_dir / f"summary_report_k{budget}.txt"
        with open(report_path, 'w') as f:
            f.write(df.to_string(index=False))

        print(f"\næŠ¥å‘Šä¿å­˜è‡³: {report_path}")

    def _create_visualizations(self, diagnostics: Dict[str, AlgorithmDiagnostics],
                               geom, x_true, budget: int):
        """ç”Ÿæˆå¯è§†åŒ–"""
        n_methods = len(diagnostics)

        # å›¾1: ROIåˆ†è§£å¯¹æ¯”
        fig1, axes = plt.subplots(2, 2, figsize=(14, 10))
        fig1.suptitle(f'ROIè¯Šæ–­åˆ†æ (k={budget})', fontsize=16, fontweight='bold')

        methods = list(diagnostics.keys())

        # 1.1 ROIå¯¹æ¯”
        ax = axes[0, 0]
        rois = [diagnostics[m].roi for m in methods]
        colors = ['green' if r > 0 else 'red' for r in rois]
        ax.barh(methods, rois, color=colors, alpha=0.7)
        ax.axvline(0, color='black', linestyle='--', linewidth=1)
        ax.set_xlabel('ROI', fontweight='bold')
        ax.set_title('ROIå¯¹æ¯”', fontweight='bold')
        ax.grid(axis='x', alpha=0.3)

        # 1.2 æˆæœ¬åˆ†è§£
        ax = axes[0, 1]
        costs_data = {
            'ä¼ æ„Ÿå™¨æˆæœ¬': [diagnostics[m].total_cost for m in methods],
            'å†³ç­–æŸå¤±': [diagnostics[m].total_loss for m in methods],
            'åŸºçº¿æŸå¤±': [diagnostics[m].baseline_loss for m in methods]
        }
        x_pos = np.arange(len(methods))
        width = 0.25
        for i, (label, values) in enumerate(costs_data.items()):
            ax.bar(x_pos + i * width, values, width, label=label, alpha=0.7)
        ax.set_xticks(x_pos + width)
        ax.set_xticklabels(methods, rotation=45, ha='right')
        ax.set_ylabel('æˆæœ¬ (Â£)', fontweight='bold')
        ax.set_title('æˆæœ¬ç»“æ„å¯¹æ¯”', fontweight='bold')
        ax.legend()
        ax.grid(axis='y', alpha=0.3)

        # 1.3 å†³ç­–è´¨é‡
        ax = axes[1, 0]
        decision_metrics = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡']
        for method in methods:
            diag = diagnostics[method]
            total = diag.n_TP + diag.n_FP + diag.n_TN + diag.n_FN
            accuracy = (diag.n_TP + diag.n_TN) / total
            precision = diag.n_TP / max(diag.n_TP + diag.n_FP, 1)
            recall = diag.n_TP / max(diag.n_TP + diag.n_FN, 1)
            ax.plot(decision_metrics, [accuracy, precision, recall],
                    marker='o', label=method, linewidth=2)
        ax.set_ylim([0, 1.05])
        ax.set_ylabel('å¾—åˆ†', fontweight='bold')
        ax.set_title('å†³ç­–è´¨é‡å¯¹æ¯”', fontweight='bold')
        ax.legend()
        ax.grid(alpha=0.3)

        # 1.4 ä¼ æ„Ÿå™¨ç±»å‹åˆ†å¸ƒ
        ax = axes[1, 1]
        type_counts = {}
        for method in methods:
            diag = diagnostics[method]
            type_counts[method] = pd.Series(diag.sensor_types).value_counts().to_dict()

        # å †å æ¡å½¢å›¾
        all_types = set()
        for counts in type_counts.values():
            all_types.update(counts.keys())
        all_types = sorted(all_types)

        bottom = np.zeros(len(methods))
        for sensor_type in all_types:
            values = [type_counts[m].get(sensor_type, 0) for m in methods]
            ax.bar(methods, values, bottom=bottom, label=sensor_type, alpha=0.7)
            bottom += values

        ax.set_ylabel('ä¼ æ„Ÿå™¨æ•°é‡', fontweight='bold')
        ax.set_title('ä¼ æ„Ÿå™¨ç±»å‹åˆ†å¸ƒ', fontweight='bold')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')

        plt.tight_layout()
        fig1_path = self.output_dir / f'roi_breakdown_k{budget}.png'
        plt.savefig(fig1_path, dpi=300, bbox_inches='tight')
        print(f"  âœ“ ROIåˆ†è§£å›¾: {fig1_path}")
        plt.close()

        # å›¾2: ç©ºé—´åˆ†å¸ƒ
        fig2, axes = plt.subplots(2, (n_methods + 1) // 2, figsize=(16, 10))
        axes = axes.flatten() if n_methods > 1 else [axes]
        fig2.suptitle(f'ä¼ æ„Ÿå™¨ç©ºé—´åˆ†å¸ƒ (k={budget})', fontsize=16, fontweight='bold')

        for idx, method in enumerate(methods):
            ax = axes[idx]
            diag = diagnostics[method]

            # ç»˜åˆ¶çœŸå®åœº
            x_grid = x_true.reshape(geom.coords[:, 0].max() // 5 + 1,
                                    geom.coords[:, 1].max() // 5 + 1)
            im = ax.contourf(x_grid, levels=15, cmap='RdYlGn_r', alpha=0.6)

            # ç»˜åˆ¶ä¼ æ„Ÿå™¨
            coords = diag.selected_coords
            costs = diag.sensor_costs
            scatter = ax.scatter(coords[:, 0], coords[:, 1],
                                 s=np.array(costs) * 2, c=costs,
                                 cmap='viridis', edgecolors='black',
                                 linewidths=2, alpha=0.9)

            ax.set_title(f'{method}\nROI={diag.roi:.3f}, Cost=Â£{diag.total_cost:.0f}',
                         fontweight='bold')
            ax.set_xlabel('X (m)')
            ax.set_ylabel('Y (m)')
            plt.colorbar(scatter, ax=ax, label='ä¼ æ„Ÿå™¨æˆæœ¬(Â£)')

        # éšè—å¤šä½™å­å›¾
        for idx in range(len(methods), len(axes)):
            axes[idx].axis('off')

        plt.tight_layout()
        fig2_path = self.output_dir / f'spatial_distribution_k{budget}.png'
        plt.savefig(fig2_path, dpi=300, bbox_inches='tight')
        print(f"  âœ“ ç©ºé—´åˆ†å¸ƒå›¾: {fig2_path}")
        plt.close()

        # å›¾3: æ··æ·†çŸ©é˜µ
        fig3, axes = plt.subplots(1, n_methods, figsize=(4 * n_methods, 4))
        axes = [axes] if n_methods == 1 else axes
        fig3.suptitle(f'å†³ç­–æ··æ·†çŸ©é˜µ (k={budget})', fontsize=16, fontweight='bold')

        for idx, method in enumerate(methods):
            diag = diagnostics[method]
            confusion = np.array([
                [diag.n_TP, diag.n_FP],
                [diag.n_FN, diag.n_TN]
            ])

            ax = axes[idx]
            sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues',
                        ax=ax, cbar=True, square=True,
                        xticklabels=['é¢„æµ‹ç»´æŠ¤', 'é¢„æµ‹ä¸ç»´æŠ¤'],
                        yticklabels=['å®é™…ç»´æŠ¤', 'å®é™…ä¸ç»´æŠ¤'])
            ax.set_title(f'{method}\nROI={diag.roi:.3f}', fontweight='bold')

        plt.tight_layout()
        fig3_path = self.output_dir / f'confusion_matrices_k{budget}.png'
        plt.savefig(fig3_path, dpi=300, bbox_inches='tight')
        print(f"  âœ“ æ··æ·†çŸ©é˜µ: {fig3_path}")
        plt.close()

    def _generate_tuning_advice(self, diagnostics: Dict[str, AlgorithmDiagnostics],
                                sensors):
        """ç”Ÿæˆè°ƒå‚å»ºè®®"""
        print("\n" + "=" * 80)
        print("ğŸ’¡ è°ƒå‚å»ºè®®")
        print("=" * 80)

        # åˆ†ææœ€ä½³å’Œæœ€å·®ç®—æ³•
        sorted_methods = sorted(diagnostics.items(), key=lambda x: x[1].roi, reverse=True)
        best_method, best_diag = sorted_methods[0]
        worst_method, worst_diag = sorted_methods[-1]

        print(f"\nğŸ† æœ€ä½³ç®—æ³•: {best_method} (ROI={best_diag.roi:.3f})")
        print(f"ğŸ’€ æœ€å·®ç®—æ³•: {worst_method} (ROI={worst_diag.roi:.3f})")
        print(f"ğŸ“Š æ€§èƒ½å·®è·: {best_diag.roi - worst_diag.roi:.3f}")

        # é€šç”¨å»ºè®®
        print("\nã€é€šç”¨è°ƒå‚å»ºè®®ã€‘")

        # 1. æ£€æŸ¥å†³ç­–æˆæœ¬
        avg_roi = np.mean([d.roi for d in diagnostics.values()])
        if avg_roi < 0:
            print("\nâš ï¸ æ‰€æœ‰ç®—æ³•ROIéƒ½ä¸ºè´Ÿï¼Œä¸»è¦é—®é¢˜å¯èƒ½åœ¨å†³ç­–æˆæœ¬è®¾ç½®ï¼š")

            L_FP = self.config.decision.L_FP_gbp
            L_FN = self.config.decision.L_FN_gbp
            ratio = L_FN / L_FP

            print(f"  å½“å‰è®¾ç½®: L_FN/L_FP = {ratio:.1f}:1")

            if ratio > 15:
                print(f"  âŒ ä¸å¯¹ç§°æ€§è¿‡é«˜ï¼å»ºè®®é™ä½åˆ°10:1")
                print(f"  å»ºè®®: L_FP={L_FP // 2:.0f}, L_FN={L_FN // 5:.0f}")

            # æ£€æŸ¥ä¼ æ„Ÿå™¨æˆæœ¬
            avg_sensor_cost = np.mean([s.cost for s in sensors])
            avg_loss_reduction = np.mean([d.baseline_loss - d.total_loss for d in diagnostics.values()])

            if avg_sensor_cost > avg_loss_reduction:
                print(f"\n  âŒ ä¼ æ„Ÿå™¨æˆæœ¬(Â£{avg_sensor_cost:.0f}) > æŸå¤±å‡å°‘(Â£{avg_loss_reduction:.0f})")
                print(f"  å»ºè®®1: é™ä½æ‰€æœ‰ä¼ æ„Ÿå™¨æˆæœ¬50%")
                print(f"  å»ºè®®2: å¢åŠ pool_fractionåˆ°0.6ä»¥è·å¾—æ›´å¥½çš„é€‰æ‹©")

        # 2. åˆ†æä¸ºä»€ä¹ˆA-optè¡¨ç°æœ€å¥½
        if best_method == 'greedy_aopt':
            print("\nğŸ” A-optimalè¡¨ç°æœ€ä½³çš„åŸå› åˆ†æï¼š")

            # æ¯”è¾ƒä¼ æ„Ÿå™¨é€‰æ‹©
            aopt_types = pd.Series(best_diag.sensor_types).value_counts()
            print(f"  A-optåå¥½: {aopt_types.to_dict()}")

            aopt_avg_cost = np.mean(best_diag.sensor_costs)
            aopt_avg_noise = np.mean(best_diag.sensor_noises)

            print(f"  å¹³å‡æˆæœ¬: Â£{aopt_avg_cost:.1f}")
            print(f"  å¹³å‡å™ªå£°: {aopt_avg_noise:.3f}")

            # ä¸å…¶ä»–ç®—æ³•å¯¹æ¯”
            for method, diag in diagnostics.items():
                if method != best_method:
                    cost_diff = np.mean(diag.sensor_costs) - aopt_avg_cost
                    noise_diff = np.mean(diag.sensor_noises) - aopt_avg_noise
                    print(f"\n  vs {method}:")
                    print(f"    æˆæœ¬å·®å¼‚: Â£{cost_diff:+.1f} ({'æ›´ä¾¿å®œ' if cost_diff < 0 else 'æ›´è´µ'})")
                    print(f"    å™ªå£°å·®å¼‚: {noise_diff:+.3f} ({'æ›´ä½å™ªå£°' if noise_diff < 0 else 'æ›´é«˜å™ªå£°'})")

                    if cost_diff > 0 and diag.roi < best_diag.roi:
                        print(f"    ğŸ’¡ {method}é€‰æ‹©äº†æ›´è´µçš„ä¼ æ„Ÿå™¨ä½†ROIæ›´ä½")
                        print(f"       å»ºè®®: è°ƒæ•´{method}çš„æˆæœ¬æƒé‡å‚æ•°")

        # 3. é’ˆå¯¹æ€§å»ºè®®
        print("\nã€ç®—æ³•ç‰¹å®šå»ºè®®ã€‘")

        for method, diag in diagnostics.items():
            if diag.roi < 0:
                print(f"\nğŸ“‰ {method} (ROI={diag.roi:.3f}):")

                # æˆæœ¬æ•ˆç‡åˆ†æ
                cost_efficiency = diag.savings / diag.total_cost if diag.total_cost > 0 else 0
                print(f"  æˆæœ¬æ•ˆç‡: {cost_efficiency:.3f}")

                if method == 'greedy_mi':
                    current_keep = self.config.selection.greedy_mi.get('keep_fraction', 0.20)
                    print(f"  å½“å‰keep_fraction={current_keep}")
                    if current_keep < 0.4:
                        print(f"  âŒ é¢„ç­›é€‰è¿‡ä¸¥ï¼å»ºè®®å¢åŠ åˆ°0.4-0.5")

                elif method == 'greedy_evi':
                    n_samples = self.config.selection.greedy_evi.get('n_y_samples', 16)
                    print(f"  å½“å‰n_y_samples={n_samples}")
                    if diag.n_FP > diag.n_FN * 2:
                        print(f"  âŒ è¯¯æŠ¥è¿‡å¤šï¼å¯èƒ½éœ€è¦æ›´å¤šæ ·æœ¬")
                        print(f"  å»ºè®®: n_y_samples={n_samples * 2}")

                elif method == 'greedy_aopt':
                    n_probes = self.config.selection.greedy_aopt.get('n_probes', 8)
                    print(f"  å½“å‰n_probes={n_probes}")
                    if n_probes < 16:
                        print(f"  å»ºè®®: å¢åŠ n_probesåˆ°16ä»¥æé«˜æ–¹å·®ä¼°è®¡ç²¾åº¦")

        # ä¿å­˜å»ºè®®åˆ°æ–‡ä»¶
        advice_path = self.output_dir / "tuning_advice.txt"
        with open(advice_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("è‡ªåŠ¨è°ƒå‚å»ºè®®\n")
            f.write("=" * 80 + "\n\n")

            f.write("ã€å…³é”®å‘ç°ã€‘\n")
            f.write(f"- æœ€ä½³ç®—æ³•: {best_method} (ROI={best_diag.roi:.3f})\n")
            f.write(f"- å¹³å‡ROI: {avg_roi:.3f}\n\n")

            if avg_roi < 0:
                f.write("ã€ç´§æ€¥ä¿®å¤ã€‘\n")
                f.write("æ‰€æœ‰ç®—æ³•ROIä¸ºè´Ÿï¼Œå»ºè®®ç«‹å³ä¿®æ”¹ï¼š\n")
                f.write(f"1. é™ä½L_FN: {self.config.decision.L_FN_gbp} â†’ {self.config.decision.L_FN_gbp // 5}\n")
                f.write(f"2. é™ä½L_FP: {self.config.decision.L_FP_gbp} â†’ {self.config.decision.L_FP_gbp // 2}\n")
                f.write("3. é™ä½æ‰€æœ‰ä¼ æ„Ÿå™¨æˆæœ¬50%\n")
                f.write("4. å¢åŠ pool_fractionåˆ°0.6\n\n")

            f.write("ã€ç®—æ³•ç‰¹å®šå»ºè®®ã€‘\n")
            for method, diag in diagnostics.items():
                if diag.roi < best_diag.roi - 0.1:
                    f.write(f"\n{method}:\n")
                    if method == 'greedy_mi':
                        f.write(f"  - keep_fraction: æå‡åˆ°0.4-0.5\n")
                    elif method == 'greedy_evi':
                        f.write(f"  - n_y_samples: æå‡åˆ°32\n")
                    elif method == 'greedy_aopt':
                        f.write(f"  - n_probes: æå‡åˆ°16\n")

        print(f"\nå»ºè®®å·²ä¿å­˜è‡³: {advice_path}")

        # ç”Ÿæˆä¿®å¤åçš„é…ç½®æ–‡ä»¶
        self._generate_fixed_config(diagnostics, best_diag)

    def _generate_fixed_config(self, diagnostics, best_diag):
        """ç”Ÿæˆä¿®å¤åçš„é…ç½®æ–‡ä»¶"""
        avg_roi = np.mean([d.roi for d in diagnostics.values()])

        if avg_roi < 0:
            print("\nğŸ“ ç”Ÿæˆä¿®å¤é…ç½®æ–‡ä»¶...")

            # è¯»å–åŸé…ç½®
            fixed_config = yaml.safe_load(open(self.config._config_path))

            # åº”ç”¨ä¿®å¤
            L_FN_old = fixed_config['decision']['L_FN_gbp']
            L_FP_old = fixed_config['decision']['L_FP_gbp']

            fixed_config['decision']['L_FN_gbp'] = L_FN_old // 5
            fixed_config['decision']['L_FP_gbp'] = L_FP_old // 2
            fixed_config['decision']['target_ddi'] = 0.20

            fixed_config['sensors']['pool_fraction'] = 0.60

            # é™ä½ä¼ æ„Ÿå™¨æˆæœ¬
            for sensor_type in fixed_config['sensors']['types']:
                sensor_type['cost_gbp'] = sensor_type['cost_gbp'] * 0.5

            # è°ƒæ•´ç®—æ³•å‚æ•°
            if 'greedy_mi' in fixed_config['selection']:
                fixed_config['selection']['greedy_mi']['keep_fraction'] = 0.40
            if 'greedy_aopt' in fixed_config['selection']:
                fixed_config['selection']['greedy_aopt']['n_probes'] = 16
            if 'greedy_evi' in fixed_config['selection']:
                fixed_config['selection']['greedy_evi']['n_y_samples'] = 24

            # ä¿å­˜
            fixed_path = self.output_dir / "auto_fixed_config.yaml"
            with open(fixed_path, 'w') as f:
                yaml.dump(fixed_config, f, default_flow_style=False, allow_unicode=True)

            print(f"  âœ“ ä¿®å¤é…ç½®: {fixed_path}")
            print(f"\nè¿è¡Œå‘½ä»¤æµ‹è¯•ä¿®å¤æ•ˆæœ:")
            print(f"  python main.py --config {fixed_path} --budgets 5,10,15")


def main():
    parser = argparse.ArgumentParser(description='ROIè¯Šæ–­å·¥å…·')
    parser.add_argument('--config', type=str, required=True,
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--budget', type=int, default=5,
                        help='ä¼ æ„Ÿå™¨é¢„ç®— (é»˜è®¤: 5)')
    parser.add_argument('--methods', type=str, nargs='+',
                        default=['greedy_mi', 'greedy_aopt', 'greedy_evi', 'maxmin'],
                        help='è¦è¯Šæ–­çš„ç®—æ³•')

    args = parser.parse_args()

    # è¿è¡Œè¯Šæ–­
    diagnostic = ROIDiagnostic(args.config)
    diagnostic.run_diagnostic(args.budget, args.methods)


if __name__ == '__main__':
    main()