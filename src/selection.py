"""
ä¼ æ„Ÿå™¨é€‰æ‹©ç®—æ³•é›†åˆ - å®Œæ•´ç‰ˆæœ¬

åŒ…æ‹¬ï¼š
1. greedy_mi - è´ªå¿ƒäº’ä¿¡æ¯
2. greedy_aopt - è´ªå¿ƒA-optimalï¼ˆè¿¹æœ€å°åŒ–ï¼‰
3. greedy_evi_myopic_fast - å¿«é€Ÿå†³ç­–æ„ŸçŸ¥EVIï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰
4. maxmin_k_center - æœ€å¤§æœ€å°è¦†ç›–
5. uniform_selection - å‡åŒ€éšæœºé€‰æ‹©ï¼ˆå‘åå…¼å®¹ï¼‰
6. random_selection - é€†æˆæœ¬åŠ æƒéšæœºé€‰æ‹©ï¼ˆå‘åå…¼å®¹ï¼‰

ğŸ”¥ ä¿®å¤ç‰ˆæœ¬ - 2025-01-25
"""
import heapq

import numpy as np
import scipy.sparse as sp
from typing import List, Tuple
from dataclasses import dataclass
from sensors import Sensor, assemble_H_R
from inference import SparseFactor


@dataclass
class HeapItem:
    """å †å…ƒç´ ï¼ˆPython heapqæ˜¯æœ€å°å †ï¼Œæ‰€ä»¥å­˜è´Ÿå€¼ï¼‰"""
    neg_score: float  # -ï¼ˆgain/costï¼‰
    timestamp: int  # ç‰ˆæœ¬å·ï¼Œç”¨äºåˆ¤æ–­è¿‡æœŸ
    candidate_id: int

    def __lt__(self, other):
        return self.neg_score < other.neg_score


class LazyGreedySelector:
    """
    Lazy-Greedyé€‰æ‹©å™¨åŸºç±»

    æ ¸å¿ƒæ€æƒ³ï¼š
    1. ç»´æŠ¤æœ€å¤§å †ï¼ˆå­˜æ¯ä¸ªå€™é€‰çš„estimated scoreï¼‰
    2. æ¯æ¬¡å¼¹å‡ºå †é¡¶æ—¶éªŒè¯æ˜¯å¦è¿‡æœŸ
    3. å¦‚æœè¿‡æœŸï¼ˆå½“å‰å› å­ä¸‹é‡ç®—åscoreä¸‹é™ï¼‰â†’ æ›´æ–°å †
    4. å¦‚æœä»æ˜¯æœ€å¤§ â†’ é€‰ä¸­å¹¶åšrank-1æ›´æ–°
    """

    def __init__(self,
                 sensors: List[Sensor],
                 Q_pr,
                 costs: np.ndarray,
                 use_cost: bool = True,
                 prescreen_fraction: float = None,
                 verbose: bool = False):
        """
        Args:
            sensors: å€™é€‰ä¼ æ„Ÿå™¨åˆ—è¡¨
            Q_pr: å…ˆéªŒç²¾åº¦çŸ©é˜µ
            costs: æˆæœ¬æ•°ç»„
            use_cost: æ˜¯å¦ä½¿ç”¨æˆæœ¬å½’ä¸€åŒ–
            prescreen_fraction: MIé¢„ç­›æ¯”ä¾‹ï¼ˆNone=åŠ¨æ€è®¡ç®—ï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.sensors = sensors
        self.Q_pr = Q_pr
        self.costs = costs
        self.use_cost = use_cost
        self.verbose = verbose

        self.n = Q_pr.shape[0]
        self.C = len(sensors)

        # é¢„å¤„ç†ä¼ æ„Ÿå™¨çŸ©é˜µ
        self.H_rows = []
        self.R_list = []
        for s in sensors:
            h = np.zeros(self.n)
            h[s.idxs] = s.weights
            self.H_rows.append(h)
            self.R_list.append(s.noise_var)

        self.H_rows = np.array(self.H_rows)
        self.R_list = np.array(self.R_list)

        # å› å­åˆ†è§£
        self.factor = SparseFactor(Q_pr)

        # é¢„ç­›å‚æ•°
        if prescreen_fraction is None:
            # ğŸ”¥ ä¸“å®¶å»ºè®®ï¼šB = max(3k, ÏC)ï¼Œè¿™é‡Œå…ˆç®—Ï
            # è¿è¡Œæ—¶ä¼šæ ¹æ®kåŠ¨æ€è°ƒæ•´
            self.prescreen_fraction = 0.3
        else:
            self.prescreen_fraction = prescreen_fraction

    def compute_marginal_gain(self, idx: int) -> float:
        """
        è®¡ç®—å€™é€‰idxçš„è¾¹é™…å¢ç›Šï¼ˆå­ç±»å®ç°ï¼‰

        Returns:
            gain: æœªå½’ä¸€åŒ–çš„è¾¹é™…å¢ç›Š
        """
        raise NotImplementedError

    def update_factor(self, idx: int):
        """
        é€‰ä¸­idxåæ›´æ–°å› å­ï¼ˆrank-1æ›´æ–°ï¼‰
        """
        h = self.H_rows[idx]
        r = self.R_list[idx]
        self.factor.rank1_update(h, weight=1.0 / r)

    def prescreen_by_mi(self, k: int) -> np.ndarray:
        """
        ğŸ”¥ MIé¢„ç­›ï¼šä¿ç•™ B = max(3k, ÏC) ä¸ªå€™é€‰
        """
        n_keep_budget = 3 * k  # è‡³å°‘3kä¸ªï¼ˆä¿è¯ç†è®ºä¿è¯ï¼‰
        n_keep_pool = int(np.ceil(self.prescreen_fraction * self.C))
        n_keep = max(n_keep_budget, n_keep_pool, k + 10)
        n_keep = min(n_keep, self.C)  # ä¸è¶…è¿‡æ€»æ•°

        if self.verbose:
            print(f"    MI prescreen: computing initial gains for {self.C} candidates...")

        # æ‰¹é‡è®¡ç®—åˆå§‹MI
        Z = self.factor.solve_multi(self.H_rows.T)
        quad = np.sum(self.H_rows * Z.T, axis=1)
        mi_values = 0.5 * np.log1p(quad / self.R_list)

        # å–top-n_keep
        top_indices = np.argpartition(mi_values, -n_keep)[-n_keep:]

        if self.verbose:
            print(f"    âœ“ Kept {n_keep}/{self.C} candidates "
                  f"({100 * n_keep / self.C:.0f}%)")

        return top_indices

    def lazy_greedy_select(self, k: int,
                           use_prescreen: bool = True) -> Tuple[List[int], List[float]]:
        """
        ğŸ”¥ Lazy-Greedyæ ¸å¿ƒç®—æ³•

        Returns:
            selected_ids: é€‰ä¸­çš„å€™é€‰ç´¢å¼•
            marginal_gains: å¯¹åº”çš„è¾¹é™…å¢ç›Š
        """
        # === é¢„ç­›é˜¶æ®µ ===
        if use_prescreen and self.C > 100:
            alive_candidates = self.prescreen_by_mi(k)
        else:
            alive_candidates = np.arange(self.C)

        alive_set = set(alive_candidates)

        # === åˆå§‹åŒ–å † ===
        heap = []
        timestamp = 0  # å…¨å±€ç‰ˆæœ¬å·
        candidate_timestamps = {}  # è®°å½•æ¯ä¸ªå€™é€‰çš„æœ€æ–°ç‰ˆæœ¬

        if self.verbose:
            print(f"    Initializing heap with {len(alive_candidates)} candidates...")

        for idx in alive_candidates:
            gain = self.compute_marginal_gain(idx)
            score = gain / self.costs[idx] if self.use_cost else gain

            item = HeapItem(
                neg_score=-score,  # æœ€å°å †ï¼Œå­˜è´Ÿå€¼
                timestamp=timestamp,
                candidate_id=idx
            )
            heapq.heappush(heap, item)
            candidate_timestamps[idx] = timestamp

        # === Lazy-Greedyä¸»å¾ªç¯ ===
        selected = []
        marginal_gains = []
        total_cost = 0.0

        recomputes = 0  # ç»Ÿè®¡é‡è®¡ç®—æ¬¡æ•°

        for step in range(k):
            if len(heap) == 0:
                if self.verbose:
                    print(f"    Heap empty at step {step + 1}, stopping.")
                break

            # === å¼¹å‡ºå †é¡¶ ===
            best_item = heapq.heappop(heap)
            idx = best_item.candidate_id
            old_timestamp = best_item.timestamp

            # === éªŒè¯æ˜¯å¦è¿‡æœŸ ===
            # è¿‡æœŸæ¡ä»¶ï¼štimestamp < å½“å‰å…¨å±€timestampï¼ˆè¯´æ˜å› å­å·²æ›´æ–°ï¼‰
            is_stale = (old_timestamp < timestamp)

            if is_stale:
                # é‡æ–°è®¡ç®—å½“å‰å› å­ä¸‹çš„è¾¹é™…å¢ç›Š
                gain_new = self.compute_marginal_gain(idx)
                score_new = gain_new / self.costs[idx] if self.use_cost else gain_new

                # æ›´æ–°å †ï¼ˆå¸¦æ–°ç‰ˆæœ¬å·ï¼‰
                new_item = HeapItem(
                    neg_score=-score_new,
                    timestamp=timestamp,
                    candidate_id=idx
                )
                heapq.heappush(heap, new_item)
                candidate_timestamps[idx] = timestamp

                recomputes += 1

                # ç»§ç»­ä¸‹ä¸€è½®ï¼ˆä¸é€‰ä¸­ï¼Œç»§ç»­éªŒè¯å †é¡¶ï¼‰
                continue

            # === å¦‚æœæ²¡è¿‡æœŸï¼Œè¯´æ˜è¿™æ˜¯çœŸæ­£çš„æœ€å¤§å¢ç›Š â†’ é€‰ä¸­ ===
            gain_actual = self.compute_marginal_gain(idx)
            score_actual = gain_actual / self.costs[idx] if self.use_cost else gain_actual

            if score_actual <= 0:
                if self.verbose:
                    print(f"    Step {step + 1}: no positive gain, stopping.")
                break

            # é€‰ä¸­
            selected.append(int(idx))
            marginal_gains.append(float(gain_actual))
            total_cost += float(self.costs[idx])

            if self.verbose and (step + 1) % max(1, k // 10) == 0:
                print(f"    Step {step + 1}/{k}: selected #{idx}, "
                      f"gain={gain_actual:.4f}, cost={self.costs[idx]:.0f}")

            # === Rank-1æ›´æ–°å› å­ ===
            self.update_factor(idx)

            # ä»æ´»è·ƒé›†ç§»é™¤
            alive_set.discard(idx)

            # ğŸ”¥ å…³é”®ï¼šé€’å¢å…¨å±€ç‰ˆæœ¬å·
            # è¿™ä¼šè®©å †ä¸­æ‰€æœ‰å…ƒç´ "è¿‡æœŸ"ï¼Œä¸‹æ¬¡å¼¹å‡ºæ—¶ä¼šé‡æ–°éªŒè¯
            timestamp += 1

        if self.verbose:
            avg_recomputes = recomputes / max(1, len(selected))
            print(f"    âœ“ Lazy-Greedy stats: {len(selected)} selected, "
                  f"{recomputes} recomputes (avg {avg_recomputes:.1f} per selection)")

        return selected, marginal_gains


class LazyGreedyMI(LazyGreedySelector):
    """Lazy-Greedy for Mutual Information"""

    def compute_marginal_gain(self, idx: int) -> float:
        """MIè¾¹é™…å¢ç›Šï¼š0.5 * log(1 + h^T Î£ h / r)"""
        h = self.H_rows[idx]
        r = self.R_list[idx]

        z = self.factor.solve(h)
        quad = np.dot(h, z)
        mi = 0.5 * np.log1p(quad / r)

        return mi


class LazyGreedyEVI(LazyGreedySelector):
    """Lazy-Greedy for EVI (å¸¦æµ‹è¯•é›†è¯„ä¼°)"""

    def __init__(self,
                 sensors: List[Sensor],
                 Q_pr,
                 mu_pr: np.ndarray,
                 costs: np.ndarray,
                 decision_config,
                 test_idx: np.ndarray,
                 tau_fixed: float,
                 use_cost: bool = True,
                 prescreen_fraction: float = None,
                 verbose: bool = False):
        """
        EVIç‰ˆæœ¬éœ€è¦é¢å¤–å‚æ•°ï¼š
        - mu_pr: å…ˆéªŒå‡å€¼
        - decision_config: å†³ç­–é…ç½®
        - test_idx: æµ‹è¯•ç‚¹ç´¢å¼•
        - tau_fixed: é”å®šçš„å†³ç­–é˜ˆå€¼
        """
        super().__init__(sensors, Q_pr, costs, use_cost,
                         prescreen_fraction, verbose)

        self.mu_pr = mu_pr
        self.decision_config = decision_config
        self.test_idx = test_idx
        self.tau_fixed = tau_fixed

        # é¢„è®¡ç®—æµ‹è¯•é›†çš„å…ˆéªŒå¯¹è§’æ–¹å·®
        from inference import compute_posterior_variance_diagonal
        var_test = compute_posterior_variance_diagonal(self.factor, test_idx)
        self.diag_test = np.maximum(var_test, 1e-12)
        self.sigma_test = np.sqrt(self.diag_test)

        # é¢„è®¡ç®—ZçŸ©é˜µï¼ˆç”¨äºå¿«é€Ÿrank-1æ›´æ–°ï¼‰
        if self.verbose:
            print(f"    Precomputing Z matrix for {len(test_idx)} test points...")
        self.Z = self.factor.solve_multi(self.H_rows.T)  # (n, C)

        # å…ˆéªŒé£é™©ï¼ˆå›ºå®šï¼‰
        from decision import expected_loss
        mu_test = mu_pr[test_idx]
        self.prior_risk = expected_loss(
            mu_test, self.sigma_test, decision_config,
            test_indices=np.arange(len(test_idx)),
            tau=tau_fixed
        )

    def compute_marginal_gain(self, idx: int) -> float:
        """
        EVIè¾¹é™…å¢ç›Šï¼šprior_risk - posterior_risk
        """
        from decision import expected_loss

        # å½“å‰å› å­ä¸‹çš„æµ‹è¯•ç‚¹æ–¹å·®
        z_test = self.Z[self.test_idx, idx]
        h = self.H_rows[idx]
        r = self.R_list[idx]

        # Sherman-Morrisonå¯¹è§’æ–¹å·®æ›´æ–°
        quad = np.dot(h, self.Z[:, idx])
        denom = r + quad
        denom = max(denom, 1e-12)

        diag_post = self.diag_test - (z_test ** 2) / denom
        diag_post = np.maximum(diag_post, 1e-12)
        sigma_post = np.sqrt(diag_post)

        # åéªŒé£é™©
        mu_test = self.mu_pr[self.test_idx]
        post_risk = expected_loss(
            mu_test, sigma_post, self.decision_config,
            test_indices=np.arange(len(self.test_idx)),
            tau=self.tau_fixed
        )

        # EVI = é£é™©å‡å°‘
        evi_gain = self.prior_risk - post_risk
        evi_gain = max(evi_gain, 0.0)  # é˜²å®ˆå¼é’³ä½

        return evi_gain

    def update_factor(self, idx: int):
        """
        EVIç‰ˆæœ¬éœ€è¦åŒæ—¶æ›´æ–°ï¼š
        1. å› å­ï¼ˆrank-1æ›´æ–°ï¼‰
        2. ZçŸ©é˜µï¼ˆSherman-Morrisonï¼‰
        3. æµ‹è¯•é›†å¯¹è§’æ–¹å·®
        4. å…ˆéªŒé£é™©
        """
        h = self.H_rows[idx]
        r = self.R_list[idx]
        z_star = self.Z[:, idx]

        # è®¡ç®—åˆ†æ¯
        quad = np.dot(h, z_star)
        denom = r + quad
        denom = max(denom, 1e-12)

        # æ›´æ–°æµ‹è¯•é›†æ–¹å·®
        z_test = z_star[self.test_idx]
        self.diag_test = self.diag_test - (z_test ** 2) / denom
        self.diag_test = np.maximum(self.diag_test, 1e-12)
        self.sigma_test = np.sqrt(self.diag_test)

        # æ›´æ–°å…ˆéªŒé£é™©ï¼ˆç”¨äºä¸‹ä¸€è½®ï¼‰
        from decision import expected_loss
        mu_test = self.mu_pr[self.test_idx]
        self.prior_risk = expected_loss(
            mu_test, self.sigma_test, self.decision_config,
            test_indices=np.arange(len(self.test_idx)),
            tau=self.tau_fixed
        )

        # æ›´æ–°ZçŸ©é˜µï¼ˆSherman-Morrisonï¼‰
        c = h @ self.Z
        self.Z -= np.outer(z_star, c) / denom

        # æ›´æ–°å› å­
        self.factor.rank1_update(h, weight=1.0 / r)



@dataclass
class SelectionResult:
    """ä¼ æ„Ÿå™¨é€‰æ‹©ç»“æœ"""
    selected_ids: List[int]
    objective_values: List[float]
    marginal_gains: List[float]
    total_cost: float
    method_name: str


# =====================================================================
# 1. Greedy MIï¼ˆäº’ä¿¡æ¯ï¼‰
# =====================================================================

def greedy_mi(sensors, k: int, Q_pr, costs: np.ndarray = None,
              lazy: bool = True,
              batch_size: int = 1,
              use_cost: bool = True,
              keep_fraction: float = None,
              verbose: bool = False) -> 'SelectionResult':  # ğŸ”¥ æ·»åŠ è¿™ä¸ªå‚æ•°
    """
    ğŸ”¥ Lazy-Greedy MIï¼ˆå¸¦å †ä¼˜åŒ–ï¼‰

    å‘åå…¼å®¹æ¥å£ï¼Œä¸åŸgreedy_miç­¾åä¸€è‡´
    """
    from selection import SelectionResult

    C = len(sensors)

    if costs is None:
        costs = np.ones(C, dtype=float)
    else:
        costs = np.asarray(costs, dtype=float)

    # ä½¿ç”¨Lazy-Greedyé€‰æ‹©å™¨
    selector = LazyGreedyMI(
        sensors=sensors,
        Q_pr=Q_pr,
        costs=costs,
        use_cost=use_cost,
        prescreen_fraction=keep_fraction,  # âœ… ä½¿ç”¨å‚æ•°å
        verbose=verbose  # âœ… ç°åœ¨æœ‰è¿™ä¸ªå‚æ•°äº†
    )

    selected, marginal_gains = selector.lazy_greedy_select(k, use_prescreen=True)

    # è®¡ç®—ç´¯ç§¯ç›®æ ‡å€¼
    objective_values = []
    cumsum = 0.0
    for mg in marginal_gains:
        cumsum += mg
        objective_values.append(cumsum)

    total_cost = sum(costs[i] for i in selected)

    return SelectionResult(
        selected_ids=selected,
        objective_values=objective_values,
        marginal_gains=marginal_gains,
        total_cost=total_cost,
        method_name="Greedy-MI"
    )

# =====================================================================
# 2. Greedy A-optimalï¼ˆè¿¹æœ€å°åŒ–ï¼‰
# =====================================================================

def greedy_aopt(sensors, k: int, Q_pr, costs: np.ndarray = None,
                n_probes: int = 16, use_cost: bool = True,
                rng: np.random.Generator = None) -> 'SelectionResult':  # ğŸ”¥ æ–°å¢å‚æ•°
    """
    Greedy A-optimal design (trace minimization)

    ğŸ”¥ P0-3ä¿®å¤ï¼šæ·»åŠ rngå‚æ•°æ”¯æŒå¤–éƒ¨éšæœºæ•°ç”Ÿæˆå™¨

    Args:
        sensors: å€™é€‰ä¼ æ„Ÿå™¨åˆ—è¡¨
        k: é€‰æ‹©æ•°é‡
        Q_pr: å…ˆéªŒç²¾åº¦çŸ©é˜µ
        costs: æˆæœ¬æ•°ç»„
        n_probes: è¿¹ä¼°è®¡çš„æ¢é’ˆæ•°é‡
        use_cost: æ˜¯å¦ä½¿ç”¨æˆæœ¬å½’ä¸€åŒ–
        rng: éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆğŸ”¥ æ–°å¢ï¼Œç”¨äºæ¢é’ˆé‡‡æ ·ï¼‰
    """
    from inference import SparseFactor

    n = Q_pr.shape[0]
    C = len(sensors)

    if costs is None:
        costs = np.ones(C, dtype=float)
    else:
        costs = np.asarray(costs, dtype=float)
        if len(costs) != C:
            raise ValueError(f"Cost array length {len(costs)} doesn't match sensor count {C}")

    # ğŸ”¥ P0-3ä¿®å¤ï¼šä½¿ç”¨ä¼ å…¥çš„rng
    if rng is None:
        import warnings
        warnings.warn(
            "No RNG provided to greedy_aopt, creating new one. "
            "Pass rng from config.get_rng() for reproducibility.",
            UserWarning, stacklevel=2
        )
        rng = np.random.default_rng()  # ğŸ”¥ ç§»é™¤ç¡¬ç¼–ç çš„42

    selected = []
    marginal_gains = []
    objective_values = []
    total_cost = 0.0

    H_rows = []
    R_list = []
    for s in sensors:
        h = np.zeros(n)
        h[s.idxs] = s.weights
        H_rows.append(h)
        R_list.append(s.noise_var)

    H_rows = np.array(H_rows)
    R_list = np.array(R_list)

    factor = SparseFactor(Q_pr)

    # ğŸ”¥ ä½¿ç”¨ä¼ å…¥çš„rngç”Ÿæˆæ¢é’ˆ
    probes = rng.standard_normal((n, n_probes))
    Z_probes = factor.solve_multi(probes)
    trace_current = np.mean(np.sum(probes * Z_probes, axis=0))

    alive = np.ones(C, dtype=bool)

    for step in range(k):
        best_idx = -1
        best_gain = -np.inf
        best_reduction = 0.0

        candidates = np.where(alive)[0]

        for idx in candidates:
            h = H_rows[idx]
            r = R_list[idx]

            z = factor.solve(h)
            quad = np.dot(h, z)
            zz = np.dot(z, z)

            denom = r + quad
            if denom > 1e-12:
                reduction = zz / denom
                gain = reduction / costs[idx] if use_cost else reduction

                if gain > best_gain:
                    best_gain = gain
                    best_idx = idx
                    best_reduction = reduction

        if best_idx < 0 or best_gain <= 0:
            break

        selected.append(int(best_idx))
        marginal_gains.append(float(best_reduction))
        total_cost += float(costs[best_idx])
        trace_current -= best_reduction
        objective_values.append(float(trace_current))

        h_star = H_rows[best_idx]
        r_star = R_list[best_idx]
        factor.rank1_update(h_star, weight=1.0 / r_star)

        alive[best_idx] = False

    from selection import SelectionResult
    return SelectionResult(
        selected_ids=selected,
        objective_values=objective_values,
        marginal_gains=marginal_gains,
        total_cost=total_cost,
        method_name="Greedy-Aopt"
    )

# =====================================================================
# 3. ğŸ”¥ Greedy EVI Myopic Fastï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰
# =====================================================================

def greedy_evi_myopic_fast(
        sensors,
        k: int,
        Q_pr,
        mu_pr: np.ndarray,
        decision_config,
        test_idx: np.ndarray,
        costs: np.ndarray = None,
        n_y_samples: int = 0,              # ğŸ”¥ æ·»åŠ è¿™ä¸ª
        use_cost: bool = True,
        mi_prescreen: bool = True,
        keep_fraction: float = None,
        rng: np.random.Generator = None,
        verbose: bool = False
) -> 'SelectionResult':
    """
    ğŸ”¥ Lazy-Greedy EVIï¼ˆå¸¦å †ä¼˜åŒ–ï¼‰

    å‘åå…¼å®¹æ¥å£
    """
    from selection import SelectionResult

    C = len(sensors)

    if costs is None:
        costs = np.ones(C, dtype=float)
    else:
        costs = np.asarray(costs, dtype=float)

    # ğŸ”¥ ç¡®ä¿tauå·²é”å®š
    if hasattr(decision_config, 'tau_iri') and decision_config.tau_iri is not None:
        tau_fixed = decision_config.tau_iri
    else:
        raise ValueError(
            "tau_iri not set in decision_config. "
            "Call config.lock_decision_threshold(mu_pr) before EVI selection."
        )

    # ä½¿ç”¨Lazy-Greedy EVIé€‰æ‹©å™¨
    selector = LazyGreedyEVI(
        sensors=sensors,
        Q_pr=Q_pr,
        mu_pr=mu_pr,
        costs=costs,
        decision_config=decision_config,
        test_idx=test_idx,
        tau_fixed=tau_fixed,
        use_cost=use_cost,
        prescreen_fraction=keep_fraction,  # âœ… ä½¿ç”¨å‚æ•°å
        verbose=verbose  # âœ… å‚æ•°å·²å­˜åœ¨
    )

    selected, marginal_gains = selector.lazy_greedy_select(k, use_prescreen=True)

    # è®¡ç®—ç´¯ç§¯ç›®æ ‡å€¼
    objective_values = []
    cumsum = 0.0
    for mg in marginal_gains:
        cumsum += mg
        objective_values.append(cumsum)

    total_cost = sum(costs[i] for i in selected)

    return SelectionResult(
        selected_ids=selected,
        objective_values=objective_values,
        marginal_gains=marginal_gains,
        total_cost=total_cost,
        method_name="Greedy-EVI"
    )

# =====================================================================
# 4. Maxmin k-center
# =====================================================================

def maxmin_k_center(sensors, k: int, coords: np.ndarray,
                    costs: np.ndarray = None, use_cost: bool = True) -> 'SelectionResult':
    """Maxmin k-center (spatial coverage)"""
    import numpy as np
    from scipy.spatial.distance import cdist

    C = len(sensors)

    if costs is None:
        costs = np.ones(C, dtype=float)
    else:
        costs = np.asarray(costs, dtype=float)
        if len(costs) != C:
            raise ValueError(f"Cost array length {len(costs)} doesn't match sensor count {C}")

    sensor_coords = np.array([coords[s.idxs[0]] for s in sensors])
    dist_matrix = cdist(coords, sensor_coords)

    selected = []
    total_cost = 0.0

    avg_dist = dist_matrix.mean(axis=0)
    score = avg_dist / costs if use_cost else avg_dist
    first = int(np.argmax(score))
    selected.append(first)
    total_cost += float(costs[first])

    min_dist = dist_matrix[:, first].copy()

    for step in range(1, k):
        best_idx = -1
        best_score = -np.inf

        for idx in range(C):
            if idx in selected:
                continue

            new_min_dist = np.minimum(min_dist, dist_matrix[:, idx])
            maxmin_dist = new_min_dist.min()

            if use_cost:
                score = maxmin_dist / costs[idx]
            else:
                score = maxmin_dist

            if score > best_score:
                best_score = score
                best_idx = idx

        if best_idx < 0:
            break

        selected.append(int(best_idx))
        total_cost += float(costs[best_idx])
        min_dist = np.minimum(min_dist, dist_matrix[:, best_idx])

    return SelectionResult(
        selected_ids=selected,
        objective_values=[0.0] * len(selected),
        marginal_gains=[0.0] * len(selected),
        total_cost=total_cost,
        method_name="Maxmin"
    )


# =====================================================================
# 5. Uniform Selectionï¼ˆå‘åå…¼å®¹ï¼‰
# =====================================================================

def uniform_selection(sensors: List[Sensor], k: int, Q_pr: sp.spmatrix = None,
                     mu_pr: np.ndarray = None, rng: np.random.Generator = None) -> SelectionResult:
    """å‡åŒ€éšæœºé€‰æ‹©ï¼ˆå‘åå…¼å®¹ï¼‰"""
    if rng is None:
        rng = np.random.default_rng()

    n_sensors = len(sensors)

    if k > n_sensors:
        k = n_sensors

    selected_ids = rng.choice(n_sensors, size=k, replace=False).tolist()
    total_cost = sum(sensors[i].cost for i in selected_ids)

    return SelectionResult(
        selected_ids=selected_ids,
        objective_values=[0.0] * k,
        marginal_gains=[0.0] * k,
        total_cost=total_cost,
        method_name="Uniform"
    )


# =====================================================================
# 6. Random Selectionï¼ˆå‘åå…¼å®¹ï¼‰
# =====================================================================

def random_selection(sensors: List[Sensor], k: int, Q_pr: sp.spmatrix = None,
                    mu_pr: np.ndarray = None, rng: np.random.Generator = None) -> SelectionResult:
    """éšæœºé€‰æ‹©ï¼ˆé€†æˆæœ¬åŠ æƒï¼‰"""
    if rng is None:
        rng = np.random.default_rng()

    n_sensors = len(sensors)
    costs = np.array([s.cost for s in sensors], dtype=float)

    weights = 1.0 / (costs + 1.0)
    weights = weights / weights.sum()

    if k > n_sensors:
        k = n_sensors

    selected_ids = rng.choice(n_sensors, size=k, replace=False, p=weights).tolist()
    total_cost = sum(sensors[i].cost for i in selected_ids)

    return SelectionResult(
        selected_ids=selected_ids,
        objective_values=[0.0] * k,
        marginal_gains=[0.0] * k,
        total_cost=total_cost,
        method_name="Random"
    )