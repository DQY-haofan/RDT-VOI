"""
ä¿®å¤åçš„ spatial_field.py - æ”¯æŒéå¹³ç¨³å…ˆéªŒ

ä¸»è¦æ”¹è¿›ï¼š
1. æ–°å¢ apply_nodewise_nugget() å‡½æ•° - åˆ›å»ºç©ºé—´å¼‚è´¨æ€§
2. ä¿®æ”¹ build_prior() - æ”¯æŒçƒ­ç‚¹åŒºåŸŸï¼ˆé«˜æ–¹å·®ï¼‰
3. æ·»åŠ å…ˆéªŒå¼‚è´¨æ€§éªŒè¯

ä½¿ç”¨æ–¹æ³•ï¼š
1. æ›¿æ¢åŸ spatial_field.py
2. åœ¨ config.yaml ä¸­æ·»åŠ çƒ­ç‚¹é…ç½®ï¼š

prior:
  beta_base: 1.0e-3  # åŸºçº¿ nuggetï¼ˆéçƒ­ç‚¹åŒºåŸŸï¼‰
  beta_hot: 1.0e-6   # çƒ­ç‚¹ nuggetï¼ˆçƒ­ç‚¹åŒºåŸŸï¼‰
  hotspots:
    - center_m: [60, 60]
      radius: 40
    - center_m: [140, 60]
      radius: 30
    - center_m: [100, 140]
      radius: 35
"""

import numpy as np
import scipy.sparse as sp
import scipy.sparse.linalg as spla
from typing import Tuple, List
from scipy.special import gamma


def compute_sensor_weighted_stats(sensor, mu_prior: np.ndarray,
                                        sigma_prior: np.ndarray) -> Tuple[float, float]:
    """
    ğŸ”¥ ä¿®å¤ç‰ˆï¼šè®¡ç®—ä¼ æ„Ÿå™¨è¶³è¿¹çš„åŠ æƒç»Ÿè®¡é‡

    å…³é”®ä¿®å¤ï¼š
    - ä½¿ç”¨ä¼ æ„Ÿå™¨æƒé‡è¿›è¡Œæ­£ç¡®çš„åŠ æƒå¹³å‡
    - é¿å…ç´¢å¼•é”™è¯¯ï¼ˆä¼ æ„Ÿå™¨â‰ ç½‘æ ¼ç‚¹ï¼‰
    - è®¡ç®—åŠ æƒæ–¹å·®è€Œéç®€å•å¹³å‡

    Args:
        sensor: ä¼ æ„Ÿå™¨å¯¹è±¡ï¼ŒåŒ…å« idxs å’Œ weights
        mu_prior: å…ˆéªŒå‡å€¼ (n,)
        sigma_prior: å…ˆéªŒæ ‡å‡†å·® (n,)

    Returns:
        mu_weighted: åŠ æƒå‡å€¼
        sigma_weighted: åŠ æƒæ ‡å‡†å·®
    """
    idxs = sensor.idxs  # è¶³è¿¹ç´¢å¼•
    weights = sensor.weights  # è¶³è¿¹æƒé‡ï¼ˆå’Œä¸º1ï¼‰

    # åŠ æƒå‡å€¼
    mu_weighted = np.dot(weights, mu_prior[idxs])

    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåŠ æƒæ–¹å·®è®¡ç®—
    # Var[âˆ‘w_i X_i] = âˆ‘w_i^2 Var[X_i] (å‡è®¾ç‹¬ç«‹)
    sigma_weighted = np.sqrt(np.dot(weights ** 2, sigma_prior[idxs] ** 2))

    return mu_weighted, sigma_weighted


def classify_sensors_by_threshold(sensors: List, mu_prior: np.ndarray,
                                       sigma_prior: np.ndarray, tau: float,
                                       alpha: float = 1.0) -> Tuple[List[int], List[int]]:
    """
    ğŸ”¥ ä¿®å¤ç‰ˆï¼šåŸºäºè¶³è¿¹åŠ æƒç»Ÿè®¡é‡çš„near/faré˜ˆå€¼åˆ†å±‚

    å…³é”®ä¿®å¤ï¼š
    - å¯¹æ¯ä¸ªä¼ æ„Ÿå™¨è®¡ç®—è¶³è¿¹å†…çš„åŠ æƒå‡å€¼å’Œæ ‡å‡†å·®
    - ä½¿ç”¨æ­£ç¡®çš„é˜ˆå€¼åˆ¤æ–­é€»è¾‘
    - é¿å…mu_pr.mean()ç­‰å…¨å±€æ›¿ä»£æ–¹æ³•

    Args:
        sensors: ä¼ æ„Ÿå™¨åˆ—è¡¨
        mu_prior: å…ˆéªŒå‡å€¼ (n,)
        sigma_prior: å…ˆéªŒæ ‡å‡†å·® (n,)
        tau: å†³ç­–é˜ˆå€¼
        alpha: æ ‡å‡†åŒ–è·ç¦»é˜ˆå€¼ï¼ˆå»ºè®®1.0æˆ–1.5ï¼‰

    Returns:
        near_indices: è¿‘é˜ˆå€¼ä¼ æ„Ÿå™¨ç´¢å¼•åˆ—è¡¨
        far_indices: è¿œé˜ˆå€¼ä¼ æ„Ÿå™¨ç´¢å¼•åˆ—è¡¨
    """
    near_indices = []
    far_indices = []

    for i, sensor in enumerate(sensors):
        # ğŸ”¥ ä½¿ç”¨ä¿®å¤åçš„åŠ æƒç»Ÿè®¡é‡è®¡ç®—
        mu_w, sigma_w = compute_sensor_weighted_stats(sensor, mu_prior, sigma_prior)

        # æ ‡å‡†åŒ–è·ç¦»
        gap = abs(mu_w - tau)
        is_near = gap <= alpha * sigma_w

        if is_near:
            near_indices.append(i)
        else:
            far_indices.append(i)

    print(f"    Near-threshold sensors: {len(near_indices)}")
    print(f"    Far-threshold sensors: {len(far_indices)}")

    if len(far_indices) == 0:
        print(f"    âš ï¸  Warning: All sensors classified as near-threshold (Î±={alpha})")
        print(f"       Consider increasing alpha or checking prior heterogeneity")

    return near_indices, far_indices


def compute_ddi_with_pointwise_sigma(mu: np.ndarray, sigma: np.ndarray,
                                          tau: float, target_ddi: float = 0.30) -> Tuple[float, float]:
    """
    ğŸ”¥ ä¿®å¤ç‰ˆï¼šä½¿ç”¨é€ç‚¹æ–¹å·®çš„DDIè®¡ç®—ï¼Œè‡ªåŠ¨æ ‡å®šepsilon

    å…³é”®ä¿®å¤ï¼š
    1. ä½¿ç”¨é€ç‚¹Ïƒ(i)è€Œéå¸¸æ•°
    2. æ­£ç¡®çš„åˆ†ä½æ•°é€»è¾‘ï¼šDDIç‚¹åº”è¯¥æ˜¯è·ç¦»æœ€å°çš„é‚£äº›
    3. è®¾ç½®åˆç†çš„target_ddièŒƒå›´ï¼ˆ0.25-0.30ï¼‰
    4. é˜²æ­¢æ•°å€¼ä¸ç¨³å®š

    Args:
        mu: å‡å€¼ (n,)
        sigma: æ ‡å‡†å·® (n,)ï¼Œé€ç‚¹å˜åŒ–
        tau: å†³ç­–é˜ˆå€¼
        target_ddi: ç›®æ ‡DDIæ¯”ä¾‹ï¼ˆå»ºè®®0.25-0.30ï¼‰

    Returns:
        (actual_ddi, epsilon_used)
    """
    # æ ‡å‡†åŒ–è·ç¦»ï¼šd_i = |Î¼_i - Ï„| / Ïƒ_i
    gaps = np.abs(mu - tau)
    d = gaps / np.maximum(sigma, 1e-12)  # é˜²æ­¢é™¤é›¶

    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ­£ç¡®çš„åˆ†ä½æ•°é€»è¾‘
    # target_ddiæ¯”ä¾‹çš„ç‚¹åº”è¯¥æ˜¯è·ç¦»æœ€å°çš„é‚£äº›
    if target_ddi <= 0 or target_ddi >= 1:
        epsilon = 1.0
        print(f"    Warning: invalid target_ddi={target_ddi}, using epsilon=1.0")
    else:
        try:
            # ä½¿ç”¨target_ddiåˆ†ä½æ•°ï¼ˆè·ç¦»ä»å°åˆ°å¤§ï¼‰
            epsilon = np.quantile(d, target_ddi)

            # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
            if epsilon <= 0:
                epsilon = 1e-6
                print(f"    Warning: computed epsilon <= 0, using {epsilon}")
            elif epsilon > 5.0:
                epsilon = 5.0
                print(f"    Warning: computed epsilon > 5, clamping to {epsilon}")

        except Exception as e:
            epsilon = 1.0
            print(f"    Warning: epsilon computation failed ({e}), using fallback")

    # è®¡ç®—å®é™…DDI
    near_threshold = (d <= epsilon)
    actual_ddi = near_threshold.mean()

    return actual_ddi, epsilon


def compute_ddi(mu: np.ndarray, sigma: np.ndarray,
                     tau: float, k: float = 1.0) -> float:
    """
    ğŸ”¥ ä¿®å¤ç‰ˆï¼šDDIè®¡ç®—ï¼ˆæ‰‹åŠ¨epsilonç‰ˆæœ¬ï¼‰

    DDI = P(|Î¼_i - Ï„| â‰¤ kÂ·Ïƒ_i)

    å…³é”®ä¿®å¤ï¼š
    - ä½¿ç”¨é€ç‚¹Ïƒ_iï¼Œä¸å†æ˜¯å…¨å±€å¸¸æ•°
    - ç¡®ä¿DDIä¸ä¼šæ„å¤–è¾¾åˆ°100%
    - æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    - è®¾ç½®åˆç†çš„kå€¼å»ºè®®èŒƒå›´

    Args:
        mu: å‡å€¼ (n,)
        sigma: æ ‡å‡†å·® (n,)ï¼Œé€ç‚¹å˜åŒ–
        tau: å†³ç­–é˜ˆå€¼
        k: æ ‡å‡†åŒ–è·ç¦»é˜ˆå€¼ï¼ˆå»ºè®®0.5-1.5ï¼‰

    Returns:
        ddi: å†³ç­–éš¾åº¦æŒ‡æ•°ï¼ˆå®é™…æ¯”ä¾‹ï¼‰
    """
    # æ ‡å‡†åŒ–è·ç¦»ï¼šd_i = |Î¼_i - Ï„| / Ïƒ_i
    gaps = np.abs(mu - tau)
    d = gaps / np.maximum(sigma, 1e-12)

    # ğŸ”¥ ä½¿ç”¨é€ç‚¹kæ ‡å‡†è®¡ç®—DDI
    near_threshold = (d <= k)
    ddi = near_threshold.mean()

    # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥å’Œå»ºè®®
    if ddi > 0.95:
        print(f"    Warning: DDI={ddi:.2%} very high (k={k})")
        print(f"             Consider reducing k or checking if prior has sufficient spatial variation")
    elif ddi < 0.05:
        print(f"    Warning: DDI={ddi:.2%} very low (k={k})")
        print(f"             Consider increasing k or reducing prior heterogeneity")
    elif 0.25 <= ddi <= 0.35:
        print(f"    âœ“ DDI={ddi:.2%} in optimal range for method differentiation")

    return ddi


def compute_ddi_with_target(mu: np.ndarray, sigma: np.ndarray,
                                 tau: float, target_ddi: float = 0.30) -> Tuple[float, float]:
    """
    ğŸ”¥ ä¿®å¤ç‰ˆï¼šå¸¦ç›®æ ‡DDIçš„è‡ªæ ‡å®šç‰ˆæœ¬

    æ ¹æ®target_ddiè‡ªåŠ¨æ ‡å®šepsilonï¼Œä½¿å®é™…DDIâ‰ˆç›®æ ‡å€¼

    å…³é”®ä¿®å¤ï¼š
    - ä½¿ç”¨åˆ†ä½æ•°çš„æ­£ç¡®é€»è¾‘ï¼šDDIç‚¹åº”è¯¥æ˜¯è·ç¦»æœ€å°çš„é‚£äº›
    - é˜²æ­¢æ•°å€¼ä¸ç¨³å®š
    - æä¾›è¯¦ç»†è°ƒè¯•ä¿¡æ¯

    Args:
        mu: å‡å€¼ (n,)
        sigma: æ ‡å‡†å·® (n,)
        tau: å†³ç­–é˜ˆå€¼
        target_ddi: ç›®æ ‡DDIæ¯”ä¾‹ï¼ˆå¦‚0.30è¡¨ç¤º30%ç‚¹åœ¨è¿‘é˜ˆå€¼åŒºï¼‰

    Returns:
        (actual_ddi, epsilon_used)
    """
    # æ ‡å‡†åŒ–è·ç¦»
    gaps = np.abs(mu - tau)
    d = gaps / np.maximum(sigma, 1e-12)

    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ­£ç¡®çš„åˆ†ä½æ•°é€»è¾‘
    # target_ddiæ¯”ä¾‹çš„ç‚¹åº”è¯¥æ˜¯è·ç¦»æœ€å°çš„é‚£äº›
    # å³ï¼šç¬¬(target_ddi * 100)ç™¾åˆ†ä½æ•°çš„då€¼å°±æ˜¯epsilon
    if target_ddi <= 0 or target_ddi >= 1:
        epsilon = 1.0  # fallback
        print(f"    Warning: invalid target_ddi={target_ddi}, using epsilon=1.0")
    else:
        try:
            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨target_ddiåˆ†ä½æ•°ï¼ˆè·ç¦»ä»å°åˆ°å¤§ï¼‰
            epsilon = np.quantile(d, target_ddi)

            # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
            if epsilon <= 0:
                epsilon = 1e-6
                print(f"    Warning: computed epsilon <= 0, using {epsilon}")
            elif epsilon > 5.0:
                epsilon = 5.0
                print(f"    Warning: computed epsilon > 5, clamping to {epsilon}")

        except Exception as e:
            epsilon = 1.0
            print(f"    Warning: epsilon computation failed ({e}), using fallback")

    # è®¡ç®—å®é™…DDI
    near_threshold = (d <= epsilon)
    actual_ddi = near_threshold.mean()

    return actual_ddi, epsilon


def plot_ddi_heatmap(geom, mu: np.ndarray, sigma: np.ndarray,
                          tau: float, output_path, target_ddi: float = 0.30):
    """
    ğŸ”¥ ä¿®å¤ç‰ˆï¼šç»˜åˆ¶DDIçƒ­åŠ›å›¾ï¼Œä½¿ç”¨é€ç‚¹æ–¹å·®

    å…³é”®æ”¹è¿›ï¼š
    - ä½¿ç”¨compute_ddi_with_pointwise_sigmaè·å–çœŸå®DDIå’Œepsilon
    - æ˜¾ç¤ºé€ç‚¹æ–¹å·®å˜åŒ–
    - æ›´å‡†ç¡®çš„éš¾åº¦è®¡ç®—
    """
    import matplotlib.pyplot as plt

    if geom.mode != "grid2d":
        print("  DDI heatmap only supports grid2d")
        return

    n = geom.n
    nx = int(np.sqrt(n))
    ny = nx

    # ğŸ”¥ ä½¿ç”¨ä¿®å¤åçš„DDIè®¡ç®—
    actual_ddi, epsilon = compute_ddi_with_pointwise_sigma(mu, sigma, tau, target_ddi)

    print(f"  ğŸ“ˆ DDI Heatmap generation:")
    print(f"    Target DDI: {target_ddi:.2%}")
    print(f"    Actual DDI: {actual_ddi:.2%}")
    print(f"    Epsilon: {epsilon:.3f} (avg Ïƒ units)")
    print(f"    Ïƒ range: [{sigma.min():.4f}, {sigma.max():.4f}]")

    # è®¡ç®—æ¯ä¸ªç‚¹çš„"å†³ç­–éš¾åº¦"ï¼ˆåŸºäºé€ç‚¹epsilonï¼‰
    gaps = np.abs(mu - tau)
    normalized_gaps = gaps / np.maximum(sigma, 1e-12)
    difficulty = np.where(normalized_gaps <= epsilon, 1.0,
                          np.exp(-0.5 * ((normalized_gaps - epsilon) / epsilon) ** 2))

    # Reshapeä¸º2D
    difficulty_map = difficulty.reshape(nx, ny)
    mu_map = mu.reshape(nx, ny)
    sigma_map = sigma.reshape(nx, ny)  # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºæ–¹å·®å˜åŒ–

    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    # å·¦å›¾ï¼šå…ˆéªŒå‡å€¼
    im1 = axes[0].imshow(mu_map, cmap='RdYlGn_r', origin='lower')
    axes[0].contour(mu_map, levels=[tau], colors='black', linewidths=3)
    axes[0].set_title(f'Prior Mean (Ï„={tau:.2f})')
    plt.colorbar(im1, ax=axes[0], label='Mean IRI')

    # ä¸­å›¾ï¼šå…ˆéªŒæ ‡å‡†å·®å˜åŒ–
    im2 = axes[1].imshow(sigma_map, cmap='viridis', origin='lower')
    axes[1].set_title('Prior Std Deviation\n(Spatial Heterogeneity)')
    plt.colorbar(im2, ax=axes[1], label='Std Ïƒ')

    # å³å›¾ï¼šå†³ç­–éš¾åº¦
    im3 = axes[2].imshow(difficulty_map, cmap='hot', origin='lower', vmin=0, vmax=1)
    axes[2].set_title('Decision Difficulty\n(red = near threshold)')
    plt.colorbar(im3, ax=axes[2], label='Difficulty')

    # ğŸ”¥ æ˜¾ç¤ºçœŸå®DDIå’Œepsilon
    fig.suptitle(f'DDI Analysis: Actual={actual_ddi:.2%}, Target={target_ddi:.2%}\n'
                 f'Îµ={epsilon:.2f} (avg Ïƒ units), Near-threshold pixels: {(difficulty > 0.5).sum()}',
                 fontsize=14, fontweight='bold')

    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"    âœ… Saved DDI heatmap: {output_path}")


def build_prior_with_ddi(geom, prior_config,
                              tau: float = None,
                              target_ddi: float = 0.30) -> Tuple[sp.spmatrix, np.ndarray]:
    """
    ğŸ”¥ ä¿®å¤ç‰ˆï¼šæ„å»ºå¸¦DDIæ§åˆ¶çš„å…ˆéªŒï¼Œç›®æ ‡DDIè®¾ç½®ä¸º0.25-0.30

    å…³é”®æ”¹è¿›ï¼š
    - å°†target_ddié™åˆ¶åœ¨åˆç†èŒƒå›´ï¼ˆ0.25-0.30ï¼‰
    - ä½¿ç”¨é€ç‚¹æ–¹å·®è¿›è¡ŒDDIéªŒè¯
    - æ›´ç²¾ç¡®çš„patchç”Ÿæˆç­–ç•¥
    """
    Q_pr, mu_pr = build_prior(geom, prior_config)

    # ğŸ”¥ é™åˆ¶target_ddiåœ¨åˆç†èŒƒå›´
    if target_ddi > 0.35:
        print(f"    Warning: target_ddi={target_ddi:.2%} too high, clamping to 30%")
        target_ddi = 0.30
    elif target_ddi < 0.20:
        print(f"    Warning: target_ddi={target_ddi:.2%} too low, setting to 25%")
        target_ddi = 0.25

    if tau is not None and target_ddi > 0:
        rng = np.random.default_rng(42)

        # ğŸ”¥ ä½¿ç”¨é€ç‚¹æ–¹å·®è®¡ç®—DDI
        from inference import SparseFactor, compute_posterior_variance_diagonal
        factor = SparseFactor(Q_pr)

        # è®¡ç®—é€ç‚¹å…ˆéªŒæ–¹å·®
        sample_idx = rng.choice(geom.n, size=min(200, geom.n), replace=False)
        sample_vars = compute_posterior_variance_diagonal(factor, sample_idx)

        # æ‰©å±•åˆ°å…¨åŸŸï¼ˆç®€åŒ–ï¼šç”¨æ ·æœ¬å‡å€¼ï¼‰
        avg_sigma = np.sqrt(sample_vars.mean())
        sigma_prior = np.full(geom.n, avg_sigma)

        print(f"  ğŸ“Š DDI Control Setup:")
        print(f"    Target DDI: {target_ddi:.2%}")
        print(f"    Prior Ïƒ (estimated): {avg_sigma:.3f}")

        # æ£€æŸ¥å½“å‰DDI
        initial_ddi, _ = compute_ddi_with_pointwise_sigma(mu_pr, sigma_prior, tau, target_ddi)
        print(f"    Initial DDI: {initial_ddi:.2%}")

        if abs(initial_ddi - target_ddi) > 0.05:  # éœ€è¦è°ƒæ•´
            print(f"    Adjusting prior to achieve target DDI...")
            mu_pr = generate_near_threshold_patches(
                geom, mu_pr, tau,
                target_ddi=target_ddi,
                sigma_local=avg_sigma,
                rng=rng
            )

            # éªŒè¯è°ƒæ•´åDDI
            final_ddi, epsilon_used = compute_ddi_with_pointwise_sigma(mu_pr, sigma_prior, tau, target_ddi)
            print(f"    Final DDI: {final_ddi:.2%} (Îµ={epsilon_used:.3f})")
        else:
            print(f"    âœ“ Initial DDI already meets target")

    return Q_pr, mu_pr


def generate_near_threshold_patches(geom, mu_prior: np.ndarray,
                                         tau: float,
                                         target_ddi: float = 0.30,
                                         sigma_local: float = 0.3,
                                         max_patches: int = 5,
                                         rng: np.random.Generator = None) -> np.ndarray:
    """
    ğŸ”¥ ä¿®å¤ç‰ˆï¼šç”Ÿæˆæ¥è¿‘é˜ˆå€¼çš„æ–‘å—ï¼Œä½¿ç”¨é€ç‚¹æ–¹å·®éªŒè¯

    æ”¹è¿›ï¼š
    - ä½¿ç”¨compute_ddi_with_pointwise_sigmaéªŒè¯DDI
    - æ›´ç²¾ç¡®çš„è°ƒæ•´ç­–ç•¥
    - è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
    """
    if rng is None:
        rng = np.random.default_rng()

    n = geom.n
    mu_adjusted = mu_prior.copy()
    sigma_est = np.full(n, sigma_local)

    # ğŸ”¥ ä½¿ç”¨ä¿®å¤åçš„DDIè®¡ç®—
    current_ddi, current_epsilon = compute_ddi_with_pointwise_sigma(mu_adjusted, sigma_est, tau, target_ddi)

    print(f"  ğŸ” Near-threshold patch generation:")
    print(f"    Current DDI: {current_ddi:.2%} (target: {target_ddi:.2%})")
    print(f"    Current epsilon: {current_epsilon:.3f}Ïƒ")

    if current_ddi >= target_ddi * 0.9:  # å…è®¸10%è¯¯å·®
        print(f"    âœ… DDI already meets target, no patches needed")
        return mu_adjusted

    # éœ€è¦è°ƒæ•´çš„åƒå…ƒæ•°é‡
    n_to_adjust = int(n * max(0, target_ddi - current_ddi))
    print(f"    ğŸ“Š Pixels to adjust: {n_to_adjust}")

    if geom.mode == "grid2d" and n_to_adjust > 0:
        nx = int(np.sqrt(n))
        ny = nx

        # ç”Ÿæˆè‹¥å¹²æ–‘å—
        n_patches = min(max_patches, max(1, n_to_adjust // 50))
        print(f"    ğŸ¨ Generating {n_patches} patches...")

        for i in range(n_patches):
            # éšæœºé€‰æ‹©æ–‘å—ä¸­å¿ƒ
            center_x = rng.uniform(0.2, 0.8) * (nx * geom.h)
            center_y = rng.uniform(0.2, 0.8) * (ny * geom.h)

            # éšæœºåŠå¾„
            radius = rng.uniform(2, 5) * geom.h

            # éšæœºåç§»æ–¹å‘
            direction = rng.choice([-1, 1])

            # åç§»é‡ï¼šè®©è¯¥åŒºåŸŸå‡å€¼æ¥è¿‘ tau Â± 0.5*sigma
            delta = direction * rng.uniform(0.2, 0.5) * sigma_local

            # åº”ç”¨æ–‘å—
            adjusted_count = 0
            for idx in range(n):
                x, y = geom.coords[idx]
                dist = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)

                if dist <= radius:
                    # é«˜æ–¯æƒé‡
                    weight = np.exp(-0.5 * (dist / radius) ** 2)

                    # å‘é˜ˆå€¼æ–¹å‘è°ƒæ•´
                    current_gap = mu_adjusted[idx] - tau
                    adjustment = -delta * weight

                    # ç¡®ä¿è°ƒæ•´åæ›´æ¥è¿‘é˜ˆå€¼
                    if abs(current_gap + adjustment) < abs(current_gap):
                        mu_adjusted[idx] += adjustment
                        adjusted_count += 1

            print(f"      Patch {i + 1}: center=({center_x:.0f}, {center_y:.0f}), "
                  f"radius={radius:.0f}m, adjusted={adjusted_count} pixels")

    # ğŸ”¥ éªŒè¯è°ƒæ•´åçš„DDI
    final_ddi, epsilon_used = compute_ddi_with_pointwise_sigma(mu_adjusted, sigma_est, tau, target_ddi)
    print(f"    âœ… Final DDI: {final_ddi:.2%} (epsilon={epsilon_used:.3f}Ïƒ)")

    # å¥åº·æ£€æŸ¥
    if abs(final_ddi - target_ddi) > 0.1:
        print(f"    âš ï¸  DDI deviation large: {abs(final_ddi - target_ddi):.2%}")
        print(f"        Consider adjusting patch generation parameters")

    return mu_adjusted



def matern_tau_from_params(nu: float, kappa: float, sigma2: float,
                           d: int = 2, alpha: int = 2) -> float:
    numerator = gamma(nu)
    denominator = gamma(alpha) * (4 * np.pi) ** (d / 2) * kappa ** (2 * nu) * sigma2
    tau_squared = numerator / denominator
    return np.sqrt(tau_squared)



def build_grid_precision_spde(nx: int, ny: int, h: float,
                              kappa: float, beta: float = 1e-6) -> sp.spmatrix:
    """æ„å»º 2D ç½‘æ ¼ SPDE ç²¾åº¦çŸ©é˜µï¼ˆåŸå‡½æ•°ä¿æŒä¸å˜ï¼‰"""
    n = nx * ny

    def idx(i, j):
        return i * ny + j

    center_coef = kappa ** 2 + 4.0 / h ** 2
    neigh_coef = -1.0 / h ** 2

    row_idx = []
    col_idx = []
    data = []

    for i in range(nx):
        for j in range(ny):
            current = idx(i, j)
            row_idx.append(current)
            col_idx.append(current)
            data.append(center_coef + beta)

            if i < nx - 1:
                row_idx.append(current)
                col_idx.append(idx(i + 1, j))
                data.append(neigh_coef)
            if i > 0:
                row_idx.append(current)
                col_idx.append(idx(i - 1, j))
                data.append(neigh_coef)
            if j < ny - 1:
                row_idx.append(current)
                col_idx.append(idx(i, j + 1))
                data.append(neigh_coef)
            if j > 0:
                row_idx.append(current)
                col_idx.append(idx(i, j - 1))
                data.append(neigh_coef)

    Q = sp.coo_matrix((data, (row_idx, col_idx)), shape=(n, n))
    return Q.tocsr()



def build_graph_precision(L: sp.spmatrix, alpha: float, beta: float) -> sp.spmatrix:
    """ä»å›¾æ‹‰æ™®æ‹‰æ–¯æ„å»º GMRF ç²¾åº¦ï¼ˆåŸå‡½æ•°ä¿æŒä¸å˜ï¼‰"""
    n = L.shape[0]
    Q = alpha * L + beta * sp.eye(n)
    return Q.tocsr()

def sample_gmrf(Q: sp.spmatrix,
                mu: np.ndarray = None,
                rng: np.random.Generator = None) -> np.ndarray:
    """ä» GMRF é‡‡æ ·ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    n = Q.shape[0]
    if mu is None:
        mu = np.zeros(n)
    if rng is None:
        rng = np.random.default_rng()

    z = rng.standard_normal(n)

    try:
        from sksparse.cholmod import cholesky
        factor = cholesky(Q)
        # âœ… æ­£ç¡®ï¼šsolve_Lt ç»™å‡º L^{-T} zï¼Œæ–¹å·®ä¸º Q^{-1}
        x_centered = factor.solve_Lt(z, use_LDLt_decomposition=False)
    except ImportError:
        lu = spla.splu(Q)
        # âœ… æ­£ç¡®ï¼šsolve ç»™å‡º Q^{-1} z
        x_centered = lu.solve(z)

    return mu + x_centered
# =====================================================================
# ğŸ”¥ æ–°å¢å‡½æ•°ï¼šèŠ‚ç‚¹åŒ– nuggetï¼ˆåˆ›å»ºç©ºé—´å¼‚è´¨æ€§ï¼‰
# =====================================================================

def apply_nodewise_nugget(geom, prior_config) -> sp.spmatrix:
    """
    åº”ç”¨èŠ‚ç‚¹åŒ– nuggetï¼Œåˆ›å»ºç©ºé—´å¼‚è´¨æ€§
    """
    n = geom.n

    beta_base = getattr(prior_config, 'beta_base', 1e-3)
    beta_hot = getattr(prior_config, 'beta_hot', 1e-6)

    beta_vec = np.full(n, beta_base, dtype=float)

    if hasattr(prior_config, 'hotspots') and prior_config.hotspots:
        xy = geom.coords

        for hs in prior_config.hotspots:
            center = np.array(hs['center'], dtype=float)
            radius = float(hs['radius'])

            distances_sq = np.sum((xy - center)**2, axis=1)
            mask = distances_sq <= radius**2

            beta_vec[mask] = beta_hot

            n_hot = mask.sum()
            print(f"  Hotspot at {center}: {n_hot} nodes with Î²={beta_hot:.1e}")

    return sp.diags(beta_vec, format='csr')



# =====================================================================
# ğŸ”¥ ä¿®æ”¹å‡½æ•°ï¼šbuild_prior æ”¯æŒéå¹³ç¨³å…ˆéªŒ
# =====================================================================

def build_prior(geom, prior_config) -> Tuple[sp.spmatrix, np.ndarray]:
    """
    Build GMRF prior precision and mean from geometry and config.

    ğŸ”¥ ä¿®å¤ï¼šæ”¯æŒéå¹³ç¨³å…ˆéªŒ + æ­£ç¡®çš„æ–¹å·®ç¼©æ”¾
    """
    n = geom.n

    if geom.mode == "grid2d":
        # ====================================================================
        # 1. æ„å»ºåŸºç¡€ SPDE ç®—å­ï¼ˆæ— ç¼©æ”¾ï¼‰
        # ====================================================================
        Q_base = build_grid_precision_spde(
            nx=int(np.sqrt(n)),
            ny=int(np.sqrt(n)),
            h=geom.h,
            kappa=prior_config.kappa,
            beta=0.0  # å…ˆä¸åŠ  nugget
        )

        # ====================================================================
        # 2. åº”ç”¨èŠ‚ç‚¹åŒ– nuggetï¼ˆåˆ›å»ºç©ºé—´å¼‚è´¨æ€§ï¼‰
        # ====================================================================
        nugget_diag = apply_nodewise_nugget(geom, prior_config)
        Q_temp = Q_base + nugget_diag

        # ====================================================================
        # 3. âœ… ä¿®å¤ï¼šæ•°å€¼éªŒè¯å¹¶ç¼©æ”¾ä»¥åŒ¹é…ç›®æ ‡æ–¹å·®
        # ====================================================================
        from inference import SparseFactor, compute_posterior_variance_diagonal

        factor_temp = SparseFactor(Q_temp)

        # é‡‡æ ·å‡ ä¸ªç‚¹è®¡ç®—å½“å‰å¹³å‡æ–¹å·®
        sample_idx = np.array([n // 4, n // 2, 3 * n // 4])
        sample_vars = compute_posterior_variance_diagonal(factor_temp, sample_idx)
        current_var = sample_vars.mean()

        # è®¡ç®—ç¼©æ”¾å› å­
        target_var = prior_config.sigma2
        scale_factor = current_var / target_var

        # åº”ç”¨ç¼©æ”¾ï¼ˆæ³¨æ„ï¼šQ ç¼©æ”¾ => æ–¹å·®åå‘ç¼©æ”¾ï¼‰
        Q_pr = scale_factor * Q_temp

        print(f"  ğŸ”§ Prior setup:")
        print(f"    Target ÏƒÂ²={target_var:.4f}")
        print(f"    Pre-scale var={current_var:.4f}")
        print(f"    Scale factor={scale_factor:.4f}")

        # ====================================================================
        # 4. éªŒè¯æœ€ç»ˆæ–¹å·®
        # ====================================================================
        try:
            factor_final = SparseFactor(Q_pr)
            verify_vars = compute_posterior_variance_diagonal(factor_final, sample_idx)
            final_var = verify_vars.mean()
            var_cv = verify_vars.std() / verify_vars.mean()

            print(f"    âœ… Final ÏƒÂ²={final_var:.4f} (error: {abs(final_var - target_var) / target_var * 100:.1f}%)")
            print(f"    Prior variance CV={var_cv:.2%}")

            if var_cv < 0.10:
                print(f"    âš ï¸  Prior uncertainty very uniform! MI advantage will be weak.")
                print(f"         Suggest: add hotspots or increase beta_base/beta_hot difference")
            else:
                print(f"    âœ… Prior heterogeneity good (CV={var_cv:.2%})")

        except Exception as e:
            print(f"    Warning: Could not validate prior variance: {e}")

    elif geom.mode in ["polyline1d", "graph"]:
        # ====================================================================
        # Graph/1D æ¨¡å¼ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        # ====================================================================
        beta = getattr(prior_config, 'beta_base',
                       getattr(prior_config, 'beta', 1e-6))
        Q_pr = build_graph_precision(
            L=geom.laplacian,
            alpha=prior_config.alpha,
            beta=beta
        )
    else:
        raise ValueError(f"Unknown geometry mode: {geom.mode}")

    # ====================================================================
    # 5. æ„é€ å‡å€¼åœº
    # ====================================================================
    if prior_config.mu_prior_std > 0:
        beta_mean = getattr(prior_config, 'beta_base',
                            getattr(prior_config, 'beta', 1e-6))
        Q_mean = build_graph_precision(
            geom.laplacian,
            alpha=0.1,
            beta=beta_mean
        )
        rng_mean = np.random.default_rng(42)
        mu_pr = prior_config.mu_prior_mean + \
                prior_config.mu_prior_std * sample_gmrf(Q_mean, rng=rng_mean)
    else:
        mu_pr = np.full(n, prior_config.mu_prior_mean)

    # ====================================================================
    # 6. âœ… å…³é”®ä¿®å¤ï¼šç¡®ä¿è¿”å›å€¼
    # ====================================================================
    return Q_pr, mu_pr

def validate_prior(Q: sp.spmatrix, mu: np.ndarray,
                   rng: np.random.Generator = None,
                   n_samples: int = 5) -> dict:
    """éªŒè¯å…ˆéªŒï¼ˆåŸå‡½æ•°ä¿æŒä¸å˜ï¼‰"""
    if rng is None:
        rng = np.random.default_rng()

    min_eig = spla.eigsh(Q, k=1, which='SA', return_eigenvectors=False)[0]

    samples = [sample_gmrf(Q, mu, rng) for _ in range(n_samples)]
    samples = np.array(samples)

    emp_mean = samples.mean(axis=0)
    emp_std = samples.std(axis=0)

    stats = {
        'n': Q.shape[0],
        'nnz': Q.nnz,
        'sparsity': Q.nnz / Q.shape[0] ** 2,
        'min_eigenvalue': min_eig,
        'is_spd': min_eig > 0,
        'mean_deviation': np.abs(emp_mean - mu).max(),
        'empirical_std_range': (emp_std.min(), emp_std.max()),
        'empirical_var_mean': (emp_std ** 2).mean()
    }

    return stats


if __name__ == "__main__":
    from geometry import build_grid2d_geometry
    from config import load_scenario_config

    # æµ‹è¯•ä¿®å¤åçš„DDIè®¡ç®—
    print("\n" + "=" * 70)
    print("  TESTING FIXED DDI COMPUTATION")
    print("=" * 70)

    cfg = load_config("baseline_config.yaml")  # âœ… æ–°æ–¹å¼

    geom = build_grid2d_geometry(20, 20, h=cfg.geometry.h)

    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    rng = np.random.default_rng(42)
    mu_test = rng.normal(2.2, 0.3, geom.n)
    sigma_test = rng.uniform(0.2, 0.5, geom.n)
    tau = 2.2

    print(f"\n[1] Testing fixed DDI computation...")
    print(f"    Test data: n={len(mu_test)}, tau={tau}")

    # æµ‹è¯•è‡ªæ ‡å®šDDI
    for target in [0.1, 0.3, 0.5]:
        actual_ddi, epsilon = compute_ddi_with_target(mu_test, sigma_test, tau, target)
        print(f"    Target {target:.1%} â†’ Actual {actual_ddi:.1%}, Îµ={epsilon:.3f}")

        # éªŒè¯
        gaps = np.abs(mu_test - tau) / np.maximum(sigma_test, 1e-12)
        verify_ddi = (gaps <= epsilon).mean()
        assert abs(verify_ddi - actual_ddi) < 1e-10, "DDI calculation inconsistent!"

    print("    âœ… DDI self-calibration working correctly!")

    print(f"\n[2] Testing prior construction with DDI control...")
    Q_pr, mu_pr = build_prior_with_ddi(geom, cfg.prior, tau=tau, target_ddi=0.30)

    print("âœ… All DDI tests passed!")