"""
å¯è§†åŒ–è¾…åŠ©å‡½æ•° - ç”Ÿæˆä¸“å®¶å»ºè®®ä¸­ç¼ºå¤±çš„ä¸‰å¼ å›¾

åŒ…æ‹¬ï¼š
1. Critical Difference å›¾ï¼ˆä½¿ç”¨fold-levelæ•°æ®ï¼‰
2. Type Composition å †å å›¾
3. Spatial Diagnostics å›¾
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List
import scipy.sparse as sp


# ============================================================================
# 1. Critical Difference å›¾ï¼ˆä½¿ç”¨fold-levelæ•°æ®ï¼‰
# ============================================================================

def aggregate_fold_level_results(all_results) -> pd.DataFrame:
    """
    èšåˆfold-levelç»“æœï¼Œä¸ºCritical Differenceå›¾å‡†å¤‡æ•°æ®

    Returns:
        DataFrame with columns: method, budget, fold, expected_loss_gbp, rmse, ...
    """
    rows = []

    for method_name, method_data in all_results.items():
        budgets_data = method_data.get('budgets', {})

        for budget_key, budget_data in budgets_data.items():
            budget = int(budget_key)
            fold_results = budget_data.get('fold_results', [])

            for fold_idx, fold_res in enumerate(fold_results):
                if not fold_res or not fold_res.get('success', False):
                    continue

                metrics = fold_res.get('metrics', {})

                row = {
                    'method': method_name,
                    'budget': budget,
                    'fold': fold_idx,
                    'expected_loss_gbp': metrics.get('expected_loss_gbp', np.nan),
                    'rmse': metrics.get('rmse', np.nan),
                    'mae': metrics.get('mae', np.nan),
                    'r2': metrics.get('r2', np.nan),
                    'coverage_90': metrics.get('coverage_90', np.nan),
                    'msse': metrics.get('msse', np.nan),
                }

                rows.append(row)

    df = pd.DataFrame(rows)
    print(f"  Aggregated {len(df)} fold-level results")
    return df


def plot_critical_difference_from_folds(df: pd.DataFrame,
                                        metric: str,
                                        output_path: Path,
                                        alpha: float = 0.05):
    """
    ç»˜åˆ¶Critical Differenceå›¾ï¼ˆä½¿ç”¨fold-levelæ•°æ®ï¼‰

    Args:
        df: fold-level results DataFrame
        metric: 'expected_loss_gbp' or other metric
        output_path: è¾“å‡ºè·¯å¾„
        alpha: æ˜¾è‘—æ€§æ°´å¹³
    """
    try:
        from scipy.stats import friedmanchisquare, rankdata
        from itertools import combinations
    except ImportError:
        print("  Warning: scipy not available for CD diagram")
        return

    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
    sub = df[df[metric].notna()].copy()

    if len(sub) < 10:
        print(f"  Skipping CD diagram: insufficient data (n={len(sub)})")
        return

    # åˆ›å»ºå®ä¾‹IDï¼ˆbudget + foldç»„åˆï¼‰
    sub['instance'] = sub['budget'].astype(str) + '_f' + sub['fold'].astype(int).astype(str)

    # Pivotï¼šè¡Œ=å®ä¾‹ï¼Œåˆ—=æ–¹æ³•
    pivot = sub.pivot_table(index='instance', columns='method', values=metric, aggfunc='mean')

    methods = pivot.columns.tolist()
    n_methods = len(methods)
    n_instances = len(pivot)

    print(f"  CD diagram: {n_methods} methods Ã— {n_instances} instances")

    if n_methods < 2 or n_instances < 5:
        print(f"  Skipping CD diagram: too few methods or instances")
        return

    # è®¡ç®—æ’åï¼ˆæ¯ä¸ªå®ä¾‹å†…æ’åï¼Œå€¼è¶Šå°è¶Šå¥½ï¼‰
    ranks = pivot.rank(axis=1, method='average')
    avg_ranks = ranks.mean(axis=0).sort_values()

    # Friedmanæ£€éªŒ
    try:
        stat, p_value = friedmanchisquare(*[pivot[m].dropna() for m in methods])
        print(f"  Friedman test: Ï‡Â²={stat:.2f}, p={p_value:.4f}")
    except:
        p_value = np.nan

    # è®¡ç®—Critical Difference
    # CD = q_Î± * sqrt(k(k+1) / (6N))
    # ä½¿ç”¨Nemenyiè¿‘ä¼¼ï¼šq_0.05 â‰ˆ 2.576 (k=3), 2.850 (k=5)
    q_values = {2: 1.960, 3: 2.576, 4: 2.772, 5: 2.850, 6: 2.936, 7: 3.036, 8: 3.098}
    q_alpha = q_values.get(n_methods, 2.850)  # é»˜è®¤å€¼

    cd_value = q_alpha * np.sqrt(n_methods * (n_methods + 1) / (6 * n_instances))

    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(10, 4))

    y_pos = np.arange(n_methods)
    ax.barh(y_pos, avg_ranks.values, color='steelblue', alpha=0.7)
    ax.set_yticks(y_pos)
    ax.set_yticklabels(avg_ranks.index)
    ax.set_xlabel('Average Rank (lower is better)')
    ax.set_title(f'Critical Difference Diagram - {metric}\nCD={cd_value:.2f} at Î±={alpha}')
    ax.axvline(avg_ranks.values[0] + cd_value, color='red', linestyle='--',
               linewidth=2, label=f'CD={cd_value:.2f}')

    # æ·»åŠ æ¨ªçº¿è¿æ¥ä¸æ˜¾è‘—å·®å¼‚çš„æ–¹æ³•
    for i in range(n_methods):
        for j in range(i + 1, n_methods):
            rank_diff = abs(avg_ranks.iloc[j] - avg_ranks.iloc[i])
            if rank_diff < cd_value:
                # ä¸æ˜¾è‘—å·®å¼‚ï¼Œç”»çº¿
                ax.plot([avg_ranks.iloc[i], avg_ranks.iloc[j]],
                        [i, j], 'k-', linewidth=1, alpha=0.3)

    ax.legend()
    ax.grid(axis='x', alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"  âœ“ Saved Critical Difference diagram: {output_path}")


# ============================================================================
# 2. Type Composition å †å å›¾
# ============================================================================

def summarize_type_composition(all_results, sensors) -> pd.DataFrame:
    """
    ç»Ÿè®¡æ¯ä¸ªæ–¹æ³•å’Œé¢„ç®—ä¸‹é€‰æ‹©çš„ä¼ æ„Ÿå™¨ç±»å‹åˆ†å¸ƒ

    Args:
        all_results: ç»“æœå­—å…¸
        sensors: ä¼ æ„Ÿå™¨åˆ—è¡¨

    Returns:
        DataFrame with columns: method, budget, type, count
    """
    rows = []

    for method_name, method_data in all_results.items():
        budgets_data = method_data.get('budgets', {})

        for budget_key, budget_data in budgets_data.items():
            budget = int(budget_key)
            fold_results = budget_data.get('fold_results', [])

            # ç»Ÿè®¡æ‰€æœ‰foldçš„ç±»å‹ï¼ˆå–å¹³å‡ï¼‰
            type_counts = {}
            valid_folds = 0

            for fold_res in fold_results:
                if not fold_res or not fold_res.get('success', False):
                    continue

                sel_result = fold_res.get('selection_result')
                if sel_result is None:
                    continue

                valid_folds += 1
                selected_ids = sel_result.selected_ids

                for sid in selected_ids:
                    sensor_type = sensors[sid].type_name
                    type_counts[sensor_type] = type_counts.get(sensor_type, 0) + 1

            # å¹³å‡æ¯foldçš„ç±»å‹æ•°é‡
            if valid_folds > 0:
                for sensor_type, count in type_counts.items():
                    avg_count = count / valid_folds
                    rows.append({
                        'method': method_name,
                        'budget': budget,
                        'type': sensor_type,
                        'count': avg_count
                    })

    df = pd.DataFrame(rows)
    print(f"  Summarized type composition: {len(df)} records")
    return df


def plot_type_composition(df: pd.DataFrame, output_path: Path,
                          selected_budgets: List[int] = None):
    """
    ç»˜åˆ¶ä¼ æ„Ÿå™¨ç±»å‹å †å æŸ±çŠ¶å›¾

    Args:
        df: type composition DataFrame
        output_path: è¾“å‡ºè·¯å¾„
        selected_budgets: è¦æ˜¾ç¤ºçš„é¢„ç®—åˆ—è¡¨ï¼ˆNone=å…¨éƒ¨ï¼‰
    """
    if len(df) == 0:
        print("  No type composition data to plot")
        return

    # è¿‡æ»¤é¢„ç®—
    if selected_budgets:
        df = df[df['budget'].isin(selected_budgets)]

    if len(df) == 0:
        return

    # Pivotï¼šè¡Œ=method-budgetï¼Œåˆ—=type
    df['method_budget'] = df['method'] + '\n(k=' + df['budget'].astype(str) + ')'
    pivot = df.pivot_table(index='method_budget', columns='type',
                           values='count', aggfunc='sum', fill_value=0)

    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(12, 6))

    pivot.plot(kind='bar', stacked=True, ax=ax,
               colormap='tab10', width=0.8)

    ax.set_xlabel('Method and Budget')
    ax.set_ylabel('Average Sensor Count')
    ax.set_title('Sensor Type Composition by Method and Budget')
    ax.legend(title='Sensor Type', bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(axis='y', alpha=0.3)

    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"  âœ“ Saved type composition plot: {output_path}")


# ============================================================================
# 3. Spatial Diagnostics å›¾
# ============================================================================

def plot_spatial_diagnostics(geom, Q_pr, selected_sensors,
                             residuals, output_path: Path):
    """
    ç»˜åˆ¶ç©ºé—´è¯Šæ–­å›¾ï¼šå…ˆéªŒæ–¹å·®çƒ­å›¾ + é€‰å€ + Moran's I

    Args:
        geom: å‡ ä½•å¯¹è±¡
        Q_pr: å…ˆéªŒç²¾åº¦çŸ©é˜µ
        selected_sensors: é€‰æ‹©çš„ä¼ æ„Ÿå™¨åˆ—è¡¨ï¼ˆæŸä¸ªæ–¹æ³•å’Œé¢„ç®—ï¼‰
        residuals: æ®‹å·®å‘é‡ (n,)
        output_path: è¾“å‡ºè·¯å¾„
    """
    from inference import SparseFactor, compute_posterior_variance_diagonal
    from evaluation import morans_i

    n = geom.n

    # 1. ä¼°è®¡å…ˆéªŒæ–¹å·®ï¼ˆHutchinsonè¿‘ä¼¼ï¼‰
    print("  Computing prior variance (Hutchinson)...")
    factor = SparseFactor(Q_pr)

    # é‡‡æ ·å°‘é‡probeä¼°è®¡å¯¹è§’æ–¹å·®
    n_probes = 8
    rng = np.random.default_rng(42)
    Z = rng.standard_normal((n, n_probes))
    V = factor.solve(Z)
    diag_var_pr = (Z * V).mean(axis=1)

    # 2. è®¡ç®—Moran's I
    I_stat, I_pval = morans_i(residuals, geom.adjacency,
                              n_permutations=99, rng=rng)

    # 3. ç»˜å›¾
    if geom.mode == "grid2d":
        nx = int(np.sqrt(n))
        ny = nx

        fig, axes = plt.subplots(1, 2, figsize=(14, 6))

        # å·¦å›¾ï¼šå…ˆéªŒæ–¹å·®çƒ­å›¾ + é€‰å€
        var_map = diag_var_pr.reshape(nx, ny)
        im1 = axes[0].imshow(var_map, cmap='YlOrRd', origin='lower')
        axes[0].set_title(f'Prior Variance (CV={diag_var_pr.std() / diag_var_pr.mean():.2%})')
        axes[0].set_xlabel('x (grid)')
        axes[0].set_ylabel('y (grid)')
        plt.colorbar(im1, ax=axes[0], label='Variance')

        # æ ‡è®°é€‰æ‹©çš„ä¼ æ„Ÿå™¨
        if selected_sensors:
            for sensor in selected_sensors:
                center_idx = sensor.idxs[0]  # å–ä¸­å¿ƒç‚¹
                i, j = center_idx // ny, center_idx % ny
                axes[0].plot(j, i, 'b*', markersize=10,
                             markeredgecolor='white', markeredgewidth=0.5)

        # å³å›¾ï¼šæ®‹å·®çƒ­å›¾ + Moran's I
        resid_map = residuals.reshape(nx, ny)
        im2 = axes[1].imshow(resid_map, cmap='RdBu_r', origin='lower',
                             vmin=-np.abs(residuals).max(),
                             vmax=np.abs(residuals).max())
        axes[1].set_title(f"Residuals (Moran's I={I_stat:.3f}, p={I_pval:.3f})")
        axes[1].set_xlabel('x (grid)')
        axes[1].set_ylabel('y (grid)')
        plt.colorbar(im2, ax=axes[1], label='Residual')

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"  âœ“ Saved spatial diagnostics: {output_path}")
    else:
        print(f"  Spatial diagnostics plot not implemented for mode={geom.mode}")


# ============================================================================
# ä¸»å…¥å£ï¼šç”Ÿæˆæ‰€æœ‰ä¸“å®¶å»ºè®®çš„å›¾
# ============================================================================

def generate_expert_plots(all_results, sensors, geom, Q_pr,
                          output_dir: Path, config):
    """
    ç”Ÿæˆä¸“å®¶å»ºè®®ä¸­ç¼ºå¤±çš„ä¸‰å¼ å›¾

    Args:
        all_results: å®Œæ•´ç»“æœå­—å…¸
        sensors: ä¼ æ„Ÿå™¨åˆ—è¡¨
        geom: å‡ ä½•å¯¹è±¡
        Q_pr: å…ˆéªŒç²¾åº¦çŸ©é˜µ
        output_dir: è¾“å‡ºç›®å½•
        config: é…ç½®å¯¹è±¡
    """
    print("\n" + "=" * 70)
    print("Generating Expert-Recommended Plots")
    print("=" * 70)

    curves_dir = output_dir / "curves"
    curves_dir.mkdir(parents=True, exist_ok=True)

    # 1. Critical Difference å›¾ï¼ˆfold-levelï¼‰
    print("\n1. Critical Difference Diagram...")
    df_folds = aggregate_fold_level_results(all_results)

    if len(df_folds) > 0:
        plot_critical_difference_from_folds(
            df_folds,
            metric='expected_loss_gbp',
            output_path=curves_dir / "f7b_critical_difference.png",
            alpha=0.05
        )

    # 2. Type Composition å †å å›¾
    print("\n2. Sensor Type Composition...")
    df_types = summarize_type_composition(all_results, sensors)

    if len(df_types) > 0:
        selected_budgets = [10, 30, 50] if 50 in df_types['budget'].unique() else None
        plot_type_composition(
            df_types,
            output_path=curves_dir / "f3_type_composition.png",
            selected_budgets=selected_budgets
        )

    # 3. Spatial Diagnosticsï¼ˆå–ä¸€ä¸ªä»£è¡¨æ€§caseï¼‰
    # æ‰¾ä¸€ä¸ªæˆåŠŸçš„foldç»“æœ
    for method_name, method_data in all_results.items():
        budgets_data = method_data.get('budgets', {})

        for budget_key, budget_data in budgets_data.items():
            fold_results = budget_data.get('fold_results', [])

            for fold_idx, fold_res in enumerate(fold_results):
                if not fold_res or not fold_res.get('success', False):
                    continue

                # æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„case
                sel_result = fold_res.get('selection_result')

                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„æ®‹å·®
                if 'mu_post' not in fold_res or 'x_true' not in fold_res:
                    continue

                mu_post = fold_res['mu_post']
                x_true = fold_res['x_true']

                # ğŸ”¥ è®¡ç®—å®Œæ•´åŸŸçš„æ®‹å·®ï¼ˆè€Œä¸æ˜¯æµ‹è¯•é›†ï¼‰
                if len(mu_post) == geom.n and len(x_true) == geom.n:
                    residuals = mu_post - x_true
                else:
                    # å¦‚æœåªæœ‰æµ‹è¯•é›†æ•°æ®ï¼Œè·³è¿‡
                    print(f"    Skipping: incomplete posterior data")
                    continue

                if sel_result:
                    selected = [sensors[i] for i in sel_result.selected_ids]

                    try:
                        plot_spatial_diagnostics(
                            geom, Q_pr, selected, residuals,
                            output_path=curves_dir / f"f6_spatial_diagnostics_{method_name}_k{budget_key}.png"
                        )

                        # åªç”»ä¸€ä¸ªå°±å¤Ÿäº†
                        print("\n" + "=" * 70)
                        return
                    except Exception as e:
                        print(f"    Failed to plot spatial diagnostics: {e}")
                        import traceback
                        traceback.print_exc()
                        continue

    print("  Warning: No valid fold results found for spatial diagnostics")
    print("\n" + "=" * 70)


# ============================================================================
# ğŸ”¥ Effect Size Analysis (æ–°å¢æ•ˆåº”é‡åˆ†æ)
# ============================================================================

def compute_cliffs_delta(x: np.ndarray, y: np.ndarray) -> float:
    """
    è®¡ç®— Cliff's Delta æ•ˆåº”é‡

    Cliff's Delta æ˜¯ä¸€ç§éå‚æ•°æ•ˆåº”é‡æµ‹åº¦ï¼ŒèŒƒå›´ [-1, 1]ï¼š
    - Î´ = 0: ä¸¤ç»„æ— å·®å¼‚
    - Î´ = -1: y ä¸­æ‰€æœ‰å€¼éƒ½ä¼˜äº xï¼ˆå¯¹äºè¶Šå°è¶Šå¥½çš„æŒ‡æ ‡ï¼‰
    - Î´ = +1: x ä¸­æ‰€æœ‰å€¼éƒ½ä¼˜äº y

    è§£é‡Šï¼ˆCohen's é£æ ¼ï¼‰ï¼š
    - |Î´| < 0.147: negligible
    - 0.147 â‰¤ |Î´| < 0.330: small
    - 0.330 â‰¤ |Î´| < 0.474: medium
    - |Î´| â‰¥ 0.474: large

    Args:
        x: æ–¹æ³• A çš„ç»“æœæ•°ç»„
        y: æ–¹æ³• B çš„ç»“æœæ•°ç»„

    Returns:
        delta: Cliff's Delta å€¼
    """
    n_x, n_y = len(x), len(y)

    if n_x == 0 or n_y == 0:
        return np.nan

    # è®¡ç®—æ‰€æœ‰é…å¯¹çš„ä¼˜åŠ£å…³ç³»
    dominance = 0
    for xi in x:
        for yi in y:
            if xi < yi:  # x æ›´å¥½ï¼ˆå‡è®¾è¶Šå°è¶Šå¥½ï¼‰
                dominance += 1
            elif xi > yi:  # y æ›´å¥½
                dominance -= 1

    delta = dominance / (n_x * n_y)
    return delta


def interpret_cliffs_delta(delta: float) -> str:
    """è§£é‡Š Cliff's Delta çš„æ•ˆåº”å¤§å°"""
    abs_delta = abs(delta)

    if abs_delta < 0.147:
        return "negligible"
    elif abs_delta < 0.330:
        return "small"
    elif abs_delta < 0.474:
        return "medium"
    else:
        return "large"


def compute_win_rate(x: np.ndarray, y: np.ndarray,
                     lower_is_better: bool = True) -> float:
    """
    è®¡ç®—é…å¯¹èƒœç‡ï¼ˆæ–¹æ³• x ä¼˜äºæ–¹æ³• y çš„æ¯”ä¾‹ï¼‰

    Args:
        x, y: ä¸¤ä¸ªæ–¹æ³•çš„ç»“æœæ•°ç»„
        lower_is_better: æ˜¯å¦è¶Šå°è¶Šå¥½

    Returns:
        win_rate: x èƒœå‡ºçš„æ¯”ä¾‹ [0, 1]
    """
    if len(x) != len(y):
        raise ValueError("Arrays must have same length for pairwise comparison")

    if len(x) == 0:
        return np.nan

    if lower_is_better:
        wins = np.sum(x < y)
    else:
        wins = np.sum(x > y)

    return wins / len(x)


def compute_pairwise_statistics(df_folds: pd.DataFrame,
                                metric: str = 'expected_loss_gbp',
                                lower_is_better: bool = True) -> tuple:
    """
    è®¡ç®—æ‰€æœ‰æ–¹æ³•é—´çš„é…å¯¹ç»Ÿè®¡é‡

    Args:
        df_folds: fold-level DataFrame with columns [method, budget, fold, metric, ...]
        metric: è¦æ¯”è¾ƒçš„æŒ‡æ ‡
        lower_is_better: æŒ‡æ ‡æ˜¯å¦è¶Šå°è¶Šå¥½

    Returns:
        delta_matrix: Cliff's Delta çŸ©é˜µ (n_methods, n_methods)
        winrate_matrix: èƒœç‡çŸ©é˜µ (n_methods, n_methods)
        summary_df: æ±‡æ€» DataFrame
    """
    methods = sorted(df_folds['method'].unique())
    n_methods = len(methods)

    delta_matrix = np.zeros((n_methods, n_methods))
    winrate_matrix = np.zeros((n_methods, n_methods))

    # è®¡ç®—é…å¯¹ç»Ÿè®¡é‡
    for i, method_a in enumerate(methods):
        for j, method_b in enumerate(methods):
            if i == j:
                delta_matrix[i, j] = 0
                winrate_matrix[i, j] = 0.5
                continue

            # è·å–ä¸¤ä¸ªæ–¹æ³•åœ¨æ‰€æœ‰ (budget, fold) å®ä¾‹ä¸Šçš„ç»“æœ
            vals_a = df_folds[df_folds['method'] == method_a][metric].values
            vals_b = df_folds[df_folds['method'] == method_b][metric].values

            # ç¡®ä¿é•¿åº¦ç›¸åŒï¼ˆé…å¯¹æ¯”è¾ƒï¼‰
            min_len = min(len(vals_a), len(vals_b))
            vals_a = vals_a[:min_len]
            vals_b = vals_b[:min_len]

            # Cliff's Deltaï¼ˆå¯¹äºè¶Šå°è¶Šå¥½çš„æŒ‡æ ‡ï¼Œè´Ÿå€¼è¡¨ç¤º a æ›´å¥½ï¼‰
            if lower_is_better:
                delta = compute_cliffs_delta(vals_b, vals_a)  # åè½¬ï¼Œè®©è´Ÿå€¼è¡¨ç¤º a æ›´å¥½
            else:
                delta = compute_cliffs_delta(vals_a, vals_b)

            delta_matrix[i, j] = delta

            # èƒœç‡ï¼ˆa ä¼˜äº b çš„æ¯”ä¾‹ï¼‰
            winrate = compute_win_rate(vals_a, vals_b, lower_is_better)
            winrate_matrix[i, j] = winrate

    # åˆ›å»ºæ±‡æ€» DataFrame
    summary_rows = []
    for i, method_a in enumerate(methods):
        for j, method_b in enumerate(methods):
            if i != j:
                summary_rows.append({
                    'Method A': method_a,
                    'Method B': method_b,
                    'Cliff_Delta': delta_matrix[i, j],
                    'Effect_Size': interpret_cliffs_delta(delta_matrix[i, j]),
                    'Win_Rate': winrate_matrix[i, j],
                    'A_Better': winrate_matrix[i, j] > 0.5
                })

    summary_df = pd.DataFrame(summary_rows)

    return delta_matrix, winrate_matrix, summary_df


def plot_effect_size_heatmaps(delta_matrix: np.ndarray,
                              winrate_matrix: np.ndarray,
                              methods: list,
                              output_path: Path,
                              metric_name: str = 'Expected Loss'):
    """
    ç»˜åˆ¶æ•ˆåº”é‡åŒçƒ­åŠ›å›¾ï¼ˆCliff's Delta + èƒœç‡ï¼‰

    Args:
        delta_matrix: Cliff's Delta çŸ©é˜µ
        winrate_matrix: èƒœç‡çŸ©é˜µ
        methods: æ–¹æ³•åç§°åˆ—è¡¨
        output_path: è¾“å‡ºè·¯å¾„
        metric_name: æŒ‡æ ‡åç§°ï¼ˆç”¨äºæ ‡é¢˜ï¼‰
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

    n_methods = len(methods)

    # === å·¦å›¾ï¼šCliff's Delta ===
    im1 = ax1.imshow(delta_matrix, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')
    ax1.set_xticks(range(n_methods))
    ax1.set_yticks(range(n_methods))
    ax1.set_xticklabels(methods, rotation=45, ha='right')
    ax1.set_yticklabels(methods)
    ax1.set_title(f"Cliff's Delta Effect Size\n{metric_name}\n"
                  "(negative = row method better)", fontsize=12)
    ax1.set_xlabel('Method B (compared to)', fontsize=10)
    ax1.set_ylabel('Method A (baseline)', fontsize=10)

    # æ·»åŠ æ•°å€¼å’Œæ•ˆåº”å¤§å°æ ‡æ³¨
    for i in range(n_methods):
        for j in range(n_methods):
            delta_val = delta_matrix[i, j]
            effect = interpret_cliffs_delta(delta_val)

            # æ–‡æœ¬é¢œè‰²ï¼ˆæ·±è‰²èƒŒæ™¯ç”¨ç™½è‰²ï¼Œæµ…è‰²èƒŒæ™¯ç”¨é»‘è‰²ï¼‰
            text_color = 'white' if abs(delta_val) > 0.5 else 'black'

            # ä¸»æ•°å€¼
            ax1.text(j, i, f'{delta_val:.2f}',
                    ha="center", va="center", color=text_color,
                    fontsize=9, fontweight='bold')

            # æ•ˆåº”å¤§å°æ³¨é‡Šï¼ˆå¯¹è§’çº¿é™¤å¤–ï¼‰
            if i != j and abs(delta_val) >= 0.147:  # åªæ ‡æ³¨énegligibleçš„
                ax1.text(j, i + 0.3, f'({effect[0]})',
                        ha="center", va="center", color=text_color,
                        fontsize=7, style='italic')

    # é¢œè‰²æ¡
    cbar1 = plt.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)
    cbar1.set_label("Cliff's Delta\n(negative = A better)", fontsize=10)

    # === å³å›¾ï¼šèƒœç‡ ===
    im2 = ax2.imshow(winrate_matrix, cmap='RdYlGn', vmin=0, vmax=1, aspect='auto')
    ax2.set_xticks(range(n_methods))
    ax2.set_yticks(range(n_methods))
    ax2.set_xticklabels(methods, rotation=45, ha='right')
    ax2.set_yticklabels(methods)
    ax2.set_title(f"Pairwise Win Rate\n{metric_name}\n"
                  "(row method wins over column method)", fontsize=12)
    ax2.set_xlabel('Method B (opponent)', fontsize=10)
    ax2.set_ylabel('Method A (player)', fontsize=10)

    # æ·»åŠ æ•°å€¼æ ‡æ³¨
    for i in range(n_methods):
        for j in range(n_methods):
            winrate_val = winrate_matrix[i, j]

            # æ–‡æœ¬é¢œè‰²
            if winrate_val > 0.75:
                text_color = 'white'
            elif winrate_val < 0.25:
                text_color = 'white'
            else:
                text_color = 'black'

            # ä¸»æ•°å€¼
            ax2.text(j, i, f'{winrate_val:.0%}',
                    ha="center", va="center", color=text_color,
                    fontsize=10, fontweight='bold')

            # æ˜¾è‘—æ ‡è®°ï¼ˆèƒœç‡ > 60% æˆ– < 40%ï¼‰
            if i != j:
                if winrate_val > 0.6:
                    marker = 'â†‘'  # A æ˜¾è‘—æ›´å¥½
                elif winrate_val < 0.4:
                    marker = 'â†“'  # B æ˜¾è‘—æ›´å¥½
                else:
                    marker = 'â‰ˆ'  # æ¥è¿‘

                ax2.text(j, i + 0.35, marker,
                        ha="center", va="center", color=text_color,
                        fontsize=12)

    # é¢œè‰²æ¡
    cbar2 = plt.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)
    cbar2.set_label('Win Rate\n(A wins over B)', fontsize=10)

    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"  âœ“ Saved effect size heatmaps: {output_path}")


def generate_pairwise_comparison_table(summary_df: pd.DataFrame,
                                       output_path: Path,
                                       top_k: int = 20):
    """
    ç”Ÿæˆé…å¯¹æ¯”è¾ƒè¡¨ï¼ˆæ˜¾ç¤ºæœ€å¤§æ•ˆåº”é‡çš„æ¯”è¾ƒï¼‰

    Args:
        summary_df: é…å¯¹ç»Ÿè®¡æ±‡æ€» DataFrame
        output_path: è¾“å‡ºè·¯å¾„
        top_k: æ˜¾ç¤ºå‰ k å¯¹æ¯”è¾ƒ
    """
    # æŒ‰ Cliff's Delta ç»å¯¹å€¼æ’åº
    summary_df['Abs_Delta'] = summary_df['Cliff_Delta'].abs()
    top_comparisons = summary_df.nlargest(top_k, 'Abs_Delta')

    # æ ¼å¼åŒ–æ˜¾ç¤º
    display_df = top_comparisons[[
        'Method A', 'Method B', 'Cliff_Delta', 'Effect_Size', 'Win_Rate', 'A_Better'
    ]].copy()

    display_df['Cliff_Delta'] = display_df['Cliff_Delta'].map('{:.3f}'.format)
    display_df['Win_Rate'] = display_df['Win_Rate'].map('{:.1%}'.format)

    # ä¿å­˜ä¸º CSV
    display_df.to_csv(output_path, index=False)
    print(f"  âœ“ Saved pairwise comparison table: {output_path}")

    return display_df



if __name__ == "__main__":
    print("Visualization helpers loaded successfully")