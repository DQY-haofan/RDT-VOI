"""
Main experimental script for RDT-VoI simulation (CLI version with parallel support)
æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šé…ç½®æ–‡ä»¶å’Œè¾“å‡ºç›®å½•ï¼Œé›†æˆå¹¶è¡Œå¤„ç†

# åœºæ™¯Aï¼ˆä¸²è¡Œï¼‰
python main.py --scenario A

# åœºæ™¯Bï¼ˆå¹¶è¡Œï¼Œ5 workersï¼‰
python main.py -s B --parallel --workers 5

# å¿«é€Ÿæµ‹è¯•ï¼ˆå¹¶è¡Œï¼‰
python main.py -s A --quick-test --parallel

# è‡ªå®šä¹‰é…ç½®
python main.py --config my_config.yaml --parallel

"""

from pathlib import Path
from datetime import datetime
import json
import pickle
import sys
import warnings
import numpy as np
import pandas as pd
import argparse
from matplotlib import pyplot as plt
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp
import time

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

from config import load_config, load_scenario_config
from geometry import build_grid2d_geometry
from spatial_field import build_prior, sample_gmrf, build_prior_with_ddi
from sensors import generate_sensor_pool
from inference import compute_posterior, compute_posterior_variance_diagonal
from sensors import get_observation

from method_wrappers import get_selection_method, get_available_methods
from evaluation import spatial_block_cv, compute_metrics, morans_i

from visualization import (
    setup_style,
    generate_all_visualizations_v2,
aggregate_results_for_visualization

)


class NumpyEncoder(json.JSONEncoder):
    """å¤„ç†numpyç±»å‹çš„JSON encoder"""
    def default(self, obj):
        if isinstance(obj, np.bool_):
            return bool(obj)
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super(NumpyEncoder, self).default(obj)


def parse_arguments():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(
        description='RDT-VoI Simulation Framework',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # ä½¿ç”¨åœºæ™¯Aé…ç½®
  python main.py --scenario A
  
  # ä½¿ç”¨åœºæ™¯Bé…ç½®ï¼ŒæŒ‡å®šè¾“å‡ºç›®å½•
  python main.py --scenario B --output results/scenario_B
  
  # å¿«é€Ÿæµ‹è¯•è¿è¡Œ
  python main.py -s A --quick-test
  
  # è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
  python main.py --config path/to/custom.yaml
  
  # å¹¶è¡Œå¤„ç†ï¼ˆ5ä¸ªworkerï¼‰
  python main.py -s A --parallel --workers 5
        """
    )

    # ä¸»è¦å‚æ•°
    parser.add_argument(
        '-s', '--scenario',
        type=str,
        choices=['A', 'B', 'a', 'b'],
        default=None,
        help='åœºæ™¯ç±»å‹ (A=é«˜é£é™©, B=ç®—åŠ›/é²æ£’æ€§) - ä¼˜å…ˆçº§é«˜äº --config'
    )

    parser.add_argument(
        '-c', '--config',
        type=str,
        default=None,
        help='è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆä»…åœ¨æœªæŒ‡å®š --scenario æ—¶ä½¿ç”¨ï¼‰'
    )

    parser.add_argument(
        '-o', '--output',
        type=str,
        default=None,
        help='è¾“å‡ºæ ¹ç›®å½• (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–)'
    )

    # å¯é€‰è¦†ç›–å‚æ•°
    parser.add_argument(
        '--seed',
        type=int,
        default=None,
        help='éšæœºç§å­ (è¦†ç›–é…ç½®æ–‡ä»¶)'
    )

    parser.add_argument(
        '--budgets',
        type=int,
        nargs='+',
        default=None,
        help='é¢„ç®—åˆ—è¡¨ (è¦†ç›–é…ç½®æ–‡ä»¶), ä¾‹å¦‚: --budgets 5 10 20'
    )

    parser.add_argument(
        '--methods',
        type=str,
        nargs='+',
        default=None,
        help='è¦è¿è¡Œçš„æ–¹æ³• (è¦†ç›–é…ç½®æ–‡ä»¶), ä¾‹å¦‚: --methods greedy_mi greedy_evi'
    )

    # ğŸ”¥ å¹¶è¡Œå¤„ç†é€‰é¡¹
    parser.add_argument(
        '--parallel',
        action='store_true',
        help='å¯ç”¨å¹¶è¡Œå¤„ç†ï¼ˆæ˜¾è‘—åŠ é€ŸCVæŠ˜å ï¼‰'
    )

    parser.add_argument(
        '--workers',
        type=int,
        default=None,
        help='å¹¶è¡Œworkeræ•°é‡ï¼ˆé»˜è®¤ï¼šCPUæ ¸å¿ƒæ•°-1ï¼‰'
    )

    # æµ‹è¯•å’Œè°ƒè¯•é€‰é¡¹
    parser.add_argument(
        '--quick-test',
        action='store_true',
        help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ (å°ç½‘æ ¼, å°‘é¢„ç®—, å°‘fold)'
    )

    parser.add_argument(
        '--skip-viz',
        action='store_true',
        help='è·³è¿‡å¯è§†åŒ–ç”Ÿæˆ (ä»…è¿è¡Œå®éªŒ)'
    )

    parser.add_argument(
        '--viz-only',
        action='store_true',
        help='ä»…ç”Ÿæˆå¯è§†åŒ– (åŠ è½½å·²æœ‰ç»“æœ)'
    )

    parser.add_argument(
        '--results-file',
        type=str,
        default=None,
        help='å·²æœ‰ç»“æœæ–‡ä»¶è·¯å¾„ (ç”¨äº --viz-only)'
    )

    # è¯¦ç»†ç¨‹åº¦
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='è¯¦ç»†è¾“å‡ºæ¨¡å¼'
    )

    parser.add_argument(
        '-q', '--quiet',
        action='store_true',
        help='é™é»˜æ¨¡å¼ï¼ˆæœ€å°‘è¾“å‡ºï¼‰'
    )

    return parser.parse_args()


def detect_scenario_from_config(cfg) -> str:
    """ä»é…ç½®è‡ªåŠ¨æ£€æµ‹åœºæ™¯ç±»å‹"""
    exp_name = cfg.experiment.name.lower()
    if 'highstakes' in exp_name or 'high_stakes' in exp_name or '_a_' in exp_name:
        return 'A'
    elif 'proxy' in exp_name or 'compute' in exp_name or '_b_' in exp_name:
        return 'B'

    ddi = getattr(cfg.decision, 'target_ddi', 0.0)
    fn_fp_ratio = cfg.decision.L_FN_gbp / cfg.decision.L_FP_gbp if cfg.decision.L_FP_gbp > 0 else 1.0

    if ddi >= 0.2 or fn_fp_ratio > 10:
        return 'A'
    elif ddi < 0.15 or fn_fp_ratio < 5:
        return 'B'

    print("  âš ï¸  Cannot determine scenario, defaulting to A (high-stakes)")
    return 'A'


def create_output_dir_from_config(cfg, config_path: str, custom_output: str = None) -> Path:
    """æ ¹æ®é…ç½®æ–‡ä»¶ååˆ›å»ºè¾“å‡ºç›®å½•"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ä»é…ç½®æ–‡ä»¶åæå–åœºæ™¯æ ‡è¯†
    config_name = Path(config_path).stem

    # ç§»é™¤ "config_" å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
    if config_name.startswith('config_'):
        scenario_name = config_name[7:]
    else:
        scenario_name = config_name

    # ç¡®å®šè¾“å‡ºæ ¹ç›®å½•
    if custom_output:
        base_dir = Path(custom_output)
    else:
        base_dir = Path(cfg.experiment.output_dir)

    # åˆ›å»ºå±‚çº§ç›®å½•ç»“æ„
    output_dir = base_dir / f"scenario_{scenario_name}" / f"exp_{timestamp}"
    output_dir.mkdir(parents=True, exist_ok=True)

    # åˆ›å»ºå­ç›®å½•
    (output_dir / "curves").mkdir(exist_ok=True)
    (output_dir / "diagnostics").mkdir(exist_ok=True)
    (output_dir / "plots").mkdir(exist_ok=True)

    # ä¿å­˜é…ç½®å‰¯æœ¬
    cfg.save_to(output_dir)

    # ä¿å­˜ç¯å¢ƒä¿¡æ¯
    import subprocess
    try:
        env_info = subprocess.check_output(['pip', 'freeze']).decode()
        with open(output_dir / "environment.txt", 'w', encoding='utf-8') as f:
            f.write(env_info)
    except:
        pass

    # ä¿å­˜è¿è¡Œå‘½ä»¤
    with open(output_dir / "run_command.txt", 'w', encoding='utf-8') as f:
        f.write(' '.join(sys.argv))

    return output_dir


def apply_quick_test_overrides(cfg):
    """åº”ç”¨å¿«é€Ÿæµ‹è¯•æ¨¡å¼çš„è¦†ç›–"""
    print("\n  ğŸš€ Quick test mode enabled:")

    # å°ç½‘æ ¼
    cfg.geometry.nx = 10
    cfg.geometry.ny = 10
    print(f"    â†’ Grid: {cfg.geometry.nx}Ã—{cfg.geometry.ny}")

    # å°‘é¢„ç®—
    cfg.selection.budgets = [3, 5]
    print(f"    â†’ Budgets: {cfg.selection.budgets}")

    # å°‘fold
    cfg.cv.k_folds = 2
    print(f"    â†’ CV folds: {cfg.cv.k_folds}")

    # å‡å°‘é‡‡æ ·
    cfg.evi.monte_carlo_samples = 8
    print(f"    â†’ MC samples: {cfg.evi.monte_carlo_samples}")

    return cfg


# ============================================================================
# ğŸ”¥ å¹¶è¡Œå¤„ç†å‡½æ•°ï¼ˆä»æ—§ç‰ˆç§»æ¤ï¼‰
# ============================================================================

# main.py ä¸­çš„ run_single_fold_worker å‡½æ•°
# åœ¨åŸæœ‰åŸºç¡€ä¸Šä¿®æ”¹ä»¥ä¸‹éƒ¨åˆ†ï¼ˆçº¦ç¬¬850-950è¡Œï¼‰


def run_single_fold_worker(fold_data: dict) -> dict:
    """
    âœ… ä¿®å¤ç‰ˆï¼šç»Ÿä¸€ROIè®¡ç®— + Domain Scaling

    å…³é”®æ”¹è¿›ï¼š
    1. æ­£ç¡®åº”ç”¨ domain scalingï¼ˆæµ‹è¯•é›†æŸå¤± â†’ å…¨åŸŸæŸå¤±ï¼‰
    2. âš ï¸ Scenario A æ·»åŠ  near-threshold å­é›†è¯„ä¼°
    3. âš ï¸ Scenario B è®°å½•è¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡
    """
    import time
    import warnings
    import numpy as np
    from inference import compute_posterior, compute_posterior_variance_diagonal, SparseFactor
    from sensors import get_observation
    from evaluation import compute_metrics, morans_i
    from decision import expected_loss

    # è§£åŒ…æ•°æ®
    train_idx = fold_data['train_idx']
    test_idx = fold_data['test_idx']
    selection_method = fold_data['selection_method']
    k = fold_data['k']
    Q_pr = fold_data['Q_pr']
    mu_pr = fold_data['mu_pr']
    x_true = fold_data['x_true']
    sensors = fold_data['sensors']
    decision_config = fold_data['decision_config']
    geom = fold_data['geom']
    rng = np.random.default_rng(fold_data['rng_seed'])

    # ğŸ”¥ ä»configè¯»å–æ˜¯å¦å¯ç”¨domain scaling
    enable_scaling = fold_data.get('enable_domain_scaling', True)

    # ğŸ”¥ æ£€æµ‹åœºæ™¯ç±»å‹ï¼ˆé€šè¿‡ DDI æˆ–é…ç½®åç§°ï¼‰
    scenario = fold_data.get('scenario', 'A')  # é»˜è®¤ A

    try:
        # ====================================================================
        # 1. è®¡ç®—å…ˆéªŒæŸå¤±ï¼ˆç”¨äºROIï¼‰- ä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦
        # ====================================================================
        t_prior_start = time.time()
        tau = decision_config.get_threshold(mu_pr)
        factor_pr = SparseFactor(Q_pr)
        var_pr_test = compute_posterior_variance_diagonal(factor_pr, test_idx)
        sigma_pr_test = np.sqrt(np.maximum(var_pr_test, 1e-12))

        prior_loss_test = expected_loss(
            mu_pr[test_idx], sigma_pr_test, decision_config,
            test_indices=np.arange(len(test_idx)), tau=tau
        )

        # ğŸ”¥ Domain Scalingï¼ˆæ ¸å¿ƒä¿®å¤ï¼Œä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦ï¼‰
        if enable_scaling:
            N_domain = geom.n
            N_test = len(test_idx)
            scale_factor = N_domain / N_test
            prior_loss_scaled = prior_loss_test * scale_factor
        else:
            prior_loss_scaled = prior_loss_test
            scale_factor = 1.0

        prior_time = time.time() - t_prior_start

        # ====================================================================
        # 2. ä¼ æ„Ÿå™¨é€‰æ‹© - ä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦
        # ====================================================================
        t_sel_start = time.time()
        selection_result = selection_method(sensors, k, Q_pr, mu_pr)
        selection_time = time.time() - t_sel_start

        selected_sensors = [sensors[i] for i in selection_result.selected_ids]
        sensor_cost = selection_result.total_cost

        # ====================================================================
        # 3. ç”Ÿæˆè§‚æµ‹ + è®¡ç®—åéªŒ - ä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦
        # ====================================================================
        y, H, R = get_observation(x_true, selected_sensors, rng)

        t_inf_start = time.time()
        mu_post, factor_post = compute_posterior(Q_pr, mu_pr, H, R, y)
        inference_time = time.time() - t_inf_start

        var_post_test = compute_posterior_variance_diagonal(factor_post, test_idx)
        sigma_post_test = np.sqrt(np.maximum(var_post_test, 1e-12))
        sigma_post = np.zeros(len(mu_post))
        sigma_post[test_idx] = sigma_post_test

        # ====================================================================
        # 4. åŸºç¡€æŒ‡æ ‡ - ä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦
        # ====================================================================
        metrics = compute_metrics(mu_post, sigma_post, x_true, test_idx, decision_config)
        posterior_loss_test = metrics['expected_loss_gbp']

        if enable_scaling:
            posterior_loss_scaled = posterior_loss_test * scale_factor
        else:
            posterior_loss_scaled = posterior_loss_test

        # ğŸ”¥ ä¿®å¤åçš„ROIè®¡ç®—
        savings_scaled = prior_loss_scaled - posterior_loss_scaled

        if sensor_cost > 0:
            roi = (savings_scaled - sensor_cost) / sensor_cost
            cost_efficiency = savings_scaled / sensor_cost
        else:
            roi = np.inf if savings_scaled > 0 else 0.0
            cost_efficiency = np.inf if savings_scaled > 0 else 0.0

        # ====================================================================
        # 5. âš ï¸ Scenario A ç‰¹æœ‰ï¼šNear-threshold å­é›†è¯„ä¼°
        # ====================================================================
        near_threshold_metrics = {}
        if scenario == 'A':
            try:
                gaps_prior = np.abs(mu_pr[test_idx] - tau)
                near_mask = gaps_prior <= 1.0 * sigma_pr_test

                if near_mask.sum() > 0:
                    prior_loss_near = expected_loss(
                        mu_pr[test_idx][near_mask],
                        sigma_pr_test[near_mask],
                        decision_config,
                        test_indices=np.arange(near_mask.sum()),
                        tau=tau
                    )

                    posterior_loss_near = expected_loss(
                        mu_post[test_idx][near_mask],
                        sigma_post_test[near_mask],
                        decision_config,
                        test_indices=np.arange(near_mask.sum()),
                        tau=tau
                    )

                    if enable_scaling:
                        prior_loss_near *= scale_factor
                        posterior_loss_near *= scale_factor

                    savings_near = prior_loss_near - posterior_loss_near
                    roi_near = (savings_near - sensor_cost) / sensor_cost if sensor_cost > 0 else 0.0

                    near_threshold_metrics = {
                        'n_near_threshold': int(near_mask.sum()),
                        'fraction_near_threshold': float(near_mask.sum() / len(test_idx)),
                        'prior_loss_near_threshold': float(prior_loss_near),
                        'posterior_loss_near_threshold': float(posterior_loss_near),
                        'savings_near_threshold': float(savings_near),
                        'roi_near_threshold': float(roi_near)
                    }
            except Exception as e:
                warnings.warn(f"Near-threshold evaluation failed: {e}")

        # ====================================================================
        # 6. è®°å½•å®Œæ•´æŒ‡æ ‡ - ä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦
        # ====================================================================
        metrics.update({
            'roi': float(roi),
            'cost_efficiency': float(cost_efficiency),
            'prior_loss_gbp': float(prior_loss_scaled),
            'posterior_loss_gbp': float(posterior_loss_scaled),
            'savings_gbp': float(savings_scaled),
            'total_cost': float(sensor_cost),
            'prior_loss_test_only': float(prior_loss_test),
            'domain_scale_factor': float(scale_factor),
            **near_threshold_metrics  # âš ï¸ Scenario A æ‰æœ‰æ•°æ®
        })

        # ====================================================================
        # 7. DDIç»Ÿè®¡ - ä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦
        # ====================================================================
        try:
            from spatial_field import compute_ddi
            ddi_test = compute_ddi(mu_post[test_idx], sigma_post_test, tau, k=1.0)
            metrics['ddi_test'] = float(ddi_test)

            sample_size = min(200, len(mu_pr))
            sample_idx = rng.choice(len(mu_pr), size=sample_size, replace=False)
            var_pr_sample = compute_posterior_variance_diagonal(factor_pr, sample_idx)
            sigma_pr_sample = np.sqrt(np.maximum(var_pr_sample, 1e-12))
            ddi_prior = compute_ddi(mu_pr[sample_idx], sigma_pr_sample, tau, k=1.0)
            metrics['ddi_prior'] = float(ddi_prior)
        except Exception as e:
            warnings.warn(f"DDI computation failed: {e}")
            metrics['ddi_test'] = np.nan
            metrics['ddi_prior'] = np.nan

        # ====================================================================
        # 8. âš ï¸ Scenario A ç‰¹æœ‰ï¼šè¡ŒåŠ¨å—é™è¯„ä¼°
        # ====================================================================
        if scenario == 'A' and hasattr(decision_config, 'K_action') and decision_config.K_action is not None:
            try:
                from scipy.stats import norm
                K_action = decision_config.K_action
                p_failure = 1.0 - norm.cdf((tau - mu_post[test_idx]) / np.maximum(sigma_post_test, 1e-12))

                if K_action < len(test_idx):
                    top_k_local = np.argsort(p_failure)[-K_action:]
                else:
                    top_k_local = np.arange(len(test_idx))

                constrained_risks = np.zeros(len(test_idx))
                for i in range(len(test_idx)):
                    global_idx = test_idx[i]
                    if i in top_k_local:
                        if x_true[global_idx] > tau:
                            constrained_risks[i] = decision_config.L_TP_gbp
                        else:
                            constrained_risks[i] = decision_config.L_FP_gbp
                    else:
                        if x_true[global_idx] > tau:
                            constrained_risks[i] = decision_config.L_FN_gbp
                        else:
                            constrained_risks[i] = decision_config.L_TN_gbp

                constrained_loss = constrained_risks.mean()
                true_exceed = x_true[test_idx] > tau
                if true_exceed.sum() > 0:
                    hit_rate = np.sum(np.isin(top_k_local, np.where(true_exceed)[0])) / true_exceed.sum()
                else:
                    hit_rate = 1.0

                metrics['action_K'] = int(K_action)
                metrics['action_constrained_loss'] = float(constrained_loss)
                metrics['action_regret'] = float(constrained_loss - posterior_loss_test)
                metrics['action_hit_rate'] = float(hit_rate)
            except Exception as e:
                warnings.warn(f"Action-constrained evaluation failed: {e}")

        # ====================================================================
        # 9. Moran's I - ä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦
        # ====================================================================
        residuals = mu_post - x_true
        if geom.adjacency is not None:
            try:
                I_stat, I_pval = morans_i(
                    residuals[test_idx],
                    geom.adjacency[test_idx][:, test_idx],
                    n_permutations=999, rng=rng
                )
                metrics['morans_i'] = float(I_stat)
                metrics['morans_pval'] = float(I_pval)
            except Exception as e:
                warnings.warn(f"Moran's I computation failed: {e}")

        # ====================================================================
        # 10. æ—¶é—´ç»Ÿè®¡ - ä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦
        # ====================================================================
        metrics['prior_computation_time_sec'] = float(prior_time)
        metrics['selection_time_sec'] = float(selection_time)
        metrics['inference_time_sec'] = float(inference_time)
        metrics['total_time_sec'] = float(prior_time + selection_time + inference_time)

        # ====================================================================
        # 11. ä¼ æ„Ÿå™¨è¯Šæ–­ - ä¸¤ä¸ªåœºæ™¯éƒ½éœ€è¦
        # ====================================================================
        metrics['n_selected'] = len(selection_result.selected_ids)

        type_counts = {}
        for sid in selection_result.selected_ids:
            stype = sensors[sid].type_name
            type_counts[stype] = type_counts.get(stype, 0) + 1
        metrics['type_counts'] = {k: int(v) for k, v in type_counts.items()}

        selected_costs = [sensors[i].cost for i in selection_result.selected_ids]
        metrics['cost_mean'] = float(np.mean(selected_costs))
        metrics['cost_std'] = float(np.std(selected_costs))

        if 'coverage_90' in metrics:
            metrics['coverage_90'] = float(np.clip(metrics['coverage_90'], 0.0, 1.0))

        return {
            'success': True,
            'metrics': metrics,
            'selection_result': selection_result,
            'mu_post': mu_post,
            'sigma_post': sigma_post,
            'residuals': mu_post[test_idx] - x_true[test_idx],
            'test_idx': test_idx,
            'tau': tau,
            'prior_loss': prior_loss_scaled,
            'posterior_loss': posterior_loss_scaled,
            'savings': savings_scaled,
            'roi': roi
        }

    except Exception as e:
        import traceback
        return {
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc(),
        }

def run_method_evaluation(method_name: str, cfg, geom, Q_pr, mu_pr,
                          x_true, sensors, test_idx_global=None,
                          use_parallel=False, n_workers=None, verbose=True) -> dict:
    """
    è¿è¡Œæ–¹æ³•è¯„ä¼°ï¼ˆæ”¯æŒå¹¶è¡Œå¤„ç†ï¼‰

    Args:
        use_parallel: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œå¤„ç†
        n_workers: å¹¶è¡Œworkeræ•°é‡ï¼ˆNone=è‡ªåŠ¨æ£€æµ‹ï¼‰
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
    """
    if verbose:
        print(f"\n{'=' * 70}")
        print(f"  Method: {method_name.upper()}")
        if use_parallel:
            print(f"  Mode: PARALLEL ({n_workers or 'auto'} workers)")
        else:
            print(f"  Mode: SEQUENTIAL")
        print(f"{'=' * 70}")

    rng = cfg.get_rng()

    # åˆ›å»ºé€‰æ‹©æ–¹æ³•wrapper
    try:
        selection_method = get_selection_method(
            method_name=method_name,
            config=cfg,
            geom=geom,
            x_true=x_true,
            test_idx=test_idx_global
        )
    except Exception as e:
        if verbose:
            print(f"  âœ— Failed to create method wrapper: {e}")
        raise

    # ç”ŸæˆCV folds
    buffer_width = cfg.cv.buffer_width_multiplier * cfg.prior.correlation_length
    folds = spatial_block_cv(
        geom.coords, cfg.cv.k_folds, buffer_width,
        cfg.cv.block_strategy, rng
    )

    if verbose:
        for fold_idx, (train_idx, test_idx) in enumerate(folds):
            print(f"  Fold {fold_idx + 1}: train={len(train_idx)}, test={len(test_idx)}")

    results = {
        'budgets': {},
        'method_name': method_name,
        'n_folds': len(folds)
    }
    # ğŸ”¥ æ£€æµ‹åœºæ™¯ç±»å‹
    if hasattr(cfg.decision, 'target_ddi'):
        if cfg.decision.target_ddi >= 0.20:
            scenario = 'A'  # High-stakes
        else:
            scenario = 'B'  # Compute/robustness
    else:
        scenario = 'A'  # é»˜è®¤

    enable_scaling = getattr(cfg.metrics, 'scale_savings_to_domain', True) if hasattr(cfg, 'metrics') else True

    # éå†budgets
    for k in cfg.selection.budgets:
        if verbose:
            print(f"\n  Budget k={k}")
            print(f"  {'-' * 50}")

        budget_results = {
            'fold_results': [],
            'fold_metrics': []
        }

        # ğŸ”¥ å‡†å¤‡æ‰€æœ‰foldçš„æ•°æ®
        fold_data_list = []
        for fold_idx, (train_idx, test_idx) in enumerate(folds):
            fold_data = {
                'train_idx': train_idx,
                'test_idx': test_idx,
                'selection_method': selection_method,
                'k': k,
                'Q_pr': Q_pr,
                'mu_pr': mu_pr,
                'x_true': x_true,
                'sensors': sensors,
                'decision_config': cfg.decision,
                'geom': geom,
                'rng_seed': rng.integers(0, 2 ** 31),
                'enable_domain_scaling': enable_scaling,
                'scenario': scenario,  # ğŸ”¥ æ–°å¢
                'verbose': verbose
            }
            fold_data_list.append((fold_idx, fold_data))
        # ğŸ”¥ å¹¶è¡Œæˆ–ä¸²è¡Œæ‰§è¡Œ
        if use_parallel and len(fold_data_list) > 1:
            # å¹¶è¡Œæ¨¡å¼
            if n_workers is None:
                n_workers = max(1, mp.cpu_count() - 1)

            if verbose:
                print(f"    Running {len(fold_data_list)} folds in parallel "
                      f"with {n_workers} workers...")

            with ProcessPoolExecutor(max_workers=n_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_fold = {
                    executor.submit(run_single_fold_worker, fold_data): fold_idx
                    for fold_idx, fold_data in fold_data_list
                }

                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_fold):
                    fold_idx = future_to_fold[future]
                    try:
                        fold_result = future.result()
                        budget_results['fold_results'].append(fold_result)

                        if fold_result['success']:
                            metrics = fold_result['metrics']
                            budget_results['fold_metrics'].append(metrics)
                            if verbose:
                                print(f"    Fold {fold_idx + 1}: "
                                      f"RMSE={metrics['rmse']:.3f}, "
                                      f"Loss=Â£{metrics['expected_loss_gbp']:.0f}")
                        else:
                            if verbose:
                                print(f"    Fold {fold_idx + 1}: "
                                      f"âœ— {fold_result.get('error', 'unknown')}")
                    except Exception as e:
                        if verbose:
                            print(f"    Fold {fold_idx + 1}: âœ— Exception: {e}")
                        budget_results['fold_results'].append({
                            'success': False,
                            'error': str(e)
                        })
        else:
            # ä¸²è¡Œæ¨¡å¼
            for fold_idx, fold_data in fold_data_list:
                if verbose:
                    print(f"    Fold {fold_idx + 1}/{len(folds)}: "
                          f"train={len(fold_data['train_idx'])}, "
                          f"test={len(fold_data['test_idx'])}")

                try:
                    fold_result = run_single_fold_worker(fold_data)
                    budget_results['fold_results'].append(fold_result)

                    if fold_result['success']:
                        metrics = fold_result['metrics']
                        budget_results['fold_metrics'].append(metrics)
                        if verbose:
                            print(f"        RMSE={metrics['rmse']:.3f}, "
                                  f"Loss=Â£{metrics['expected_loss_gbp']:.0f}, "
                                  f"Coverage={metrics['coverage_90'] * 100:.2f}%")
                    else:
                        if verbose:
                            print(f"        âœ— FAILED: "
                                  f"{fold_result.get('error', 'unknown error')}")
                except Exception as e:
                    if verbose:
                        print(f"        âœ— Exception: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    budget_results['fold_results'].append({
                        'success': False,
                        'error': str(e),
                        'traceback': traceback.format_exc()
                    })

        # è®¡ç®—budgetçº§åˆ«çš„ç»Ÿè®¡
        if budget_results['fold_metrics']:
            n_folds = len(budget_results['fold_metrics'])
            aggregated = {}

            for key in budget_results['fold_metrics'][0].keys():
                if key in ['z_scores', 'n_test', 'n_selected', 'type_counts']:
                    continue

                values = [m[key] for m in budget_results['fold_metrics'] if key in m]
                if values and all(isinstance(v, (int, float)) for v in values):
                    aggregated[key] = {
                        'mean': np.mean(values),
                        'std': np.std(values),
                        'values': values
                    }

            budget_results['aggregated'] = aggregated

            if verbose:
                print(f"\n    Summary (n={n_folds} folds):")
                for metric in ['expected_loss_gbp', 'rmse']:
                    if metric in aggregated:
                        stats = aggregated[metric]
                        if 'loss' in metric:
                            mean_str = f"{stats['mean']:.0f}"
                            std_str = f"{stats['std']:.0f}"
                        else:
                            mean_str = f"{stats['mean']:.3f}"
                            std_str = f"{stats['std']:.3f}"
                        print(f"      {metric.replace('_', ' ').title()}: "
                              f"{mean_str} Â± {std_str}")
        else:
            if verbose:
                print(f"\n    âš ï¸  No successful folds for budget k={k}")

        results['budgets'][k] = budget_results

    return results



def main():
    """ä¸»è¯„ä¼°æµç¨‹ - CLIç‰ˆæœ¬"""
    from visualization import (
        setup_style,
        generate_all_visualizations_v2,
        aggregate_results_for_visualization

    )
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()

    # è®¾ç½®è¾“å‡ºè¯¦ç»†ç¨‹åº¦
    verbose = not args.quiet

    if verbose:
        print("=" * 70)
        print("  RDT-VoI EVALUATION FRAMEWORK (CLI VERSION)")
        print("=" * 70)

    # 1. åŠ è½½é…ç½®
    if verbose:
        print(f"\n[1] Loading configuration...")

    # ğŸ”¥ åœºæ™¯æ¨¡å¼ï¼šä¼˜å…ˆçº§æœ€é«˜
    if args.scenario:
        scenario_upper = args.scenario.upper()
        cfg = load_scenario_config(scenario_upper)
        config_path = f"config_{scenario_upper}_{'highstakes' if scenario_upper == 'A' else 'proxy'}.yaml"
        if verbose:
            print(f"    âœ“ Loaded scenario {scenario_upper} config")
    elif args.config:
        cfg = load_config(args.config)
        config_path = args.config
        if verbose:
            print(f"    âœ“ Loaded custom config: {args.config}")
    else:
        print("ERROR: Must specify either --scenario or --config")
        print("Examples:")
        print("  python main.py --scenario A")
        print("  python main.py --config path/to/config.yaml")
        sys.exit(1)

    # åº”ç”¨å‘½ä»¤è¡Œè¦†ç›–
    if args.seed:
        cfg.experiment.seed = args.seed
        if verbose:
            print(f"    â†’ Override seed: {args.seed}")

    if args.budgets:
        cfg.selection.budgets = args.budgets
        if verbose:
            print(f"    â†’ Override budgets: {args.budgets}")

    if args.methods:
        cfg.selection.methods = args.methods
        if verbose:
            print(f"    â†’ Override methods: {args.methods}")

    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    if args.quick_test:
        cfg = apply_quick_test_overrides(cfg)

    rng = cfg.get_rng()

    # æ£€æµ‹åœºæ™¯ç±»å‹
    scenario = detect_scenario_from_config(cfg)
    if verbose:
        print(f"\n    ğŸ¯ Detected Scenario: {scenario}")
        if scenario == 'A':
            print("       â†’ High-stakes / Near-threshold decision focus")
        else:
            print("       â†’ Compute efficiency / Robustness focus")

    # ğŸ”¥ å¹¶è¡Œå¤„ç†è®¾ç½®
    use_parallel = args.parallel
    n_workers = args.workers
    if use_parallel and verbose:
        if n_workers is None:
            n_workers = max(1, mp.cpu_count() - 1)
        print(f"\n    âš¡ Parallel processing enabled: {n_workers} workers")

    # 2. åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = create_output_dir_from_config(cfg, config_path, args.output)
    if verbose:
        print(f"\n[2] Output directory: {output_dir}")

    # ä»…å¯è§†åŒ–æ¨¡å¼
    if args.viz_only:
        if not args.results_file:
            print("  âœ— Error: --viz-only requires --results-file")
            sys.exit(1)

        print(f"\n[VIZ-ONLY] Loading results from: {args.results_file}")
        with open(args.results_file, 'rb') as f:
            all_results = pickle.load(f)

        df_results = aggregate_results_for_visualization(all_results)
        print("  âš ï¸  Visualization-only mode: skipping full pipeline")
        return

    # 3-8. å®Œæ•´å®éªŒæµç¨‹
    if verbose:
        print("\n[3] Building spatial domain...")
    geom = build_grid2d_geometry(cfg.geometry.nx, cfg.geometry.ny, cfg.geometry.h)

    if verbose:
        print("\n[4] Constructing GMRF prior with DDI control...")

    if hasattr(cfg.decision, 'target_ddi') and cfg.decision.target_ddi > 0:
        Q_temp, mu_temp = build_prior(geom, cfg.prior)
        tau = cfg.decision.get_threshold(mu_temp)
        if verbose:
            print(f"    Target DDI: {cfg.decision.target_ddi:.2%}")
            print(f"    Decision threshold: Ï„ = {tau:.3f}")
        Q_pr, mu_pr = build_prior_with_ddi(
            geom, cfg.prior, tau=tau, target_ddi=cfg.decision.target_ddi
        )
    else:
        Q_pr, mu_pr = build_prior(geom, cfg.prior)

        # ğŸ”¥ æ–°å¢ï¼šé¢„å…ˆè®¡ç®—å¹¶ç¼“å­˜tauåˆ°configä¸­
    tau = cfg.decision.get_threshold(mu_pr)
    cfg.decision.tau_iri = tau  # ç¼“å­˜åˆ°é…ç½®ä¸­
    if verbose:
        print(f"    âœ“ Decision threshold cached: Ï„ = {tau:.3f}")

    # ğŸ”¥ éªŒè¯DDIæ˜¯å¦è¾¾æ ‡
    if cfg.plots.ddi_overlay.get('enable', True) and verbose:
        from spatial_field import plot_ddi_heatmap, compute_ddi_with_target
        from inference import SparseFactor, compute_posterior_variance_diagonal

        factor = SparseFactor(Q_pr)
        sample_idx = rng.choice(geom.n, size=min(100, geom.n), replace=False)
        sample_vars = compute_posterior_variance_diagonal(factor, sample_idx)
        sigma_est = np.sqrt(np.mean(sample_vars)) * np.ones(geom.n)

        # âœ… ä½¿ç”¨ä¿®å¤åçš„DDIè®¡ç®—
        if hasattr(cfg.decision, 'target_ddi') and cfg.decision.target_ddi > 0:
            actual_ddi, epsilon = compute_ddi_with_target(
                mu_pr, sigma_est, tau, cfg.decision.target_ddi
            )
            print(f"    âœ“ Actual DDI: {actual_ddi:.2%} (target: {cfg.decision.target_ddi:.2%})")
            print(f"      Epsilon: {epsilon:.3f}Ïƒ")

        plot_ddi_heatmap(geom, mu_pr, sigma_est, tau,
                         output_path=output_dir / 'ddi_heatmap_prior.png')

    if verbose:
        print(f"    Precision sparsity: {Q_pr.nnz / geom.n ** 2 * 100:.2f}%")
        print(f"    Correlation length: {cfg.prior.correlation_length:.1f} m")

    if verbose:
        print("\n[5] Sampling true deterioration state...")
    x_true = sample_gmrf(Q_pr, mu_pr, rng)
    if verbose:
        print(f"    State range: [{x_true.min():.2f}, {x_true.max():.2f}]")
        print(f"    Mean: {x_true.mean():.2f}, Std: {x_true.std():.2f}")
    np.save(output_dir / 'x_true.npy', x_true)

    if verbose:
        print("\n[6] Generating sensor pool...")
    if cfg.sensors.use_heterogeneous:
        from sensors import generate_heterogeneous_sensor_pool, create_cost_zones_example
        if cfg.sensors.cost_zones:
            cost_zones = cfg.sensors.cost_zones
        else:
            cost_zones = create_cost_zones_example(geom)
        sensors = generate_heterogeneous_sensor_pool(
            geom, cfg.sensors, cost_zones=cost_zones, rng=rng
        )
    else:
        sensors = generate_sensor_pool(geom, cfg.sensors, rng)

    if verbose:
        print("\n[7] Preparing global test set for EVI...")
    n_test = min(200, geom.n)
    test_idx_global = rng.choice(geom.n, size=n_test, replace=False)
    if verbose:
        print(f"    Test set size: {n_test}")

    if verbose:
        print("\n[8] Running method evaluations...")
    methods = get_available_methods(cfg)
    if verbose:
        print(f"    Methods to evaluate: {', '.join(methods)}")

    all_results = {}
    for method_name in methods:
        t_method_start = datetime.now()
        try:
            results = run_method_evaluation(
                method_name=method_name,
                cfg=cfg,
                geom=geom,
                Q_pr=Q_pr,
                mu_pr=mu_pr,
                x_true=x_true,
                sensors=sensors,
                test_idx_global=test_idx_global,
                use_parallel=use_parallel,  # ğŸ”¥ ä¼ é€’å¹¶è¡Œå‚æ•°
                n_workers=n_workers,
                verbose=verbose
            )
            all_results[method_name] = results
            t_method_elapsed = (datetime.now() - t_method_start).total_seconds()
            if verbose:
                print(f"\n  âœ“ {method_name} completed in {t_method_elapsed:.1f}s")
        except Exception as e:
            if verbose:
                print(f"\n  âœ— {method_name} FAILED: {str(e)}")
            warnings.warn(f"Method {method_name} failed: {str(e)}")
            import traceback
            traceback.print_exc()
            continue

    # 9. ä¿å­˜ç»“æœ
    if verbose:
        print("\n[9] Saving results...")
    with open(output_dir / 'results_raw.pkl', 'wb') as f:
        pickle.dump(all_results, f)
    if verbose:
        print(f"    Saved: results_raw.pkl")

    if verbose:
        print("    Converting results to DataFrame...")
    try:
        df_results = aggregate_results_for_visualization(all_results)
        if df_results.empty:
            if verbose:
                print("    âš ï¸  Warning: No results to aggregate")
        else:
            df_results.to_csv(output_dir / 'results_aggregated.csv', index=False)
            if verbose:
                print(f"    Saved: results_aggregated.csv ({len(df_results)} rows)")
    except Exception as e:
        if verbose:
            print(f"    âœ— Failed to create aggregated DataFrame: {e}")
        df_results = pd.DataFrame()

    # 10. å¯è§†åŒ–
    if not args.skip_viz and not df_results.empty:
        if verbose:
            print("\n[10] Generating visualizations...")
        plots_dir = output_dir / 'plots'
        plots_dir.mkdir(exist_ok=True)

        try:
            # âœ… ä½¿ç”¨ä¿®å¤åçš„å¯è§†åŒ–å‡½æ•°
            from visualization import (
                aggregate_results_for_visualization,
                plot_roi_curves_fixed,
                plot_marginal_efficiency_fixed
            )

            # é‡æ–°èšåˆï¼ˆä½¿ç”¨inner joinï¼‰
            df_results_clean = aggregate_results_for_visualization(all_results)

            # ä½¿ç”¨ä¿®å¤åçš„ROIç»˜å›¾
            plot_roi_curves_fixed(df_results_clean, plots_dir, cfg, baseline_method='uniform')

            # ä½¿ç”¨ä¿®å¤åçš„è¾¹é™…æ•ˆç‡ç»˜å›¾
            plot_marginal_efficiency_fixed(all_results, plots_dir, cfg)

            # å…¶ä»–å¯è§†åŒ–å‡½æ•°...
            generate_all_visualizations_v2(
                all_results=all_results,
                df_results=df_results_clean,  # ä½¿ç”¨æ¸…ç†åçš„æ•°æ®
                geom=geom,
                sensors=sensors,
                Q_pr=Q_pr,
                mu_pr=mu_pr,
                output_dir=output_dir,
                config=cfg,
                scenario=scenario
            )

            if verbose:
                print(f"    âœ“ Visualization complete")
        except Exception as e:
            if verbose:
                print(f"    âœ— Visualization phase failed: {str(e)}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()