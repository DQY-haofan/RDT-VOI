"""
æ”¯æŒæ‰¹é‡RHSçš„æŽ¨æ–­æ¨¡å— - æ¸…ç†ç‰ˆ

ä¸»è¦æ”¹è¿›ï¼š
1. solve_multi() ç»Ÿä¸€æŽ¥å£ï¼Œç§»é™¤é‡å¤å®šä¹‰
2. æ‰¹é‡äºŒæ¬¡åž‹è®¡ç®—ä¼˜åŒ–
3. å®Œæ•´çš„å¤šRHSæ”¯æŒ
"""

import numpy as np
import scipy.sparse as sp
import scipy.sparse.linalg as spla
from typing import Tuple, Optional, Union
import warnings


class SparseFactor:
    """
    ä¼˜åŒ–çš„ç¨€ç–å› å­ç±»ï¼šæ”¯æŒæ‰¹é‡æ“ä½œå’Œrank-1æ›´æ–°
    """

    _cholmod_initialized = False  # ç±»å˜é‡ï¼Œåªæ‰“å°ä¸€æ¬¡
    _cholmod_warning_shown = False  # ðŸ”¥ æ–°å¢žï¼šæ˜¯å¦å·²æ˜¾ç¤ºè¿‡è­¦å‘Š

    def __init__(self, Q: sp.spmatrix, method: str = "cholmod"):
        """
        Factorize sparse SPD matrix Q.

        Args:
            Q: Sparse precision matrix (must be SPD)
            method: "cholmod" | "splu" | "pcg"
        """
        self.n = Q.shape[0]
        self.method = method
        self.Q = Q.tocsc()

        if method == "cholmod":
            try:
                from sksparse.cholmod import cholesky
                self.factor = cholesky(self.Q)
                self._has_cholmod = True
                # åªåœ¨ç¬¬ä¸€æ¬¡æ‰“å°
                if not SparseFactor._cholmod_initialized:
                    print("  Using CHOLMOD (fast)")
                    SparseFactor._cholmod_initialized = True
            except ImportError:
                # ðŸ”¥ ä¿®æ”¹ï¼šåªåœ¨ç¬¬ä¸€æ¬¡æ˜¾ç¤ºè­¦å‘Š
                if not SparseFactor._cholmod_warning_shown:
                    warnings.warn("cholmod not available, falling back to splu",
                                  category=ImportWarning, stacklevel=2)
                    SparseFactor._cholmod_warning_shown = True
                self.factor = spla.splu(self.Q)
                self._has_cholmod = False
                self.method = "splu"

    def solve(self, b: Union[np.ndarray, sp.spmatrix], tol: float = 1e-8) -> np.ndarray:
        """
        Solve Q * x = b (supports single or multiple RHS)

        Args:
            b: Right-hand side (n,) or (n, k) or sparse matrix
            tol: Tolerance for iterative solvers

        Returns:
            x: Solution vector(s) (n,) or (n, k)
        """
        # è½¬æ¢ç¨€ç–çŸ©é˜µä¸ºç¨ å¯†
        if sp.issparse(b):
            b = b.toarray()

        if self.method == "pcg":
            if b.ndim == 1:
                if self.ilu is not None:
                    M = spla.LinearOperator(
                        (self.n, self.n),
                        matvec=self.ilu.solve
                    )
                else:
                    M = None

                x, info = spla.cg(self.Q, b, tol=tol, M=M, maxiter=self.n)
                if info != 0:
                    warnings.warn(f"PCG did not converge (info={info})")
                return x
            else:
                # æ‰¹é‡PCGï¼ˆåˆ—å¾ªçŽ¯ï¼‰
                return np.column_stack([self.solve(b[:, i], tol) for i in range(b.shape[1])])

        else:
            # CHOLMODå’ŒSPLUéƒ½æ”¯æŒå¤šRHS
            if self._has_cholmod:
                return self.factor.solve_A(b)
            else:
                return self.factor.solve(b)

    def solve_multi(self, B: np.ndarray) -> np.ndarray:
        """
        ðŸ”¥ æ‰¹é‡æ±‚è§£ Q X = Bï¼ˆå¤šä¸ªå³ç«¯å‘é‡ï¼‰

        è¿™æ˜¯åŠ é€Ÿçš„å…³é”®ï¼ä¸€æ¬¡è°ƒç”¨è§£å†³æ‰€æœ‰å€™é€‰ï¼Œè€Œä¸æ˜¯å¾ªçŽ¯ã€‚

        Args:
            B: Right-hand sides (n, m) - æ¯åˆ—æ˜¯ä¸€ä¸ªRHS

        Returns:
            X: Solutions (n, m)

        Example:
            # ä¸è¦è¿™æ ·ï¼ˆæ…¢ï¼‰ï¼š
            for i in range(480):
                z_i = factor.solve(H[i, :])  # 480æ¬¡è°ƒç”¨

            # åº”è¯¥è¿™æ ·ï¼ˆå¿«ï¼‰ï¼š
            Z = factor.solve_multi(H.T)  # 1æ¬¡è°ƒç”¨ï¼
        """
        # ç›´æŽ¥è°ƒç”¨solveï¼Œå®ƒå·²ç»æ”¯æŒå¤šRHS
        return self.solve(B)

    def solve_lower(self, b: np.ndarray) -> np.ndarray:
        """
        Solve L * x = b (ä»…CHOLMODæ”¯æŒ)

        ç”¨é€”ï¼šå¿«é€Ÿè®¡ç®— ||L^{-1} h||^2 = h^T Î£ h
        """
        if not self._has_cholmod:
            raise NotImplementedError("solve_lower only available with CHOLMOD")

        return self.factor.solve_L(b)

    def logdet(self) -> float:
        """Compute log determinant of Q."""
        if self._has_cholmod:
            return self.factor.logdet()

        elif self.method == "splu":
            L_diag = self.factor.L.diagonal()
            U_diag = self.factor.U.diagonal()
            return np.sum(np.log(np.abs(L_diag))) + np.sum(np.log(np.abs(U_diag)))

        else:
            warnings.warn("logdet via PCG is expensive")
            rng = np.random.default_rng(42)
            n_probes = 20
            trace_inv = 0.0
            for _ in range(n_probes):
                z = rng.standard_normal(self.n)
                trace_inv += np.dot(z, self.solve(z))
            trace_inv /= n_probes
            return -np.log(trace_inv) * self.n

    def rank1_update(self, h: np.ndarray, weight: float = 1.0):
        """
        ðŸ”¥ Rank-1æ›´æ–°ï¼šQ_new = Q + weight * h h^T

        è¿™æ˜¯EVIå¿«é€Ÿå®žçŽ°çš„æ ¸å¿ƒï¼
        """
        if self._has_cholmod and weight > 0:
            try:
                # âœ… ä¿®å¤ï¼šè½¬æ¢ä¸º CSC åˆ—å‘é‡ï¼ˆCHOLMOD è¦æ±‚ï¼‰
                if sp.issparse(h):
                    h_col = h.tocsc()
                else:
                    # å°† dense array è½¬ä¸º CSC åˆ—å‘é‡
                    h_flat = h.ravel()
                    h_col = sp.csc_matrix(h_flat.reshape(-1, 1))

                self.factor.update_inplace(h_col, weight)
            except Exception as e:
                # CHOLMOD update å¤±è´¥ï¼Œé™çº§åˆ°é‡æ–°åˆ†è§£
                warnings.warn(f"CHOLMOD update failed ({e}), refactorizing...")
                if not sp.issparse(self.Q):
                    self.Q = sp.csr_matrix(self.Q)

                # ç¡®ä¿ h æ˜¯ dense ç”¨äºŽ outer
                if sp.issparse(h):
                    h = h.toarray().ravel()

                self.Q = self.Q + weight * sp.csr_matrix(np.outer(h, h))
                self.__init__(self.Q, self.method)
        else:
            # é‡æ–°åˆ†è§£
            if not sp.issparse(self.Q):
                self.Q = sp.csr_matrix(self.Q)

            # ç¡®ä¿ h æ˜¯ dense ç”¨äºŽ outer
            if sp.issparse(h):
                h = h.toarray().ravel()

            self.Q = self.Q + weight * sp.csr_matrix(np.outer(h, h))
            self.__init__(self.Q, self.method)


# =====================================================================
# æ‰¹é‡äºŒæ¬¡åž‹è®¡ç®—ï¼ˆç”¨äºŽMIé¢„ç­›ï¼‰
# =====================================================================

def batch_quadform_via_solve(factor: SparseFactor,
                             H: np.ndarray) -> np.ndarray:
    """
    æ‰¹é‡è®¡ç®— h_i^T Î£ h_iï¼Œå…¶ä¸­ H = [h_1, h_2, ..., h_m]

    Args:
        factor: SparseFactor for Q
        H: Matrix of vectors (n, m)

    Returns:
        quad: Array of quadratic forms (m,)

    ç®—æ³•ï¼š
        Z = Q^{-1} H  (ä¸€æ¬¡solveï¼Œmä¸ªRHS)
        quad[i] = h_i^T z_i = sum(H[:, i] * Z[:, i])
    """
    Z = factor.solve_multi(H)  # (n, m) - ä¸€æ¬¡è°ƒç”¨ï¼
    quad = np.einsum('ij,ij->j', H, Z)
    return quad


def batch_quadform_cholesky(factor: SparseFactor,
                            H: np.ndarray) -> np.ndarray:
    """
    ä½¿ç”¨Choleskyçš„æ›´å¿«æ–¹æ³•ï¼ˆä»…CHOLMODï¼‰

    ç®—æ³•ï¼š
        L x = H  =>  x = L^{-1} H
        h^T Î£ h = h^T Q^{-1} h = ||L^{-T} h||^2 = ||x||^2
    """
    if not factor._has_cholmod:
        return batch_quadform_via_solve(factor, H)

    T = factor.solve_lower(H)
    quad = np.einsum('ij,ij->j', T, T)
    return quad


def quadform_via_solve(factor: SparseFactor, h: np.ndarray) -> float:
    """
    å•å‘é‡ç‰ˆæœ¬ï¼ˆå‘åŽå…¼å®¹ï¼‰
    Compute h^T Î£ h = h^T Q^{-1} h
    """
    z = factor.solve(h)
    return np.dot(h, z)


# =====================================================================
# åŽéªŒè®¡ç®—ï¼ˆä¿æŒåŽŸæœ‰æŽ¥å£ï¼‰
# =====================================================================

def compute_posterior(Q_pr: sp.spmatrix,
                      mu_pr: np.ndarray,
                      H: sp.spmatrix,
                      R_diag: np.ndarray,
                      y: np.ndarray,
                      method: str = "cholmod",
                      tol: float = 1e-8) -> Tuple[np.ndarray, SparseFactor]:
    """
    Compute Gaussian posterior (unchanged interface)
    """
    n, m = Q_pr.shape[0], len(y)

    # Compute Q_post = Q_pr + H^T R^{-1} H
    R_inv = 1.0 / R_diag
    H_weighted = sp.diags(R_inv) @ H
    Q_post = Q_pr + H.T @ H_weighted

    # RHS: H^T R^{-1} y + Q_pr Î¼_pr
    rhs = H.T @ (R_inv * y) + Q_pr @ mu_pr

    # Factorize and solve
    factor = SparseFactor(Q_post, method=method)
    mu_post = factor.solve(rhs, tol=tol)

    # Validate
    residual = Q_post @ mu_post - rhs
    rhs_norm = np.linalg.norm(rhs)

    if rhs_norm > 1e-14:
        rel_residual = np.linalg.norm(residual) / rhs_norm
        if rel_residual > tol * 10:
            warnings.warn(f"High relative residual: {rel_residual:.2e}")

    return mu_post, factor


def compute_posterior_variance_diagonal(factor: SparseFactor,
                                       indices: np.ndarray = None,
                                       batch_size: int = 100) -> np.ndarray:
    """
    æ‰¹é‡è®¡ç®—å¯¹è§’æ–¹å·®ï¼ˆåŠ é€Ÿç‰ˆï¼‰
    """
    n = factor.n
    if indices is None:
        indices = np.arange(n)

    var_diag = np.zeros(len(indices))

    # åˆ†æ‰¹è®¡ç®—ï¼ˆé¿å…ä¸€æ¬¡æž„é€ è¿‡å¤§çŸ©é˜µï¼‰
    for batch_start in range(0, len(indices), batch_size):
        batch_end = min(batch_start + batch_size, len(indices))
        batch_indices = indices[batch_start:batch_end]
        batch_size_actual = len(batch_indices)

        # æž„é€ å•ä½å‘é‡æ‰¹æ¬¡
        E_batch = np.zeros((n, batch_size_actual))
        for i, idx in enumerate(batch_indices):
            E_batch[idx, i] = 1.0

        # æ‰¹é‡æ±‚è§£
        Z_batch = factor.solve_multi(E_batch)

        # æå–å¯¹è§’å…ƒ
        for i, idx in enumerate(batch_indices):
            var_diag[batch_start + i] = Z_batch[idx, i]

    return var_diag


def compute_mutual_information(Q_pr: sp.spmatrix,
                               H: sp.spmatrix,
                               R_diag: np.ndarray) -> float:
    """Compute mutual information (unchanged)"""
    R_inv = 1.0 / R_diag
    H_weighted = sp.diags(R_inv) @ H
    Q_post = Q_pr + H.T @ H_weighted

    factor_pr = SparseFactor(Q_pr)
    factor_post = SparseFactor(Q_post)

    mi = 0.5 * (factor_post.logdet() - factor_pr.logdet())
    return mi