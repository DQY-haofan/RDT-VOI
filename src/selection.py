"""
Sensor selection algorithms with submodular optimization.
Implements Greedy-MI, Greedy-A, and baseline methods.
"""

import numpy as np
import scipy.sparse as sp
from typing import List, Tuple
import heapq
from dataclasses import dataclass


@dataclass
class SelectionResult:
    """Result container for sensor selection."""
    selected_ids: List[int]
    objective_values: List[float]  # Value after each addition
    marginal_gains: List[float]  # Marginal gain at each step
    total_cost: float
    method_name: str


def greedy_mi(sensors: List, k: int, Q_pr: sp.spmatrix,
              costs: np.ndarray = None,
              lazy: bool = True,
              batch_size: int = 64) -> SelectionResult:
    """
    Greedy sensor selection maximizing Mutual Information.

    ä¿®å¤ï¼š
    1. å®ç°æ‰¹é‡å€™é€‰è¯„ä¼°ï¼ˆåŠ é€Ÿ10-50å€ï¼‰
    2. æ­£ç¡®çš„æˆæœ¬å½’ä¸€åŒ–é€»è¾‘
    3. ä½¿ç”¨batch_quadformåŠ é€ŸäºŒæ¬¡å‹è®¡ç®—
    """
    from inference import SparseFactor, batch_quadform_via_solve

    n = Q_pr.shape[0]
    n_candidates = len(sensors)

    # æå–æˆ–éªŒè¯æˆæœ¬
    if costs is None:
        costs = np.array([s.cost for s in sensors], dtype=float)
        print(f"  Using real sensor costs: min=Â£{costs.min():.0f}, "
              f"max=Â£{costs.max():.0f}, mean=Â£{costs.mean():.0f}")

    # åˆå§‹åŒ–
    selected_ids = []
    selected_sensors = []
    objective_values = []  # ç´¯è®¡æ€»MI
    marginal_gains = []  # æ¯æ­¥çš„Î”MI
    total_cost = 0.0

    # å…ˆéªŒå› å­
    current_factor = SparseFactor(Q_pr)
    current_obj = 0.0

    # ğŸ”¥ é¢„è®¡ç®—ä¼ æ„Ÿå™¨çš„hè¡Œå’Œå™ªå£°æ–¹å·®ï¼ˆé¿å…é‡å¤æ„é€ ï¼‰
    sensor_h_rows = []
    sensor_noise_vars = []
    for s in sensors:
        h = np.zeros(n)
        h[s.idxs] = s.weights
        sensor_h_rows.append(h)
        sensor_noise_vars.append(s.noise_var)

    # ä¼˜å…ˆé˜Ÿåˆ—ï¼ˆlazy evaluationï¼‰
    pq = [] if lazy else None
    last_eval = {} if lazy else None

    # Greedyå¾ªç¯
    for step in range(k):
        best_score = -np.inf
        best_gain = 0.0
        best_idx = -1

        # ğŸ”¥ æ”¶é›†å¾…è¯„ä¼°çš„å€™é€‰
        candidates_to_eval = []

        if lazy and step > 0:
            # Lazyè·¯å¾„ï¼šæ£€æŸ¥é˜Ÿåˆ—ä¸­çš„topå€™é€‰
            temp_extracted = []
            while pq and len(candidates_to_eval) < batch_size:
                neg_score, eval_iter, cand_idx, cached_gain = heapq.heappop(pq)

                if cand_idx in selected_ids:
                    continue

                if eval_iter < step:
                    # è¿‡æœŸï¼Œéœ€è¦é‡æ–°è¯„ä¼°
                    candidates_to_eval.append(cand_idx)
                    temp_extracted.append((neg_score, eval_iter, cand_idx, cached_gain))
                else:
                    # æ–°é²œçš„è¯„ä¼°ï¼Œç›´æ¥ä½¿ç”¨
                    best_idx = cand_idx
                    best_score = -neg_score
                    best_gain = cached_gain
                    # æŠŠå‰©ä½™çš„æ”¾å›é˜Ÿåˆ—
                    for item in temp_extracted:
                        heapq.heappush(pq, item)
                    break

        # å¦‚æœæ²¡æ‰¾åˆ°æˆ–é¦–æ¬¡è¿­ä»£ï¼Œå…¨é‡è¯„ä¼°ï¼ˆåˆ†æ‰¹ï¼‰
        if best_idx == -1:
            if not candidates_to_eval:
                candidates_to_eval = [i for i in range(n_candidates) if i not in selected_ids]

            # ğŸ”¥ æ‰¹é‡è¯„ä¼°å€™é€‰
            for batch_start in range(0, len(candidates_to_eval), batch_size):
                batch_end = min(batch_start + batch_size, len(candidates_to_eval))
                batch_ids = candidates_to_eval[batch_start:batch_end]

                # æ„é€ æ‰¹é‡HçŸ©é˜µ (n Ã— batch_size)
                H_batch = np.column_stack([sensor_h_rows[i] for i in batch_ids])
                R_batch = np.array([sensor_noise_vars[i] for i in batch_ids])

                # ğŸ”¥ æ‰¹é‡è®¡ç®— h^T Î£ hï¼ˆä¸€æ¬¡solveï¼‰
                quad_batch = batch_quadform_via_solve(current_factor, H_batch)

                # æ‰¹é‡è®¡ç®—gainå’Œscore
                gains_batch = 0.5 * np.log1p(quad_batch / R_batch)
                costs_batch = costs[batch_ids]
                scores_batch = gains_batch / costs_batch

                # æ›´æ–°æœ€ä½³å€™é€‰
                for i, (cand_idx, gain, score) in enumerate(zip(batch_ids, gains_batch, scores_batch)):
                    if lazy:
                        heapq.heappush(pq, (-score, step, cand_idx, gain))
                        last_eval[cand_idx] = step

                    if score > best_score:
                        best_score = score
                        best_gain = gain
                        best_idx = cand_idx

        if best_idx == -1:
            print(f"Warning: No valid sensor found at step {step}")
            break

        # æ·»åŠ é€‰ä¸­çš„ä¼ æ„Ÿå™¨
        selected_ids.append(best_idx)
        selected_sensors.append(sensors[best_idx])
        marginal_gains.append(best_gain)
        total_cost += costs[best_idx]

        # Rank-1æ›´æ–°ç²¾åº¦çŸ©é˜µ
        h_best = sensor_h_rows[best_idx]
        r_best = sensor_noise_vars[best_idx]
        current_factor.rank1_update(h_best / np.sqrt(r_best), 1.0)

        # ç´¯è®¡MIï¼ˆç”¨çœŸå®gainï¼Œä¸æ˜¯scoreï¼‰
        current_obj += best_gain
        objective_values.append(current_obj)

        # æ‰“å°è¿›åº¦ï¼ˆå¢åŠ æˆæœ¬æ•ˆç›Šä¿¡æ¯ï¼‰
        if (step + 1) % 10 == 0 or step == k - 1:
            cost_efficiency = best_gain / costs[best_idx] * 1000  # per Â£1000
            print(f"  Step {step + 1}/{k}: "
                  f"MI={current_obj:.3f} nats ({current_obj / np.log(2):.2f} bits), "
                  f"Î”MI={best_gain:.4f}, "
                  f"eff={cost_efficiency:.6f} bits/Â£1k, "
                  f"cost=Â£{total_cost:.0f}, "
                  f"type={sensors[best_idx].type_name}")

    return SelectionResult(
        selected_ids=selected_ids,
        objective_values=objective_values,
        marginal_gains=marginal_gains,
        total_cost=total_cost,
        method_name="Greedy-MI"
    )


def greedy_aopt(sensors: List, k: int, Q_pr: sp.spmatrix,
                costs: np.ndarray = None,
                hutchpp_probes: int = 20,
                batch_size: int = 32,
                max_candidates: int = None,
                early_stop_ratio: float = 0.0) -> SelectionResult:
    """
    å¤§å¹…åŠ é€Ÿç‰ˆGreedy-A-optimality

    æ–°å¢ä¼˜åŒ–ï¼š
    1. max_candidates: æ¯æ­¥åªè¯„ä¼°å‰Nä¸ªå€™é€‰ï¼ˆç©ºé—´è¿‘é‚»ï¼‰
    2. early_stop_ratio: å½“å¢ç›Š<åˆå§‹å¢ç›Š*ratioæ—¶åœæ­¢
    3. è¿›åº¦è¾“å‡ºï¼šå®æ—¶æ˜¾ç¤ºè¯„ä¼°è¿›åº¦
    4. æ‰¹é‡å¤„ç†ï¼šå‡å°‘factoræ„é€ æ¬¡æ•°

    Args:
        sensors: å€™é€‰ä¼ æ„Ÿå™¨åˆ—è¡¨
        k: é¢„ç®—
        Q_pr: å…ˆéªŒç²¾åº¦çŸ©é˜µ
        costs: ä¼ æ„Ÿå™¨æˆæœ¬ï¼ˆå¯é€‰ï¼‰
        hutchpp_probes: Hutchinson++æ¢é’ˆæ•°
        batch_size: æ‰¹é‡è¯„ä¼°å¤§å°
        max_candidates: æ¯æ­¥æœ€å¤šè¯„ä¼°çš„å€™é€‰æ•°ï¼ˆNone=å…¨éƒ¨ï¼‰
        early_stop_ratio: æ—©åœé˜ˆå€¼ï¼ˆ0=ç¦ç”¨ï¼‰
    """
    from inference import SparseFactor, compute_posterior
    import time

    n = Q_pr.shape[0]
    if costs is None:
        costs = np.ones(len(sensors))

    selected_ids = []
    selected_sensors = []
    objective_values = []
    marginal_gains = []
    total_cost = 0.0

    # å…ˆéªŒå› å­
    factor_pr = SparseFactor(Q_pr)

    # é¢„ç”Ÿæˆä¼ æ„Ÿå™¨åæ ‡ï¼ˆç”¨äºç©ºé—´ç­›é€‰ï¼‰
    from geometry import Geometry
    sensor_locations = np.array([sensors[i].idxs[0] for i in range(len(sensors))])

    # Hutchinson++é…ç½®
    rng = np.random.default_rng(42)
    probe_refresh_interval = 5

    current_trace = estimate_trace_hutchpp(factor_pr, hutchpp_probes, rng)
    print(f"  Initial trace estimate: {current_trace:.1f}")

    initial_gain = None  # ç”¨äºearly stop
    step_times = []  # è®°å½•æ¯æ­¥è€—æ—¶

    for step in range(k):
        step_start = time.time()

        best_gain = -np.inf
        best_idx = -1

        # ğŸ”¥ å€™é€‰ç­›é€‰ç­–ç•¥
        remaining = [i for i in range(len(sensors)) if i not in selected_ids]

        if max_candidates and len(remaining) > max_candidates:
            # ç©ºé—´ç­›é€‰ï¼šä¼˜å…ˆè¯„ä¼°è·ç¦»å·²é€‰ç‚¹è¾ƒè¿œçš„å€™é€‰
            if selected_ids:
                # è®¡ç®—æ¯ä¸ªå€™é€‰åˆ°å·²é€‰ç‚¹çš„æœ€å°è·ç¦»
                selected_locs = sensor_locations[selected_ids]
                remaining_locs = sensor_locations[remaining]

                from scipy.spatial.distance import cdist
                dists = cdist(remaining_locs.reshape(-1, 1),
                              selected_locs.reshape(-1, 1))
                min_dists = dists.min(axis=1)

                # é€‰æ‹©è·ç¦»æœ€è¿œçš„max_candidatesä¸ª
                top_indices = np.argsort(-min_dists)[:max_candidates]
                remaining = [remaining[i] for i in top_indices]
            else:
                # é¦–æ­¥ï¼šéšæœºé‡‡æ ·
                remaining = rng.choice(remaining, size=max_candidates, replace=False).tolist()

        # ğŸ”¥ è¿›åº¦è¾“å‡º
        print(f"  Step {step + 1}/{k}: Evaluating {len(remaining)} candidates "
              f"(out of {len(sensors) - len(selected_ids)} remaining)...")

        evaluated_count = 0
        last_print_time = time.time()

        # åˆ†æ‰¹è¯„ä¼°
        for batch_start in range(0, len(remaining), batch_size):
            batch_end = min(batch_start + batch_size, len(remaining))
            batch_ids = remaining[batch_start:batch_end]

            # ğŸ”¥ æ¯5ç§’æˆ–æ¯100ä¸ªå€™é€‰è¾“å‡ºä¸€æ¬¡è¿›åº¦
            evaluated_count += len(batch_ids)
            current_time = time.time()
            if (current_time - last_print_time > 5.0) or (batch_end == len(remaining)):
                progress_pct = 100 * evaluated_count / len(remaining)
                elapsed = current_time - step_start
                eta = elapsed / evaluated_count * (len(remaining) - evaluated_count)
                print(f"    Progress: {evaluated_count}/{len(remaining)} "
                      f"({progress_pct:.0f}%), ETA: {eta:.0f}s")
                last_print_time = current_time

            # æ„é€ æµ‹è¯•ä¼ æ„Ÿå™¨é›†åˆ
            test_sensors_list = []
            for cand_idx in batch_ids:
                test_sensors_list.append(selected_sensors + [sensors[cand_idx]])

            # åˆ·æ–°æ¢é’ˆï¼ˆæ¯probe_refresh_intervalæ­¥ï¼‰
            if step % probe_refresh_interval == 0 or step == 0:
                probes = generate_hutchpp_probes(n, hutchpp_probes, rng)

            # æ‰¹é‡è¯„ä¼°
            for cand_idx, test_sensors in zip(batch_ids, test_sensors_list):
                from sensors import assemble_H_R
                H_test, R_test = assemble_H_R(test_sensors, n)

                try:
                    mu_post, factor_post = compute_posterior(
                        Q_pr, np.zeros(n), H_test, R_test, np.zeros(len(test_sensors))
                    )

                    new_trace = estimate_trace_hutchpp_with_probes(
                        factor_post, probes
                    )

                    gain = current_trace - new_trace

                    if gain > best_gain:
                        best_gain = gain
                        best_idx = cand_idx

                except Exception as e:
                    # æ•°å€¼é—®é¢˜ï¼šè·³è¿‡è¯¥å€™é€‰
                    continue

        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°æœ‰æ•ˆå€™é€‰
        if best_idx == -1:
            print(f"  Warning: No valid candidate found at step {step + 1}")
            break

        # è®°å½•åˆå§‹å¢ç›Šï¼ˆç”¨äºearly stopï¼‰
        if step == 0:
            initial_gain = best_gain

        # ğŸ”¥ Early stopæ£€æŸ¥
        if early_stop_ratio > 0 and initial_gain is not None:
            if best_gain < initial_gain * early_stop_ratio:
                print(f"  Early stopping at step {step + 1}: "
                      f"gain {best_gain:.1f} < threshold {initial_gain * early_stop_ratio:.1f}")
                break

        # æ·»åŠ ä¼ æ„Ÿå™¨
        selected_ids.append(best_idx)
        selected_sensors.append(sensors[best_idx])
        marginal_gains.append(best_gain)
        total_cost += costs[best_idx]

        # æ›´æ–°trace
        current_trace -= best_gain
        objective_values.append(-current_trace)

        # è®°å½•è€—æ—¶
        step_time = time.time() - step_start
        step_times.append(step_time)

        # ğŸ”¥ æ›´è¯¦ç»†çš„è¿›åº¦è¾“å‡º
        avg_time = np.mean(step_times)
        eta_total = avg_time * (k - step - 1)
        print(f"  âœ“ Step {step + 1}/{k} complete: "
              f"Trace={current_trace:.1f}, Î”Trace={best_gain:.1f}, "
              f"Sensor=#{best_idx}, Cost=Â£{total_cost:.0f}, "
              f"Time={step_time:.1f}s (ETA: {eta_total / 60:.1f}min)")

    print(f"  Total time: {sum(step_times) / 60:.1f} minutes")

    return SelectionResult(
        selected_ids=selected_ids,
        objective_values=objective_values,
        marginal_gains=marginal_gains,
        total_cost=total_cost,
        method_name="Greedy-A"
    )


def estimate_trace_hutchpp(factor: 'SparseFactor', n_probes: int,
                           rng: np.random.Generator) -> float:
    """Hutchinson++ traceä¼°è®¡"""
    probes = generate_hutchpp_probes(factor.n, n_probes, rng)
    return estimate_trace_hutchpp_with_probes(factor, probes)


def generate_hutchpp_probes(n: int, n_probes: int,
                            rng: np.random.Generator) -> np.ndarray:
    """ç”ŸæˆHutchinson++æ¢é’ˆï¼ˆRademacherå‘é‡ï¼‰"""
    return rng.choice([-1, 1], size=(n, n_probes)).astype(float)


def estimate_trace_hutchpp_with_probes(factor: 'SparseFactor',
                                       probes: np.ndarray) -> float:
    """ä½¿ç”¨ç»™å®šæ¢é’ˆä¼°è®¡trace"""
    # Z = Î£ * probes = Q^{-1} * probes
    Z = factor.solve(probes)

    # trace(Î£) â‰ˆ (1/m) * sum(probes^T * Z)
    trace_est = np.mean(np.einsum('ij,ij->j', probes, Z))

    return trace_est

def uniform_selection(sensors: List, k: int, geom) -> SelectionResult:
    """
    Uniform spatial grid sensor placement.

    Args:
        sensors: Candidate sensors
        k: Budget
        geom: Geometry object

    Returns:
        result: SelectionResult
    """
    # Create kÃ—k grid over domain
    coords = geom.coords

    # Compute grid spacing
    x_range = coords[:, 0].max() - coords[:, 0].min()
    y_range = coords[:, 1].max() - coords[:, 1].min()

    k_side = int(np.ceil(np.sqrt(k)))
    x_grid = np.linspace(coords[:, 0].min(), coords[:, 0].max(), k_side)
    y_grid = np.linspace(coords[:, 1].min(), coords[:, 1].max(), k_side)

    # Find nearest sensor to each grid point
    from scipy.spatial import cKDTree
    sensor_coords = np.array([coords[s.idxs[0]] for s in sensors])
    tree = cKDTree(sensor_coords)

    selected_ids = []
    for xi in x_grid:
        for yi in y_grid:
            if len(selected_ids) >= k:
                break
            _, idx = tree.query([xi, yi])
            if idx not in selected_ids:
                selected_ids.append(idx)

    total_cost = sum(sensors[i].cost for i in selected_ids)

    return SelectionResult(
        selected_ids=selected_ids,
        objective_values=[],
        marginal_gains=[],
        total_cost=total_cost,
        method_name="Uniform"
    )


def random_selection(sensors: List, k: int,
                     rng: np.random.Generator) -> SelectionResult:
    """
    Random sensor selection baseline.

    Args:
        sensors: Candidate sensors
        k: Budget
        rng: Random generator

    Returns:
        result: SelectionResult
    """
    selected_ids = rng.choice(len(sensors), size=k, replace=False).tolist()
    total_cost = sum(sensors[i].cost for i in selected_ids)

    return SelectionResult(
        selected_ids=selected_ids,
        objective_values=[],
        marginal_gains=[],
        total_cost=total_cost,
        method_name="Random"
    )


if __name__ == "__main__":
    from config import load_config
    from geometry import build_grid2d_geometry
    from spatial_field import build_prior
    from sensors import generate_sensor_pool

    cfg = load_config()
    rng = cfg.get_rng()

    # Setup
    geom = build_grid2d_geometry(20, 20, h=cfg.geometry.h)
    Q_pr, mu_pr = build_prior(geom, cfg.prior)
    sensors = generate_sensor_pool(geom, cfg.sensors, rng)

    print(f"Selecting from {len(sensors)} candidates...")

    # Test Greedy-MI
    print("\nGreedy-MI:")
    result = greedy_mi(sensors, k=10, Q_pr=Q_pr, lazy=True)
    print(f"  Final MI: {result.objective_values[-1]:.3f}")
    print(f"  Total cost: Â£{result.total_cost:.0f}")

    # Test Random
    print("\nRandom:")
    result_random = random_selection(sensors, k=10, rng=rng)
    print(f"  Total cost: Â£{result_random.total_cost:.0f}")