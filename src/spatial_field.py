"""
ä¿®å¤åçš„ spatial_field.py - æ”¯æŒéå¹³ç¨³å…ˆéªŒ

ä¸»è¦æ”¹è¿›ï¼š
1. æ–°å¢ apply_nodewise_nugget() å‡½æ•° - åˆ›å»ºç©ºé—´å¼‚è´¨æ€§
2. ä¿®æ”¹ build_prior() - æ”¯æŒçƒ­ç‚¹åŒºåŸŸï¼ˆé«˜æ–¹å·®ï¼‰
3. æ·»åŠ å…ˆéªŒå¼‚è´¨æ€§éªŒè¯

ä½¿ç”¨æ–¹æ³•ï¼š
1. æ›¿æ¢åŸ spatial_field.py
2. åœ¨ config.yaml ä¸­æ·»åŠ çƒ­ç‚¹é…ç½®ï¼š

prior:
  beta_base: 1.0e-3  # åŸºçº¿ nuggetï¼ˆéçƒ­ç‚¹åŒºåŸŸï¼‰
  beta_hot: 1.0e-6   # çƒ­ç‚¹ nuggetï¼ˆçƒ­ç‚¹åŒºåŸŸï¼‰
  hotspots:
    - center_m: [60, 60]
      radius_m: 40
    - center_m: [140, 60]
      radius_m: 30
    - center_m: [100, 140]
      radius_m: 35
"""

import numpy as np
import scipy.sparse as sp
import scipy.sparse.linalg as spla
from typing import Tuple
from scipy.special import gamma


def matern_tau_from_params(nu: float, kappa: float, sigma2: float,
                           d: int = 2, alpha: int = 2) -> float:
    """è®¡ç®— SPDE å™ªå£°å°ºåº¦ Ï„ï¼ˆåŸå‡½æ•°ä¿æŒä¸å˜ï¼‰"""
    numerator = gamma(nu)
    denominator = gamma(alpha) * (4 * np.pi) ** (d / 2) * kappa ** (2 * nu) * sigma2
    tau_squared = numerator / denominator
    return np.sqrt(tau_squared)


def build_grid_precision_spde(nx: int, ny: int, h: float,
                              kappa: float, beta: float = 1e-6) -> sp.spmatrix:
    """æ„å»º 2D ç½‘æ ¼ SPDE ç²¾åº¦çŸ©é˜µï¼ˆåŸå‡½æ•°ä¿æŒä¸å˜ï¼‰"""
    n = nx * ny

    def idx(i, j):
        return i * ny + j

    center_coef = kappa ** 2 + 4.0 / h ** 2
    neigh_coef = -1.0 / h ** 2

    row_idx = []
    col_idx = []
    data = []

    for i in range(nx):
        for j in range(ny):
            current = idx(i, j)
            row_idx.append(current)
            col_idx.append(current)
            data.append(center_coef + beta)

            if i < nx - 1:
                row_idx.append(current)
                col_idx.append(idx(i + 1, j))
                data.append(neigh_coef)
            if i > 0:
                row_idx.append(current)
                col_idx.append(idx(i - 1, j))
                data.append(neigh_coef)
            if j < ny - 1:
                row_idx.append(current)
                col_idx.append(idx(i, j + 1))
                data.append(neigh_coef)
            if j > 0:
                row_idx.append(current)
                col_idx.append(idx(i, j - 1))
                data.append(neigh_coef)

    Q = sp.coo_matrix((data, (row_idx, col_idx)), shape=(n, n))
    return Q.tocsr()


def build_graph_precision(L: sp.spmatrix, alpha: float, beta: float) -> sp.spmatrix:
    """ä»å›¾æ‹‰æ™®æ‹‰æ–¯æ„å»º GMRF ç²¾åº¦ï¼ˆåŸå‡½æ•°ä¿æŒä¸å˜ï¼‰"""
    n = L.shape[0]
    Q = alpha * L + beta * sp.eye(n)
    return Q.tocsr()


def sample_gmrf(Q: sp.spmatrix,
                mu: np.ndarray = None,
                rng: np.random.Generator = None) -> np.ndarray:
    """ä» GMRF é‡‡æ ·ï¼ˆåŸå‡½æ•°ä¿æŒä¸å˜ï¼‰"""
    n = Q.shape[0]
    if mu is None:
        mu = np.zeros(n)
    if rng is None:
        rng = np.random.default_rng()

    z = rng.standard_normal(n)

    try:
        from sksparse.cholmod import cholesky
        factor = cholesky(Q)
        x_centered = factor.solve_Lt(z, use_LDLt_decomposition=False)
    except ImportError:
        lu = spla.splu(Q)
        x_centered = lu.solve(z)

    return mu + x_centered


# =====================================================================
# ğŸ”¥ æ–°å¢å‡½æ•°ï¼šèŠ‚ç‚¹åŒ– nuggetï¼ˆåˆ›å»ºç©ºé—´å¼‚è´¨æ€§ï¼‰
# =====================================================================

def apply_nodewise_nugget(geom, prior_config) -> sp.spmatrix:
    """
    ğŸ”¥ æ–°å¢ï¼šåº”ç”¨èŠ‚ç‚¹åŒ– nuggetï¼Œåˆ›å»ºç©ºé—´å¼‚è´¨æ€§

    çƒ­ç‚¹åŒºåŸŸï¼šä½ nugget â†’ é«˜ä¸ç¡®å®šæ€§ï¼ˆå¤§æ–¹å·®ï¼‰
    éçƒ­ç‚¹åŒºåŸŸï¼šé«˜ nugget â†’ ä½ä¸ç¡®å®šæ€§ï¼ˆå°æ–¹å·®ï¼‰

    è¿™æ˜¯è®© MI/EVI æ–¹æ³•æ‹‰å¼€å·®è·çš„å…³é”®ï¼

    Args:
        geom: å‡ ä½•å¯¹è±¡ï¼ˆéœ€è¦ coords å±æ€§ï¼‰
        prior_config: å…ˆéªŒé…ç½®ï¼ˆéœ€è¦ beta_base, beta_hot, hotspots å±æ€§ï¼‰

    Returns:
        èŠ‚ç‚¹åŒ– nugget å¯¹è§’çŸ©é˜µ

    é…ç½®ç¤ºä¾‹ï¼š
        prior:
          beta_base: 1.0e-3  # éçƒ­ç‚¹åŒºåŸŸ
          beta_hot: 1.0e-6   # çƒ­ç‚¹åŒºåŸŸ
          hotspots:
            - center_m: [60, 60]
              radius_m: 40
    """
    n = geom.n

    # é»˜è®¤å€¼ï¼ˆå¦‚æœé…ç½®ä¸­æ²¡æœ‰ï¼‰
    beta_base = getattr(prior_config, 'beta_base', 1e-3)
    beta_hot = getattr(prior_config, 'beta_hot', 1e-6)

    # åˆå§‹åŒ–ä¸ºåŸºçº¿ nugget
    beta_vec = np.full(n, beta_base, dtype=float)

    # åº”ç”¨çƒ­ç‚¹
    if hasattr(prior_config, 'hotspots') and prior_config.hotspots:
        xy = geom.coords  # shape (n, 2), å•ä½ç±³

        for hs in prior_config.hotspots:
            center = np.array(hs['center_m'], dtype=float)  # (x, y)
            radius = float(hs['radius_m'])

            # æ‰¾åˆ°çƒ­ç‚¹èŒƒå›´å†…çš„èŠ‚ç‚¹
            distances_sq = np.sum((xy - center)**2, axis=1)
            mask = distances_sq <= radius**2

            # çƒ­ç‚¹åŒºåŸŸç”¨ä½ nuggetï¼ˆé«˜ä¸ç¡®å®šæ€§ï¼‰
            beta_vec[mask] = beta_hot

            n_hot = mask.sum()
            print(f"  Hotspot at {center}: {n_hot} nodes with Î²={beta_hot:.1e}")

    return sp.diags(beta_vec, format='csr')


# =====================================================================
# ğŸ”¥ ä¿®æ”¹å‡½æ•°ï¼šbuild_prior æ”¯æŒéå¹³ç¨³å…ˆéªŒ
# =====================================================================

def generate_near_threshold_patches(geom, mu_prior: np.ndarray,
                                    tau: float,
                                    target_ddi: float = 0.3,
                                    sigma_local: float = 0.3,
                                    max_patches: int = 5,
                                    rng: np.random.Generator = None) -> np.ndarray:
    """
    ğŸ”¥ ç”Ÿæˆæ¥è¿‘é˜ˆå€¼çš„æ–‘å—ï¼Œæ§åˆ¶ DDIï¼ˆå†³ç­–éš¾åº¦æŒ‡æ•°ï¼‰

    DDI = P(|Î¼ - Ï„| â‰¤ k*Ïƒ)ï¼Œk=1 æ—¶è¡¨ç¤º 1 æ ‡å‡†å·®èŒƒå›´å†…

    ç›®æ ‡ï¼šè®© 20-40% çš„åƒå…ƒè½åœ¨"é˜ˆå€¼é™„è¿‘"ï¼Œè¿™æ˜¯ EVI å¤§æ˜¾èº«æ‰‹çš„åŒºåŸŸ

    Args:
        geom: å‡ ä½•å¯¹è±¡
        mu_prior: åŸå§‹å…ˆéªŒå‡å€¼ (n,)
        tau: å†³ç­–é˜ˆå€¼
        target_ddi: ç›®æ ‡ DDI æ¯”ä¾‹ï¼ˆ0.2-0.4ï¼‰
        sigma_local: å±€éƒ¨æ ‡å‡†å·®ä¼°è®¡
        max_patches: æœ€å¤šæ·»åŠ å¤šå°‘ä¸ªæ–‘å—
        rng: éšæœºæ•°ç”Ÿæˆå™¨

    Returns:
        mu_adjusted: è°ƒæ•´åçš„å…ˆéªŒå‡å€¼ (n,)
    """
    if rng is None:
        rng = np.random.default_rng()

    n = geom.n
    mu_adjusted = mu_prior.copy()

    # è®¡ç®—å½“å‰ DDI
    current_ddi = np.mean(np.abs(mu_prior - tau) <= sigma_local)

    if current_ddi >= target_ddi:
        print(f"  Current DDI={current_ddi:.2%} already meets target={target_ddi:.2%}")
        return mu_adjusted

    # éœ€è¦è°ƒæ•´çš„åƒå…ƒæ•°é‡
    n_to_adjust = int(n * (target_ddi - current_ddi))

    print(f"  Generating near-threshold patches:")
    print(f"    Current DDI: {current_ddi:.2%}")
    print(f"    Target DDI: {target_ddi:.2%}")
    print(f"    Pixels to adjust: {n_to_adjust}")

    if geom.mode == "grid2d":
        nx = int(np.sqrt(n))
        ny = nx

        # ç”Ÿæˆè‹¥å¹²æ–‘å—
        n_patches = min(max_patches, max(1, n_to_adjust // 50))

        for i in range(n_patches):
            # éšæœºé€‰æ‹©æ–‘å—ä¸­å¿ƒ
            center_x = rng.uniform(0.2, 0.8) * (nx * geom.h)
            center_y = rng.uniform(0.2, 0.8) * (ny * geom.h)

            # éšæœºåŠå¾„ï¼ˆè¦†ç›– 20-100 ä¸ªåƒå…ƒï¼‰
            radius = rng.uniform(2, 5) * geom.h

            # éšæœºåç§»æ–¹å‘ï¼ˆå‘ä¸Šæˆ–å‘ä¸‹æ¥è¿‘é˜ˆå€¼ï¼‰
            direction = rng.choice([-1, 1])

            # åç§»é‡ï¼šè®©è¯¥åŒºåŸŸå‡å€¼æ¥è¿‘ tau Â± 0.5*sigma
            delta = direction * rng.uniform(0.2, 0.5) * sigma_local

            # åº”ç”¨æ–‘å—
            for idx in range(n):
                x, y = geom.coords[idx]
                dist = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)

                if dist <= radius:
                    # é«˜æ–¯æƒé‡
                    weight = np.exp(-0.5 * (dist / radius) ** 2)

                    # å‘é˜ˆå€¼æ–¹å‘è°ƒæ•´
                    current_gap = mu_adjusted[idx] - tau
                    adjustment = -delta * weight

                    # ç¡®ä¿è°ƒæ•´åæ›´æ¥è¿‘é˜ˆå€¼
                    if abs(current_gap + adjustment) < abs(current_gap):
                        mu_adjusted[idx] += adjustment

            print(f"    Patch {i + 1}: center=({center_x:.0f}, {center_y:.0f}), "
                  f"radius={radius:.0f}m, shift={delta:+.3f}")

    else:
        # å¯¹äºéç½‘æ ¼å‡ ä½•ï¼Œä½¿ç”¨å…¨å±€è°ƒæ•´
        gaps = mu_adjusted - tau
        large_gap_mask = np.abs(gaps) > sigma_local

        if large_gap_mask.sum() > 0:
            # é€‰æ‹©æœ€è¿œç¦»é˜ˆå€¼çš„ç‚¹å‘å†…æ‹‰
            n_adjust = min(n_to_adjust, large_gap_mask.sum())
            adjust_idx = np.argsort(np.abs(gaps))[-n_adjust:]

            for idx in adjust_idx:
                # æ‹‰å‘é˜ˆå€¼æ–¹å‘
                direction = -np.sign(gaps[idx])
                delta = direction * rng.uniform(0.2, 0.5) * sigma_local
                mu_adjusted[idx] += delta

    # éªŒè¯è°ƒæ•´åçš„ DDI
    final_ddi = np.mean(np.abs(mu_adjusted - tau) <= sigma_local)
    print(f"    Final DDI: {final_ddi:.2%}")

    return mu_adjusted


def build_prior_with_ddi(geom, prior_config,
                         tau: float = None,
                         target_ddi: float = 0.3) -> Tuple[sp.spmatrix, np.ndarray]:
    """
    ğŸ”¥ æ„å»ºå¸¦ DDI æ§åˆ¶çš„å…ˆéªŒ

    å…ˆæ­£å¸¸æ„å»ºå…ˆéªŒï¼Œç„¶åè°ƒæ•´å‡å€¼åœºä½¿å…¶æ¥è¿‘é˜ˆå€¼
    """
    # æ­£å¸¸æ„å»ºå…ˆéªŒ
    Q_pr, mu_pr = build_prior(geom, prior_config)

    # å¦‚æœæŒ‡å®šäº†é˜ˆå€¼å’Œç›®æ ‡ DDIï¼Œè°ƒæ•´å‡å€¼åœº
    if tau is not None and target_ddi > 0:
        rng = np.random.default_rng(42)  # å›ºå®šç§å­ä¿è¯å¯é‡å¤

        # ä¼°è®¡å±€éƒ¨æ ‡å‡†å·®ï¼ˆä½¿ç”¨å…ˆéªŒæ–¹å·®çš„å¹³æ–¹æ ¹ï¼‰
        from inference import SparseFactor, compute_posterior_variance_diagonal
        factor = SparseFactor(Q_pr)

        # é‡‡æ ·å°‘é‡ç‚¹ä¼°è®¡æ–¹å·®
        sample_idx = rng.choice(geom.n, size=min(100, geom.n), replace=False)
        sample_vars = compute_posterior_variance_diagonal(factor, sample_idx)
        sigma_local = np.sqrt(sample_vars.mean())

        print(f"  Estimated local Ïƒ = {sigma_local:.3f}")

        # ç”Ÿæˆè¿‘é˜ˆå€¼æ–‘å—
        mu_pr = generate_near_threshold_patches(
            geom, mu_pr, tau,
            target_ddi=target_ddi,
            sigma_local=sigma_local,
            rng=rng
        )

    return Q_pr, mu_pr


def compute_ddi(mu: np.ndarray, sigma: np.ndarray,
                tau: float, k: float = 1.0) -> float:
    """
    è®¡ç®—å†³ç­–éš¾åº¦æŒ‡æ•°ï¼ˆDecision Difficulty Indexï¼‰

    DDI = P(|Î¼ - Ï„| â‰¤ k*Ïƒ)

    Args:
        mu: å‡å€¼å‘é‡ (n,)
        sigma: æ ‡å‡†å·®å‘é‡ (n,)
        tau: å†³ç­–é˜ˆå€¼
        k: æ ‡å‡†å·®å€æ•°ï¼ˆé»˜è®¤ 1.0ï¼‰

    Returns:
        DDI: è½åœ¨é˜ˆå€¼é™„è¿‘çš„æ¯”ä¾‹ [0, 1]
    """
    gaps = np.abs(mu - tau)
    threshold_band = k * sigma

    near_threshold = gaps <= threshold_band
    ddi = near_threshold.mean()

    return ddi


def plot_ddi_heatmap(geom, mu: np.ndarray, sigma: np.ndarray,
                     tau: float, output_path, k: float = 1.0):
    """
    ç»˜åˆ¶ DDI çƒ­åŠ›å›¾

    æ ‡æ³¨å“ªäº›åŒºåŸŸå¤„äº"å†³ç­–éš¾åº¦"åŒº
    """
    import matplotlib.pyplot as plt

    if geom.mode != "grid2d":
        print("  DDI heatmap only supports grid2d")
        return

    n = geom.n
    nx = int(np.sqrt(n))
    ny = nx

    # è®¡ç®—æ¯ä¸ªç‚¹çš„"å†³ç­–éš¾åº¦"
    gaps = np.abs(mu - tau)
    difficulty = np.exp(-0.5 * (gaps / (k * sigma)) ** 2)

    # Reshape ä¸º 2D
    difficulty_map = difficulty.reshape(nx, ny)
    mu_map = mu.reshape(nx, ny)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

    # å·¦å›¾ï¼šå…ˆéªŒå‡å€¼
    im1 = ax1.imshow(mu_map, cmap='RdYlGn_r', origin='lower')
    ax1.contour(mu_map, levels=[tau], colors='black', linewidths=3)
    ax1.set_title(f'Prior Mean (Ï„={tau:.2f})')
    plt.colorbar(im1, ax=ax1, label='Mean IRI')

    # å³å›¾ï¼šå†³ç­–éš¾åº¦
    im2 = ax2.imshow(difficulty_map, cmap='hot', origin='lower', vmin=0, vmax=1)
    ax2.set_title('Decision Difficulty\n(closer to 1 = near threshold)')
    plt.colorbar(im2, ax=ax2, label='Difficulty')

    # è®¡ç®— DDI
    ddi = compute_ddi(mu, sigma, tau, k)
    fig.suptitle(f'DDI = {ddi:.2%} (|Î¼-Ï„| â‰¤ {k}Ïƒ)', fontsize=14, fontweight='bold')

    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"  âœ“ Saved DDI heatmap: {output_path}")


def build_prior(geom, prior_config) -> Tuple[sp.spmatrix, np.ndarray]:
    """
    Build GMRF prior precision and mean from geometry and config.

    ğŸ”¥ ä¿®å¤ï¼šæ”¯æŒéå¹³ç¨³å…ˆéªŒï¼ˆçƒ­ç‚¹åŒºåŸŸé«˜æ–¹å·®ï¼‰

    æ”¹è¿›ï¼š
    1. ä½¿ç”¨èŠ‚ç‚¹åŒ– nugget æ›¿ä»£å‡åŒ€ nugget
    2. è‡ªåŠ¨éªŒè¯å…ˆéªŒå¼‚è´¨æ€§ï¼ˆCV åº” > 10%ï¼‰
    3. ç»™å‡ºè­¦å‘Šå¦‚æœå…ˆéªŒè¿‡äºå‡åŒ€
    """
    n = geom.n

    if geom.mode == "grid2d":
        # âœ… æ­¥éª¤1ï¼šæ„å»ºåŸºç¡€SPDEç®—å­ Q_base = (ÎºÂ² - Î”)
        Q_base = build_grid_precision_spde(
            nx=int(np.sqrt(n)),
            ny=int(np.sqrt(n)),
            h=geom.h,
            kappa=prior_config.kappa,
            beta=0.0  # ä¸åœ¨è¿™é‡ŒåŠ  nugget
        )

        # âœ… æ­¥éª¤2ï¼šè®¡ç®—Ï„Â²ï¼ˆSPDEå™ªå£°æ–¹å·®ï¼‰
        tau = matern_tau_from_params(
            nu=prior_config.nu,
            kappa=prior_config.kappa,
            sigma2=prior_config.sigma2,
            d=2,
            alpha=prior_config.alpha
        )

        # âœ… æ­¥éª¤3ï¼šç¼©æ”¾ SPDE ç®—å­
        Q_spde = (tau ** 2) * Q_base

        # ğŸ”¥ æ­¥éª¤4ï¼šåº”ç”¨èŠ‚ç‚¹åŒ– nuggetï¼ˆåˆ›å»ºç©ºé—´å¼‚è´¨æ€§ï¼‰
        nugget_diag = apply_nodewise_nugget(geom, prior_config)
        Q_pr = Q_spde + nugget_diag

        # éªŒè¯ï¼šè®¡ç®—æ–¹å·®ç»Ÿè®¡
        print(f"  Prior setup: Ï„={tau:.4f}, target ÏƒÂ²={prior_config.sigma2:.4f}")

        # ğŸ”¥ å¿«é€ŸéªŒè¯ç©ºé—´å¼‚è´¨æ€§ï¼ˆé‡‡æ ·å‡ ä¸ªå¯¹è§’å…ƒï¼‰
        try:
            from inference import SparseFactor, compute_posterior_variance_diagonal
            factor = SparseFactor(Q_pr)

            # é‡‡æ ·ä¸åŒåŒºåŸŸçš„æ–¹å·®
            n_samples = min(50, n)
            test_idx = np.linspace(0, n-1, n_samples, dtype=int)
            sample_vars = compute_posterior_variance_diagonal(factor, test_idx)

            var_cv = sample_vars.std() / sample_vars.mean()
            print(f"  Prior variance: mean={sample_vars.mean():.4f}, "
                  f"std={sample_vars.std():.4f}, CV={var_cv:.2%}")

            if var_cv < 0.1:
                print("  âš ï¸  å…ˆéªŒä¸ç¡®å®šæ€§éå¸¸å‡åŒ€ï¼MIä¼˜åŠ¿ä¼šå‡å¼±ã€‚")
                print("      å»ºè®®ï¼šæ·»åŠ  hotspots é…ç½®æˆ–å¢å¤§ beta_base/beta_hot å·®è·")
            else:
                print(f"  âœ“ å…ˆéªŒå¼‚è´¨æ€§è‰¯å¥½ (CV={var_cv:.2%})")

        except Exception as e:
            print(f"  Warning: Could not validate prior variance: {e}")

    elif geom.mode in ["polyline1d", "graph"]:
        # å¯¹äºéç½‘æ ¼å‡ ä½•ï¼Œä½¿ç”¨åŸæœ‰æ–¹æ³•
        # å°è¯•è¯»å– beta_baseï¼Œå¦‚æœæ²¡æœ‰å°±ç”¨ beta
        beta = getattr(prior_config, 'beta_base',
                      getattr(prior_config, 'beta', 1e-6))
        Q_pr = build_graph_precision(
            L=geom.laplacian,
            alpha=prior_config.alpha,
            beta=beta
        )
    else:
        raise ValueError(f"Unknown geometry mode: {geom.mode}")

    # æ„é€ å‡å€¼åœº
    if prior_config.mu_prior_std > 0:
        # é‡‡æ ·ä¸€ä¸ªå…‰æ»‘çš„å‡å€¼åœº
        beta_mean = getattr(prior_config, 'beta_base',
                           getattr(prior_config, 'beta', 1e-6))
        Q_mean = build_graph_precision(
            geom.laplacian,
            alpha=0.1,  # æ¯”prioræ›´å…‰æ»‘
            beta=beta_mean
        )
        rng_mean = np.random.default_rng(42)  # å›ºå®šç§å­
        mu_pr = prior_config.mu_prior_mean + \
                prior_config.mu_prior_std * sample_gmrf(Q_mean, rng=rng_mean)
    else:
        # å¸¸æ•°å‡å€¼
        mu_pr = np.full(n, prior_config.mu_prior_mean)

    return Q_pr, mu_pr


def validate_prior(Q: sp.spmatrix, mu: np.ndarray,
                   rng: np.random.Generator = None,
                   n_samples: int = 5) -> dict:
    """éªŒè¯å…ˆéªŒï¼ˆåŸå‡½æ•°ä¿æŒä¸å˜ï¼‰"""
    if rng is None:
        rng = np.random.default_rng()

    min_eig = spla.eigsh(Q, k=1, which='SA', return_eigenvectors=False)[0]

    samples = [sample_gmrf(Q, mu, rng) for _ in range(n_samples)]
    samples = np.array(samples)

    emp_mean = samples.mean(axis=0)
    emp_std = samples.std(axis=0)

    stats = {
        'n': Q.shape[0],
        'nnz': Q.nnz,
        'sparsity': Q.nnz / Q.shape[0] ** 2,
        'min_eigenvalue': min_eig,
        'is_spd': min_eig > 0,
        'mean_deviation': np.abs(emp_mean - mu).max(),
        'empirical_std_range': (emp_std.min(), emp_std.max()),
        'empirical_var_mean': (emp_std ** 2).mean()
    }

    return stats


if __name__ == "__main__":
    # æµ‹è¯•éå¹³ç¨³å…ˆéªŒ
    from config import load_config
    from geometry import build_grid2d_geometry

    cfg = load_config()
    geom = build_grid2d_geometry(20, 20, h=cfg.geometry.h)

    Q_pr, mu_pr = build_prior(geom, cfg.prior)

    print("\nPrior construction:")
    print(f"  n = {Q_pr.shape[0]}")
    print(f"  nnz = {Q_pr.nnz} ({Q_pr.nnz / Q_pr.shape[0] ** 2 * 100:.2f}%)")

    # Validate
    rng = cfg.get_rng()
    stats = validate_prior(Q_pr, mu_pr, rng, n_samples=50)
    print(f"  Min eigenvalue: {stats['min_eigenvalue']:.6f}")
    print(f"  Is SPD: {stats['is_spd']}")
    print(f"  Empirical variance (mean): {stats['empirical_var_mean']:.4f}")
    print(f"  Target ÏƒÂ²: {cfg.prior.sigma2:.4f}")

    # Sample true state
    x_true = sample_gmrf(Q_pr, mu_pr, rng)
    print(f"  Sample range: [{x_true.min():.3f}, {x_true.max():.3f}]")