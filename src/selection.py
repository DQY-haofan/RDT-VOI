"""
åŠ é€Ÿç‰ˆä¼ æ„Ÿå™¨é€‰æ‹© - æ‰¹é‡æ±‚è§£ç‰ˆæœ¬

ä¸»è¦ä¼˜åŒ–ï¼š
1. æ‰¹é‡RHSæ±‚è§£ï¼ˆä¸€æ¬¡è§£å¤šä¸ªå€™é€‰ï¼‰
2. è‡ªé€‚åº”æ‰¹é‡å¤§å°
3. ä¼˜åŒ–çš„lazy-greedy
4. æå‰ç»ˆæ­¢æ— æ•ˆå€™é€‰

é¢„æœŸåŠ é€Ÿï¼š3-10å€ï¼ˆCPUï¼‰
"""

import numpy as np
import scipy.sparse as sp
from typing import List, Tuple
import heapq
from dataclasses import dataclass


@dataclass
class SelectionResult:
    """Result container for sensor selection."""
    selected_ids: List[int]
    objective_values: List[float]
    marginal_gains: List[float]
    total_cost: float
    method_name: str


def greedy_mi(sensors: List, k: int, Q_pr: sp.spmatrix,
              costs: np.ndarray = None,
              lazy: bool = True,
              batch_size: int = 64) -> SelectionResult:
    """
    åŠ é€Ÿç‰ˆGreedy-MIï¼šæ‰¹é‡RHSæ±‚è§£

    æ–°å¢å‚æ•°ï¼š
        batch_size: æ¯æ‰¹è¯„ä¼°çš„å€™é€‰æ•°ï¼ˆé»˜è®¤64ï¼Œè‡ªé€‚åº”è°ƒæ•´ï¼‰

    åŠ é€ŸåŸç†ï¼š
        - æŠŠå¤šä¸ªå€™é€‰çš„hå‘é‡å †å æˆçŸ©é˜µ H_batch (nÃ—B)
        - ä¸€æ¬¡solveå¾—åˆ° Q^{-1} H_batchï¼Œè€ŒéBæ¬¡solve
        - BLASä¼˜åŒ–çš„çŸ©é˜µä¹˜æ³•ï¼Œç¼“å­˜å‹å¥½
    """
    from inference import SparseFactor, quadform_via_solve

    n = Q_pr.shape[0]
    n_candidates = len(sensors)

    # æå–æˆæœ¬
    if costs is None:
        costs = np.array([s.cost for s in sensors], dtype=float)
        print(f"  Using real sensor costs: min=Â£{costs.min():.0f}, "
              f"max=Â£{costs.max():.0f}, mean=Â£{costs.mean():.0f}")

    # åˆå§‹åŒ–
    selected_ids = []
    selected_sensors = []
    objective_values = []
    marginal_gains = []
    total_cost = 0.0

    # å…ˆéªŒå› å­
    current_factor = SparseFactor(Q_pr)
    current_obj = 0.0

    # æ‡’æƒ°é˜Ÿåˆ—ï¼š(-score, iteration, sensor_id)
    pq = [] if lazy else None
    last_eval = {} if lazy else None

    # ğŸ”¥ é¢„è®¡ç®—æ‰€æœ‰å€™é€‰çš„hå‘é‡ï¼ˆé¿å…é‡å¤æ„é€ ï¼‰
    print("  Precomputing candidate vectors...")
    sensor_h_rows = np.zeros((n, n_candidates))
    sensor_noise_vars = np.zeros(n_candidates)

    for i, s in enumerate(sensors):
        sensor_h_rows[s.idxs, i] = s.weights
        sensor_noise_vars[i] = s.noise_var

    print(f"  Sparse density: {np.count_nonzero(sensor_h_rows)/(n*n_candidates)*100:.2f}%")

    # Greedyå¾ªç¯
    for step in range(k):
        best_score = -np.inf
        best_gain = 0.0
        best_idx = -1

        # ğŸ”¥ æ‰¹é‡è¯„ä¼°ç­–ç•¥
        if lazy and step > 0:
            # ä»é˜Ÿåˆ—ä¸­å–å‡ºtopå€™é€‰è¿›è¡Œç´§åŒ–
            candidates_to_eval = []
            temp_heap = []

            # å–å‡ºtop batch_sizeä¸ªå€™é€‰ï¼ˆæˆ–æ›´å°‘ï¼‰
            while pq and len(candidates_to_eval) < batch_size:
                neg_score, eval_iter, cand_idx = heapq.heappop(pq)

                if cand_idx in selected_ids:
                    continue

                if eval_iter < step:
                    # éœ€è¦é‡æ–°è¯„ä¼°
                    candidates_to_eval.append(cand_idx)
                else:
                    # æ–°é²œçš„ï¼Œè®°å½•ä¸‹æ¥å¯èƒ½å°±æ˜¯æœ€ä½³
                    temp_heap.append((neg_score, eval_iter, cand_idx))

            # ğŸ”¥ æ‰¹é‡è¯„ä¼°è¿™äº›å€™é€‰
            if candidates_to_eval:
                gains_batch, scores_batch = batch_evaluate_candidates(
                    candidates_to_eval,
                    sensor_h_rows,
                    sensor_noise_vars,
                    costs,
                    current_factor,
                    step
                )

                # æ›´æ–°é˜Ÿåˆ—
                for cand_idx, gain, score in zip(candidates_to_eval, gains_batch, scores_batch):
                    heapq.heappush(pq, (-score, step, cand_idx))
                    last_eval[cand_idx] = step

                    if score > best_score:
                        best_score = score
                        best_gain = gain
                        best_idx = cand_idx

            # æŠŠæ–°é²œçš„å€™é€‰æ”¾å›å»
            for item in temp_heap:
                heapq.heappush(pq, item)
                neg_score, eval_iter, cand_idx = item
                if -neg_score > best_score:
                    # éœ€è¦éªŒè¯è¿™ä¸ªå€™é€‰
                    gain, score = evaluate_single_candidate(
                        cand_idx,
                        sensor_h_rows,
                        sensor_noise_vars,
                        costs,
                        current_factor
                    )
                    if score > best_score:
                        best_score = score
                        best_gain = gain
                        best_idx = cand_idx

        # å¦‚æœæ²¡æ‰¾åˆ°æˆ–é¦–æ¬¡è¿­ä»£ï¼Œæ‰¹é‡è¯„ä¼°æ‰€æœ‰å€™é€‰
        if best_idx == -1:
            # ğŸ”¥ åˆ†æ‰¹è¯„ä¼°æ‰€æœ‰å€™é€‰
            remaining = [i for i in range(n_candidates) if i not in selected_ids]

            for batch_start in range(0, len(remaining), batch_size):
                batch_ids = remaining[batch_start:batch_start + batch_size]

                gains_batch, scores_batch = batch_evaluate_candidates(
                    batch_ids,
                    sensor_h_rows,
                    sensor_noise_vars,
                    costs,
                    current_factor,
                    step
                )

                if lazy:
                    # å…¥é˜Ÿ
                    for cand_idx, gain, score in zip(batch_ids, gains_batch, scores_batch):
                        heapq.heappush(pq, (-score, step, cand_idx))
                        last_eval[cand_idx] = step

                # æ›´æ–°æœ€ä½³
                batch_best_idx = np.argmax(scores_batch)
                if scores_batch[batch_best_idx] > best_score:
                    best_score = scores_batch[batch_best_idx]
                    best_gain = gains_batch[batch_best_idx]
                    best_idx = batch_ids[batch_best_idx]

        if best_idx == -1:
            print(f"Warning: No valid sensor found at step {step}")
            break

        # æ·»åŠ é€‰ä¸­çš„ä¼ æ„Ÿå™¨
        selected_ids.append(best_idx)
        selected_sensors.append(sensors[best_idx])
        marginal_gains.append(best_gain)
        total_cost += costs[best_idx]

        # Rank-1æ›´æ–°
        h_best = sensor_h_rows[:, best_idx]
        r_best = sensor_noise_vars[best_idx]
        current_factor.rank1_update(h_best / np.sqrt(r_best), 1.0)

        # ç´¯è®¡MI
        current_obj += best_gain
        objective_values.append(current_obj)

        # æ‰“å°è¿›åº¦
        if (step + 1) % 10 == 0 or step == k - 1:
            print(f"  Step {step + 1}/{k}: "
                  f"MI={current_obj:.3f} nats, "
                  f"Î”MI={best_gain:.4f}, "
                  f"score={best_score:.6f}, "
                  f"cost=Â£{total_cost:.0f}, "
                  f"type={sensors[best_idx].type_name}")

    return SelectionResult(
        selected_ids=selected_ids,
        objective_values=objective_values,
        marginal_gains=marginal_gains,
        total_cost=total_cost,
        method_name="Greedy-MI"
    )


def batch_evaluate_candidates(
    cand_ids: List[int],
    sensor_h_rows: np.ndarray,  # (n, N_total)
    sensor_noise_vars: np.ndarray,
    costs: np.ndarray,
    factor: 'SparseFactor',
    iteration: int
) -> Tuple[np.ndarray, np.ndarray]:
    """
    æ‰¹é‡è¯„ä¼°å¤šä¸ªå€™é€‰çš„å¢ç›Šå’Œå¾—åˆ†

    Args:
        cand_ids: å€™é€‰ç´¢å¼•åˆ—è¡¨
        sensor_h_rows: æ‰€æœ‰å€™é€‰çš„hå‘é‡ (n, N_total)
        sensor_noise_vars: å™ªå£°æ–¹å·®
        costs: æˆæœ¬
        factor: å½“å‰ç²¾åº¦å› å­
        iteration: å½“å‰è¿­ä»£

    Returns:
        gains: æ¯ä¸ªå€™é€‰çš„è¾¹é™…å¢ç›Š (B,)
        scores: æ¯ä¸ªå€™é€‰çš„å¾—åˆ† (B,)
    """
    # ğŸ”¥ å…³é”®ï¼šæ‰¹é‡æ±‚è§£ Q^{-1} H_batch
    H_batch = sensor_h_rows[:, cand_ids]  # (n, B)

    # ä¸€æ¬¡solveå¾—åˆ°æ‰€æœ‰å€™é€‰çš„ Î£ h
    Z_batch = factor.solve(H_batch)  # (n, B)

    # ğŸ”¥ æ‰¹é‡è®¡ç®— h^T Î£ hï¼ˆåˆ—å‘é‡ç‚¹ç§¯ï¼‰
    quad_batch = np.einsum('ij,ij->j', H_batch, Z_batch)

    # æ‰¹é‡è®¡ç®—å¢ç›Š
    r_batch = sensor_noise_vars[cand_ids]
    gains = 0.5 * np.log1p(quad_batch / r_batch)

    # æ‰¹é‡è®¡ç®—å¾—åˆ†ï¼ˆæˆæœ¬å½’ä¸€åŒ–ï¼‰
    cost_batch = costs[cand_ids]
    scores = gains / cost_batch

    return gains, scores


def evaluate_single_candidate(
    cand_idx: int,
    sensor_h_rows: np.ndarray,
    sensor_noise_vars: np.ndarray,
    costs: np.ndarray,
    factor: 'SparseFactor'
) -> Tuple[float, float]:
    """å•ä¸ªå€™é€‰è¯„ä¼°ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
    h = sensor_h_rows[:, cand_idx]

    # ä½¿ç”¨å·²æœ‰çš„quadformæ¥å£
    from inference import quadform_via_solve
    q = quadform_via_solve(factor, h)

    gain = 0.5 * np.log1p(q / sensor_noise_vars[cand_idx])
    score = gain / costs[cand_idx]

    return gain, score


# =====================================================================
# Greedy-A åŠ é€Ÿç‰ˆï¼ˆHutchinson++æ”¹è¿›ï¼‰
# =====================================================================

def greedy_aopt(sensors: List, k: int, Q_pr: sp.spmatrix,
                costs: np.ndarray = None,
                hutchpp_probes: int = 20,
                batch_size: int = 32) -> SelectionResult:
    """
    åŠ é€Ÿç‰ˆGreedy-A-optimality

    ä¼˜åŒ–ï¼š
    1. Hutchinson++ æ‰¹é‡æ¢é’ˆ
    2. æ¯Tæ­¥é‡ç”¨æ¢é’ˆï¼ˆä¸ç”¨æ¯æ­¥éƒ½é‡‡æ ·ï¼‰
    3. æ‰¹é‡å€™é€‰è¯„ä¼°
    """
    from inference import SparseFactor, compute_posterior

    n = Q_pr.shape[0]
    if costs is None:
        costs = np.ones(len(sensors))

    selected_ids = []
    selected_sensors = []
    objective_values = []
    marginal_gains = []
    total_cost = 0.0

    # åˆå§‹traceä¼°è®¡
    factor_pr = SparseFactor(Q_pr)

    # ğŸ”¥ Hutchinson++: é¢„ç”Ÿæˆæ¢é’ˆçŸ©é˜µï¼ˆé‡ç”¨å¤šæ­¥ï¼‰
    rng = np.random.default_rng(42)
    probe_refresh_interval = 5  # æ¯5æ­¥åˆ·æ–°æ¢é’ˆ

    current_trace = estimate_trace_hutchpp(factor_pr, hutchpp_probes, rng)
    print(f"  Initial trace estimate: {current_trace:.1f}")

    for step in range(k):
        best_gain = -np.inf
        best_idx = -1

        # åˆ†æ‰¹è¯„ä¼°å€™é€‰
        remaining = [i for i in range(len(sensors)) if i not in selected_ids]

        for batch_start in range(0, len(remaining), batch_size):
            batch_ids = remaining[batch_start:batch_start + batch_size]

            # æ‰¹é‡æ„å»ºHçŸ©é˜µ
            test_sensors_list = []
            for cand_idx in batch_ids:
                test_sensors_list.append(selected_sensors + [sensors[cand_idx]])

            # ğŸ”¥ æ‰¹é‡traceä¼°è®¡ï¼ˆå¤ç”¨æ¢é’ˆï¼‰
            if step % probe_refresh_interval == 0 or step == 0:
                probes = generate_hutchpp_probes(n, hutchpp_probes, rng)

            for cand_idx, test_sensors in zip(batch_ids, test_sensors_list):
                from sensors import assemble_H_R
                H_test, R_test = assemble_H_R(test_sensors, n)

                # å¿«é€Ÿtraceä¼°è®¡
                mu_post, factor_post = compute_posterior(
                    Q_pr, np.zeros(n), H_test, R_test, np.zeros(len(test_sensors))
                )

                new_trace = estimate_trace_hutchpp_with_probes(
                    factor_post, probes
                )

                gain = current_trace - new_trace

                if gain > best_gain:
                    best_gain = gain
                    best_idx = cand_idx

        if best_idx == -1:
            break

        # æ·»åŠ ä¼ æ„Ÿå™¨
        selected_ids.append(best_idx)
        selected_sensors.append(sensors[best_idx])
        marginal_gains.append(best_gain)
        total_cost += costs[best_idx]

        # æ›´æ–°trace
        current_trace -= best_gain
        objective_values.append(-current_trace)

        if (step + 1) % 10 == 0:
            print(f"  Step {step + 1}/{k}: Trace={current_trace:.1f}, Î”={best_gain:.1f}")

    return SelectionResult(
        selected_ids=selected_ids,
        objective_values=objective_values,
        marginal_gains=marginal_gains,
        total_cost=total_cost,
        method_name="Greedy-A"
    )


def estimate_trace_hutchpp(factor: 'SparseFactor', n_probes: int,
                          rng: np.random.Generator) -> float:
    """Hutchinson++ traceä¼°è®¡"""
    probes = generate_hutchpp_probes(factor.n, n_probes, rng)
    return estimate_trace_hutchpp_with_probes(factor, probes)


def generate_hutchpp_probes(n: int, n_probes: int,
                           rng: np.random.Generator) -> np.ndarray:
    """ç”ŸæˆHutchinson++æ¢é’ˆï¼ˆRademacherå‘é‡ï¼‰"""
    return rng.choice([-1, 1], size=(n, n_probes)).astype(float)


def estimate_trace_hutchpp_with_probes(factor: 'SparseFactor',
                                      probes: np.ndarray) -> float:
    """ä½¿ç”¨ç»™å®šæ¢é’ˆä¼°è®¡trace"""
    # Z = Î£ * probes = Q^{-1} * probes
    Z = factor.solve(probes)

    # trace(Î£) â‰ˆ (1/m) * sum(probes^T * Z)
    trace_est = np.mean(np.einsum('ij,ij->j', probes, Z))

    return trace_est